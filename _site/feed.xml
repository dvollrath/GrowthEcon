<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title></title>
    <atom:link href="https://growthecon.com/feed.xml" rel="self" type="application/rss+xml"/>
    <link>https://growthecon.com/</link>
    <description></description>
    <pubDate>Fri, 08 Jan 2021 12:09:16 -0600</pubDate>
    
      <item>
        <title>The 1965 shift in growth</title>
        <link>https://growthecon.com/blog/BLS-TFP-Again/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/BLS-TFP-Again/</guid>
        <description>&lt;p&gt;Well, insurrection in the nation’s literal Capitol was not the context I expected for my next blog entry. But with lots of nervous energy and few useful outlets for it (I, alas, am not authorized to arrest Ted Cruz) I figured I’d work on this post.&lt;/p&gt;

&lt;p&gt;This is a follow up to my &lt;a href=&quot;https://growthecon.com/blog/BLS-TFP/&quot;&gt;last post&lt;/a&gt; from early December, where I was digging deeper into some data on total factor productivity (TFP) growth rates. The reason for &lt;em&gt;that&lt;/em&gt; post was that I participated in a discourse on &lt;a href=&quot;https://www.pairagraph.com/dialogue/ee04c261817f45f39e1d0bb5f63e0b90&quot;&gt;Pairagraph&lt;/a&gt; with &lt;a href=&quot;https://twitter.com/elidourado&quot;&gt;Eli Dourado&lt;/a&gt; of the Center for Growth and Opportunity. The prompt was “Economic growth is stagnating, but there’s more to the story.” We were talking about interpretations of slow growth.&lt;/p&gt;

&lt;p&gt;The upshot of the December post was that the growth rate of TFP started to drag far earlier than the discourse with Eli - or much of the current discourse around slow growth - assumed. Rather than slow TFP growth starting after the Great Recession, or after 2000, it appears to have started in the early 1970s.&lt;/p&gt;

&lt;p&gt;I want to revise that earlier post a little to push back the slowdown even further to the mid-1960s, and talk more about &lt;em&gt;why&lt;/em&gt; the slowdown started so early, and lingered so long. The short answer is: Baby Boomers.&lt;/p&gt;

&lt;p&gt;Standard disclaimer about this being utter speculation applies.&lt;/p&gt;

&lt;h3 id=&quot;decomposing-growth&quot;&gt;Decomposing growth&lt;/h3&gt;
&lt;p&gt;I’m using the same data from the December post, and that Eli and I talked briefly about in our posts on Pairagraph. This is the BLS series on multi-factor productivity, which is just a different word for TFP. You can see the December post for links to a version of that data hosted by John Fernald at the San Fran Fed that includes some adjustments for capacity utilization. That adjustment isn’t terribly important to what I’m doing here.&lt;/p&gt;

&lt;p&gt;When the BLS (or John with his adjusted data) calculate the growth rate of TFP for a year, they use a formula that looks like this&lt;/p&gt;

\[gTFP = gGDP - a gK - (1-a) gLQ - (1-a) gHours.\]

&lt;p&gt;That is, the growth rate of TFP (&lt;img src=&quot;http://latex.codecogs.com/png.latex?gTFP\inline&quot;/&gt;) is equal to the growth rate of GDP (&lt;img src=&quot;http://latex.codecogs.com/png.latex?gGDP\inline&quot;/&gt;) minus the growth that can be accounted for by capital and labor (all the rest of those terms). The value of &lt;img src=&quot;http://latex.codecogs.com/png.latex?a\inline&quot;/&gt; serves as a weight on how important growth in capital is (&lt;img src=&quot;http://latex.codecogs.com/png.latex?gK\inline&quot;/&gt;) and how important the two pieces of labor are (&lt;img src=&quot;http://latex.codecogs.com/png.latex?gLQ\inline&quot;/&gt; and &lt;img src=&quot;http://latex.codecogs.com/png.latex?gHours\inline&quot;/&gt;). That value can change year to year, but is generally around 0.33. I have thoughts - long, tedious, boring thoughts - about why that number is probably too high, but this is not the time or place to subject you to them.&lt;/p&gt;

&lt;p&gt;Those two parts of labor are &lt;img src=&quot;http://latex.codecogs.com/png.latex?gHours\inline&quot;/&gt;, which measures the growth in the raw hours worked by people in the economy, and &lt;img src=&quot;http://latex.codecogs.com/png.latex?gLQ\inline&quot;/&gt;, which measures the “labor quality” of those people. This labor quality is inferred from changes in relative wages, and is meant to reflect any change in how valuable firms find workers. This would be capturing any increase due to education, or skill acquisition outside of formal education, or experience effects, or … whatever else might make labor useful to a firm &lt;em&gt;beyond&lt;/em&gt; the raw hours that labor works.&lt;/p&gt;

&lt;p&gt;This little table shows the values of each piece of that equation for three different time periods: 1948-65, 1966-2000, and 2001-2018. All the growth rates are in percent form, to avoid lots of things to four and five decimal places.&lt;/p&gt;

&lt;table style=&quot;width:100%&quot;&gt;
	&lt;colgroup&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 15%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
       &lt;col span=&quot;1&quot; style=&quot;width: 17%;&quot; /&gt;
    &lt;/colgroup&gt;
  &lt;tr&gt;
    &lt;th&gt;Years&lt;/th&gt;
    &lt;th&gt;gGDP&lt;/th&gt; 
    &lt;th&gt;agK &lt;/th&gt;
    &lt;th&gt;(1-a)gLQ&lt;/th&gt;
    &lt;th&gt;(1-a)gHours&lt;/th&gt;
    &lt;th&gt;gTFP&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;48-65&lt;/td&gt;
    &lt;td&gt;3.46&lt;/td&gt; 
    &lt;td&gt;3.02&lt;/td&gt;
    &lt;td&gt;0.41&lt;/td&gt;
    &lt;td&gt;0.38&lt;/td&gt;
    &lt;td&gt;2.01&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;66-00&lt;/td&gt;
    &lt;td&gt;3.29&lt;/td&gt; 
    &lt;td&gt;3.98&lt;/td&gt;
    &lt;td&gt;0.37&lt;/td&gt;
    &lt;td&gt;1.55&lt;/td&gt;
    &lt;td&gt;0.75&lt;/td&gt;
  &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td&gt;01-18&lt;/td&gt;
    &lt;td&gt;2.05&lt;/td&gt; 
    &lt;td&gt;2.54&lt;/td&gt;
    &lt;td&gt;0.42&lt;/td&gt;
    &lt;td&gt;0.44&lt;/td&gt;
    &lt;td&gt;0.61&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;Take a look at what happens, in particular, at the transition from 1948-65 to 1966-00. GDP growth falls &lt;em&gt;a little&lt;/em&gt;, from 3.46% per year to 3.29% per year. But capital growth &lt;em&gt;increases&lt;/em&gt; by almost one whole percentage point, from 3.02 to 3.98% per year. Labor quality growth doesn’t change much, but the growth rate of hours sees a very large &lt;em&gt;increase&lt;/em&gt;, from 0.38% per year to 1.55% per year.&lt;/p&gt;

&lt;p&gt;The net effect of (a) the growth rate of GDP staying about the same and (b) the growth rate of inputs rising is to lower the implied growth rate of TFP. It drops from 2.01% per year to only 0.75%. This is a significant slowdown in productivity growth, and it happens in the mid-1960s, not in the late 1970s, the early 2000s, or after the Great Recession.&lt;/p&gt;

&lt;p&gt;Note from the third line that the growth rate of TFP does drop in 01-18 to 0.61%, but that drop from 0.75% is much smaller than the drop that occurs starting in 1966. We’ll come back to the other pieces of this later.&lt;/p&gt;

&lt;p&gt;Going back to the change in 1965, the point I want to make is that productivity growth dropped - in accounting terms - because input growth went up but we did not see any increase in output. The economy absorbed more and more workeres and more and more capital, but it didn’t translate into more and more output growth.&lt;/p&gt;

&lt;h3 id=&quot;boomers&quot;&gt;Boomers!&lt;/h3&gt;
&lt;p&gt;The choice of 1965 wasn’t an accident. That year is when the first Boomers turned 20. I chose it because it represents a point at which the Baby Boom generation really started to hit the labor force. Yes, some of them would have been working at younger than age 20 (and hence in the early 1960s) but by the late 1960s the labor force participation of the Boomers would really be kicking in.&lt;/p&gt;

&lt;p&gt;And once they entered the work force, what happened? Very clearly hours started to grow faster (1.55% versus 0.38%) but output did not. Capital accumulated faster (3.98% versus 3.02%) but output did not. And if you raise the growth rate of inputs like labor and capital, but nothing happens to the growth rate of output, then by necessity the growth rate of TFP must be lower.&lt;/p&gt;

&lt;p&gt;One possibility is that it just so happens that around 1965 when the Boomers hit the labor market, the pace of innovation or technological change or &lt;em&gt;something&lt;/em&gt; slowed down. And that it slowed down just enough to offset the increase in input growth, and left us with the same growth rate of output. You cannot rule that out. You could probably even make an okay case for this by talking about how the build-out of the electric grid or phone service or the interstate highway system were winding down starting in 1965?&lt;/p&gt;

&lt;p&gt;But that also seems kind of coincidental. A different story is that the economy kept expanding at about 3.3% per year after 1965 for some fundamental reasons like continued technological change or even continued expansion in natural resource use, and that we then tried to stuff a whole outsized generation of workers into that same economy (along with extra buildings so they’d have a place to sit). Like “Okay, your parents own the company so we have to find &lt;em&gt;something&lt;/em&gt; for you to do, so why don’t you sit here and move these papers from that file to that one.”&lt;/p&gt;

&lt;p&gt;That’s a cruel way to phrase things, but I think there is something to idea that the Baby Boom generation came along and was just too big to absorb all at once. We normally think of production expanding as you add more labor, yes. But what if that really only makes sense if you add small amounts of labor at any given time?&lt;/p&gt;

&lt;p&gt;Having an additional worker show up at your construction site probably helps move things along. Having three show up might be useful. Having twenty show up becomes a management problem. In more mathemetical terms, I’m thinking that the elasticity of output with respect to labor to a first order approximation is positive and something like, say, 0.6 or 0.7. But that “to a first order approximation” part is important. That means the elasticity holds for small percent changes in labor. There could well be second-order effects (like when the 20 people show up at the site) that cause the elasticity to plummet when the percent change in labor gets large.&lt;/p&gt;

&lt;p&gt;To belabor this further, I’m not just talking about a diminishing marginal product for labor. Having an elasticity of 0.6 or 0.7 (i.e. less than one) already incorporates a diminishing marginal product. I’m talking about a second-order effect that says the elasticity itself falls, and so the marginal product of labor diminishes even faster as you add more labor. It’s like talking about acceleration versus velocity, sort of.&lt;/p&gt;

&lt;p&gt;The drop in TFP growth starting in 1966 (ish) may reflect the fact that it is just hard to accommodate that big of a generation into the labor force over a short time. Maybe it didn’t reflect a real change in our ability to innovate at all.&lt;/p&gt;

&lt;h3 id=&quot;the-olds&quot;&gt;The olds&lt;/h3&gt;
&lt;p&gt;One reason I might be wrong about all that is what happened in 2001-18. We’re looking now at the tail end of the Boomers work life. They’re kind of at their career peaks around 2000, and then start the process of extracting themselves from the workforce. You can see the drop in both labor hours growth (from 1.55 to 0.44%) and the drop in capital growth (from 3.98 to 2.54%) that occur. But output growth does not stay around 3.3%. Instead it drops to 2.05%. With the end result that productivity growth stays low, and in fact drops a little more (from 0.75 to 0.61%).&lt;/p&gt;

&lt;p&gt;Why didn’t the effect work in reverse? Why didn’t output growth stay at around 3.3% and TFP growth go back up to something close to 2% per year as the Boomers exited? One very plausible reason is that I’m just wrong about this idea regarding the first and second order effects in 1965. What the transition to 2001-18 might indicate is that there really was some slowdown in innovation or technological change or &lt;em&gt;something&lt;/em&gt; during the 1966-2000 period that stuck. Maybe it was the drop in manufacturing as a share of economic activity, or changes in some policies, or globalization, or whatever.&lt;/p&gt;

&lt;p&gt;That could well be the case. It still leaves me wondering why we should focus hard on the period 2001-18 for the source of the slowdown in productivity growth, though. It may well be something that occurred earlier.&lt;/p&gt;

&lt;p&gt;Or, perhaps there is some fundamental asymmetry between growing and shrinking. Maybe the second-order effects that pushed down the elasticity with respect to labor in 1965 don’t work in reverse. What I mean is this. Starting around 1965, the marginal product of a new Boomer worker got pushed to zero because it was just too hard to absorb them all at once (the 20 new people on the construction site). But by 2000, we’ve had a few decades to figure out how to use those Boomers, and they each have a role and reason to be there that has positive marginal value. When they leave/retire, that lowers output. So rather than having the exit of the Boomers be reflected in higher TFP growth, it is reflected in lower GDP growth.&lt;/p&gt;

&lt;p&gt;In the construction analogy, after a few months with those 20 extra workers around, you’ve worked out a nice system, and can now slap up a house without them all sitting around. If I then come along and tell you to get rid of 10 of those extra workers, or all 20 of them, that is now going to have a big impact on your house-building. You’ve got to re-adjust &lt;em&gt;again&lt;/em&gt; to dealing with a smaller workforce. And you may no longer remember how you did it with fewer people.&lt;/p&gt;

&lt;p&gt;This might all sound like I’m working really hard to blame Boomers for current economic problems. I’m not out to get them. I’m not even convinced that this represents an economic problem (&lt;a href=&quot;https://amzn.to/35mzPfg&quot;&gt;buy my book!&lt;/a&gt;). But the sheer scale of their impact is easy to forget. You can see it in the numbers of the above table just in the hours growth. Going from 0.38% growth in hours per year to 1.55% growth is a factor of &lt;em&gt;four&lt;/em&gt;. Four times the rate of new employees and hours entering the economy every year. That’s massive.&lt;/p&gt;

&lt;p&gt;My argument depends on some kind of second-order effect, or that there isn’t a strict mechanical relationship of the number of workers to output. One way to think about this is with one of my all-time favorite papers, &lt;a href=&quot;https://ideas.repec.org/a/ucp/jpolec/v113y2005i3p582-625.html&quot;&gt;James Schmitz’s 2005 work&lt;/a&gt; on the US and Canadian iron ore industries. The point of that paper was that competition (from Brazil) lead to fundamental changes in labor productivity despite no changes in underlying technology. It’s an example of an industry that originally absorbed a lot of labor without changing output much. In this case once competition arrived they were able to shed a lot of that labor but keep output the same. No strict mechanical relatonships of labor to output.&lt;/p&gt;

&lt;p&gt;A second way to think about this is with a paper on the demographics of firms by &lt;a href=&quot;https://ideas.repec.org/p/nbr/nberwo/25382.html&quot;&gt;Hopenhayn, Neira, and Singhania&lt;/a&gt;, which I talked about in a &lt;a href=&quot;https://growthecon.com/blog/Aging-Growth/&quot;&gt;post&lt;/a&gt; a little over a year ago. Flooding the economy with new labor could lead to a flood of new firms, and new firms tend to be less productive than old firms, even if they &lt;em&gt;might&lt;/em&gt; be liable to grow faster. Again, it’s a story about slowly adapting to a surge in labor.&lt;/p&gt;

&lt;p&gt;Again, this isn’t some screed about Boomers ruining everything. It is an observation that our understanding of slow growth may need to back up a few decades, and may involve taking seriously second-order effects of labor force growth.&lt;/p&gt;

&lt;p&gt;And it got me from doom-scrollling for a while. Which reminds me:&lt;/p&gt;

&lt;p&gt;Ted Cruz is a seditious grifter who should be removed from the Senate.&lt;/p&gt;

&lt;p&gt;Happy New Year!&lt;/p&gt;

</description>
        <pubDate>Fri, 08 Jan 2021 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>When did productivity growth slow down?</title>
        <link>https://growthecon.com/blog/BLS-TFP/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/BLS-TFP/</guid>
        <description>&lt;p&gt;A few weeks ago I participated in a discourse on &lt;a href=&quot;https://www.pairagraph.com/dialogue/ee04c261817f45f39e1d0bb5f63e0b90&quot;&gt;Pairagraph&lt;/a&gt; with &lt;a href=&quot;https://twitter.com/elidourado&quot;&gt;Eli Dourado&lt;/a&gt; of the Center for Growth and Opportunity. The prompt was “Economic growth is stagnating, but there’s more to the story.” I argued that one should not interpret stagnation as implying something is wrong with the economy, and Eli argued that there was evidence of a real slowdown not just in technological growth, but in growth of welfare/well-being. You will be shocked to learn that I think my take on this subject is more accurate. But you should check out both sides of this because Eli’s position is a credible one and he does a good job of arguing it.&lt;/p&gt;

&lt;p&gt;One thing Eli and I agreed on was that looking at growth in &lt;em&gt;total factor productivity&lt;/em&gt; (TFP) was more relevant than looking at growth in GDP per capita. Growth in productivity allows you to either produce more stuff (good for growth in GDP per capita) or use fewer inputs (which is not good for growth in GDP per capita even if it is good for you or the environment). The growth rate of TFP is the better thing to focus on in asking whether stagnation matters.&lt;/p&gt;

&lt;p&gt;Here’s where I want to jump off from the original discussion. The received wisdom is that we are living through a period of slow TFP growth, and that this slowdown in TFP growth kicked in around the early 2000s.&lt;/p&gt;

&lt;p&gt;But I’m not sure that’s the whole story. When you zoom out further you’ll find that if there was a slowdown in productivity growth it started in the late 1960s or early 1970s and has continued through today. If we’re having a discussion about what went “wrong”, then we need to look &lt;em&gt;way&lt;/em&gt; earlier than the early 2000s to figure it out.&lt;/p&gt;

&lt;h3 id=&quot;measuring-tfp-growth&quot;&gt;Measuring TFP growth&lt;/h3&gt;
&lt;p&gt;The series on TFP that Eli and I reference in our discussion is from &lt;a href=&quot;https://www.frbsf.org/economic-research/indicators-data/total-factor-productivity-tfp/&quot;&gt;John Fernald of the SF Fed&lt;/a&gt; and you can download his series from that link. This series of TFP growth incorporates an adjustment for the utilization of inputs (capital and labor) based on John’s work with &lt;a href=&quot;https://ideas.repec.org/a/aea/aecrev/v96y2006i5p1418-1448.html&quot;&gt;Susanto Basu and Miles Kimball&lt;/a&gt;. The unadjusted growth in TFP he starts with is essentially just the standard BLS series on &lt;a href=&quot;https://www.bls.gov/mfp/mprdload.htm&quot;&gt;multi-factor productivity&lt;/a&gt;, which is just a synonym for TFP.&lt;/p&gt;

&lt;p&gt;In the following figure there are a few things going on. First, since I figured out how to use Plotly this fall, you get an interactive figure. You’re welcome.&lt;/p&gt;

&lt;p&gt;Second, and more important, there are three series plotted. The “Fernald Baseline” is the un-adjusted series on TFP growth. The “Fernald Util-Adjust” is that series adjusted for utilization of capital and labor. The “Original BLS” is my own calculation from the BLS data on the growth rate of TFP that Fernald’s work starts with. As you can see there are some very slight discrepancies in the Fernald Baseline and Original BLS series, but those are so insignificant I’m not worried.&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;600&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plotly.com/~dvollrath/173.embed&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;The utilization adjustment is apparent, and seems to smooth out the growth rate of TFP somewhat over time. Those big dips in the baseline data are, in part, due to low output induced by having low capacity utilization for capital or labor during recessions.&lt;/p&gt;

&lt;p&gt;What is kinda-sorta apparent from the figure is the slowdown in the growth rate of TFP. It definitely looks as if around 2010 the average growth rate of TFP was lower than during the early 2000s and late 1990s. It was as low as you see in the early 1980s, and definitely seems lower than the average rates you see in the 1950s and 1960s.&lt;/p&gt;

&lt;p&gt;With growth rates like this it is often hard to see real trends because of the noisiness. One option is to smooth the growth rates, but I find a very handy way to clarify things is just to look at the &lt;em&gt;log level&lt;/em&gt; of TFP that each of these growth rates implies over time. When you plot something in log terms (or a “ratio scale” as some people like to call it) over time, the slope of the line tells you about the growth rate, and can make trend breaks pop out.&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;600&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plotly.com/~dvollrath/175.embed&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This second figure shows those log TFP levels. To me, this makes it less obvious that 2000 was the real trend break we should be looking at. Yes, I know you’re all staring at that orange line with the “Fernald Util-Adjust” series and how it flatlines after 2000. Hang in there, and in the next section I’m going to tell you why the capacity utilization series doesn’t really change the conclusion.&lt;/p&gt;

&lt;p&gt;If you back up and look at the Fernald Baseline (blue) and BLS Original (green) series, they definitively grow faster from 1948 to around the early 1970s, and then things slow down. Yes there is some recovery in the 1990s (a higher slope) but that looks a lot like a temporary spike in a long series of slow TFP growth.&lt;/p&gt;

&lt;p&gt;To focus on that, zoom in on just the Fernald Baseline. We’d get a similar story using the BLS Original series. What I’ve done in the following figure is plot two trendlines. The first is for 1948-1972 (orange) and the second is for 1973-2019 (green).&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;600&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plotly.com/~dvollrath/177.embed&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;It is clear that the earlier trend line had a much higher slope, and hence a much higher TFP growth rate, of about 1.98% per year. The 1973-2019 trend line had growth of only about 0.87% per year. Are the trendlines perfect fits? Nope. Notice how in the early 1990s actual TFP is below trend for a while, and then there is a spike in TFP growth until about 2005 which puts actual TFP growth above trend. After 2005 the growth rate of TFP is slow, but notice that this means we’re falling almost exactly on the trendline that kicked in around 1972. The &lt;em&gt;level&lt;/em&gt; of productivity by 2019 is not very far from what we’d have guessed if we had made a projection around 1990.&lt;/p&gt;

&lt;p&gt;Why was 1972 the cutoff? Because I’m a narcissist, and that’s the year I was born. If you cut the series at any year from about 1968 to 1978 you’ll get the same story. Extremely rapid growth in the middle-20th century, and relatively slow growth in productivity in the late 20th-early 21st century. The productivity growth slowdown is not just a 21st century issue.&lt;/p&gt;

&lt;p&gt;To give a sense of the scale of the effects of the slowdown that started around 1972, take a look at the extrapolation of the orange line. That is where productivity would have been, roughly, if we had continued at 1.98% TFP growth after my birth. By 2019, TFP would have been &lt;img src=&quot;http://latex.codecogs.com/png.latex?e^{6.01}/e^{5.44} = 1.77\inline&quot;/&gt; times higher. That’s a massive difference.&lt;/p&gt;

&lt;p&gt;Hence my conclusion that if we’re going to argue about a productivity growth slowdown, we need to be arguing about what happened in the late 1960s and early 1970s and not what happened in 1999 or 2001 or 2009. We’ve been a slow-TFP growth economy for &lt;em&gt;decades&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;to-adjust-or-not&quot;&gt;To adjust or not&lt;/h3&gt;
&lt;p&gt;But what about the capacity utilization adjustment? If you back up two figures, that orange line for “Fernald Util-Adjust” just looks ugly starting in about 2005. The following figure does the same trendline breakdown for this series around 1972 as above. It has a very similar flavor, except that around 2005 things just plateau and we end up farther below the trendline by 2019.&lt;/p&gt;

&lt;iframe width=&quot;900&quot; height=&quot;600&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plotly.com/~dvollrath/179.embed&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Hover over the figure and you can see that log TFP in 2005 was 5.41, and in 2019 was …. 5.43. That’s a sum total of 2% TFP growth in 14 years, or about 0.14% per year. That &lt;em&gt;has&lt;/em&gt; to indicate there is a problem, right?&lt;/p&gt;

&lt;p&gt;Maybe. Even with the 2005-2019 slowdown, the economy isn’t that far off the trendline for 1973-2019. The gap between the actual series (blue) and the trendline (green) implies TFP is about 3% below where it “should” have been given the trend. But it’s 73% behind the 1948-1972 trend. Relatively speaking, the recent sluggish growth in TFP isn’t really important to the larger story of what happened somewhere between Stevie Wonder’s release of &lt;em&gt;Music of My Mind&lt;/em&gt; and &lt;em&gt;Innervisions&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Even if you want to contend that 1995-2005 is the right period to compare our current TFP growth to, that still leaves 1972 (or thereabouts) as the more important breakpoint. Consider the red line, which plots the trendline as if 1995-2005 became the “new normal” starting in 2005, with a growth rate of TFP of 2%. By 2019 actual TFP was 31% behind that 1995-2005 trend.&lt;/p&gt;

&lt;p&gt;But in 2019 even that “new normal” trendline was &lt;em&gt;still&lt;/em&gt; 36% behind the 1948-1972 trendline. You cannot escape the fact that the slowdown in TFP growth starting in the early 1970s was a massive event in the history of TFP growth. Explaining why TFP growth slowed down in 2005 is less imperative than explaining why it slowed down in 1972. And that is not just my narcissim or love of Stevie Wonder talking (well, okay, maybe a little).&lt;/p&gt;

&lt;h3 id=&quot;dont-you-worry-about-a-thing&quot;&gt;Don’t you worry about a thing?&lt;/h3&gt;
&lt;p&gt;This isn’t to say that the slowdown in TFP growth was a good thing. But trying to locate it in some breakdown or policy change around 2005 or the financial crisis is misguided. Conceiving of this as a early-70s change in trends rearranges my priors on a few things.&lt;/p&gt;

&lt;p&gt;First, I think it makes the argument that structural change is important for productivity growth. The early 1970s coincide roughly with the peak of American manufacturing as a share of economic activity. Is this the a demonstration of Baumol effects really kicking in? Or did the rise of competitors like Japan, and less favorable exchange rates, constrict manufacturing activity enough to make its weight felt on productivity growth?&lt;/p&gt;

&lt;p&gt;Second, even if it is due to changes in manufacturing activity, does a trend break around 1972 absolve China (WTO acession) and Mexico (NAFTA) of blame for a TFP growth slowdown? Probably?&lt;/p&gt;

&lt;p&gt;Third, is it evidence that significant financial events have lasting real effects? Did the inflation of the 70s and the Volcker disinflation do &lt;em&gt;something&lt;/em&gt; to productivity growth? You’d have to entertain that possibility, right?&lt;/p&gt;

&lt;p&gt;Fourth, is Bob Gordon more right than he thinks? Did the build-out of things like the interstate highway system, major airports, the electrical grid, and the telephone system exhaust the possibilities for significant step-ups in productivity? Should we think more about general purpose technologiges (GPTs) as drivers or bursts of productivity growth?&lt;/p&gt;

&lt;p&gt;Fifth, this puts another hole in the “market power” story of slow TFP growth. None of the series I see on this suggest any kind of prima facie case for market power changing until well after this slowdown starts in the early 1970s. Might one make the case that market power is a consequence of slow TFP growth, and not a cause?&lt;/p&gt;

&lt;p&gt;Sixth, demographics matter even more than I thought? The late 1960s/early 1970s coincide with the flood of Baby Boomers into the labor market. Are the returns to experience much more severe than we think from Mincer regressions, and so their entry lowered productivity growth before creating a spike in the late 90s as they really reached their peak?&lt;/p&gt;

&lt;p&gt;Seventh, is it possible that &lt;em&gt;Innervisions&lt;/em&gt; was so good that people no longer felt it was worth trying to innovate? Once you have that album in your life, is there a reason to ask for more?&lt;/p&gt;

&lt;p&gt;I have no answers to these questions, and I probably have more. If we’re looking too closely at the early 2000s we are probably missing the larger story. Don’t let recency bias narrow the field of inquiry!&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/RxsBc5p-dPU&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
</description>
        <pubDate>Mon, 07 Dec 2020 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>The Silicon and Industrial Revolutions</title>
        <link>https://growthecon.com/blog/Silicon-Valley/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Silicon-Valley/</guid>
        <description>&lt;p&gt;You can see this post as a way of thinking about &lt;em&gt;anything&lt;/em&gt; other than …. whatever real life has going on right now. And a warning that I posted this without a real close edit, because otherwise it would be another month before it saw the light of day.&lt;/p&gt;

&lt;p&gt;I read &lt;a href=&quot;https://amzn.to/31RI1Sb&quot;&gt;Making Silicon Valley&lt;/a&gt; by Christopher Lecuyer this summer. It’s a fairly straightforward business history of the origins of Silicon Valley, stretching back in time prior to my own vague notion of “something something Fairchild Semiconductor”. I would not recommend it as a casual read, it is very much a “and then this happened” slog through company origins, contracts, and inventions. That said, it is addressing some real historical questions about the role of military contracts and the presence of Stanford in fostering the Silicon Valley of the late 1970s/eary 80s.&lt;/p&gt;

&lt;p&gt;I found the book far more interesting for the somewhat casual asides about what motivated various company founders and inventors, and what led to the concentration of so much activity in that area. As source material for thinking about agglomeration and spillovers, the book has a lot to say. Beyond that, I found myself thinking that Lecuyer was implicitly making a very Joel Mokyr-ian argument that it was ideology and culture that drove this particular silicon revolution.&lt;/p&gt;

&lt;p&gt;It also reinforces this idea (which I tend to associate with Mokyr as well) that these kind of industrial revolutions are dependent on small networks of capable tinkerers, and not on either the average level of human capital or on a few heroic innovators. While all the names you’d expect are there (e.g. Shockley, Moore), my impression of their importance was significantly &lt;em&gt;deflated&lt;/em&gt; by Lecuyer’s book.&lt;/p&gt;

&lt;h2 id=&quot;a-overly-simplified-history&quot;&gt;A overly simplified history&lt;/h2&gt;
&lt;p&gt;To give you an idea of the scope of what the book covers, I’ll give you my own 10-cent summary. It starts with the formation of local vacuum tube companies in the San Francisco area in the 1930s, in particular Eitel-McCullough. Those two were amateur radio hobbyists, and starting making tubes to service that community. This company became a central node of the network of capable mechanics and engineers that would evolve over time and spawn most of the important firms and innovations.&lt;/p&gt;

&lt;p&gt;World War II created massive demand for vacuum tubes of all types. By the way, I am committing significant technological heresy here by using “vacuum tube” as a catch-all for the products Eitel-McCullough were producing. But this review isn’t about the technology itself, but the process that led to it. And to add another “by the way”, if you read the book you’re going to want Wikipedia open at all times to look up what the hell a klystron is.&lt;/p&gt;

&lt;p&gt;Firms connected to Eitel-McCullough as suppliers, like Litton Engineering, emerged in this period as well. They in turn sponsored new firms like Varian Associates, and what you really had by the early to mid 1950s was “Vacuum Valley”. What will be important for the story below is that these firms required a host of specialized equipment that was provided by smaller firms in the area, and thus the Vacuum Valley had at this point a tightly integrated network of engineers available to be leveraged in other ways.&lt;/p&gt;

&lt;p&gt;Vastly over-simplifying, vacuum tubes are just electrical switches, and so it became possible to think of other ways to do electrical switching, like using semiconductors. This is where Shockley Semiconductor appears in the story, although others like Hewlett-Packard were also working on semiconductors. Regardless, you now get a second wave of expansion as semiconductors become the electrical switch of choice, and the network of firms that grow out of Shockley includes Fairchild Semiconductor, which becomes its own massive node in that network. The most recognizable descendant of Fairchild is Intel. All of these firms took advantage of the engineering network of the Vacuum Valley, not just to provide equipment but to make crucial innovations.&lt;/p&gt;

&lt;p&gt;The larger point to take away from this tiny history is that the network &lt;em&gt;preceded&lt;/em&gt; the breakthroughs, not the other way around.&lt;/p&gt;

&lt;h2 id=&quot;iron-steel-and-silicon&quot;&gt;Iron, steel, and silicon&lt;/h2&gt;
&lt;p&gt;There is no question that some individuals played outsized roles in the development of Silicon Valley. Eitel, McCullough, Litton, Varian, and others in the first phase built firms from basically nothing. William Shockley won a Nobel prize for a reason. Fortunately for your iPhone, he was also a major asshole, but we’ll get to that. The guys who left Shockley to found Fairchild included people that would have an argument to be on a Mt. Rushmore of Silicon Valley: Robert Noyce, Gordon Moore, Jean Hoerni. If you were looking for “the” innovation that created Silicon Valley, then Hoerni’s creation of the planar process for creating transistors in silicon is probably it. If you want an analogy with the original Industrial Revolution, then Shockley is roughly Newcomen, and Hoerni is roughly Watt.&lt;/p&gt;

&lt;p&gt;But littered throughout Lecuyer’s book around these individuals are references to all the innovations and improvements made by the network of engineers working in the Valley in these decades.&lt;/p&gt;

&lt;p&gt;Let me just focus on Fairchild and their contribution to give you a flavor for what I mean:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Newly available historical materials … the shaping of silicon technology … was a group effort rather than the creation of ‘heroic’ individuals such as Noyce. (p. 130)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;…their first task was to build a strong technical and management team. … The founders also recruited local electronics technicians. Those who had worked in the Peninsula’s tube industries brought with them knowledge of chemical handling, glass working, and vacuum techniques. (p. 139)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;… designed the equipment needed for device development and eventual production, and outsourced its construction to local machine shops. (p. 143)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Fairchild’s engineers also developed a radically new planar component, the integrated circuit. (p. 155)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;It was Last and his engineers … who made the revolutionary step of engineering and fabricating planar integrated circuits. (p. 157)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Like vacuum tube corporations, Fairchild Semiconductor was dependent on a highly skilled workforce to control complex manufacturing processes and design advanced products. (p. 163)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;In addition, it [Fairchild] trained hundred of engineers and technicians in these new techniques. (p. 167)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I could go on and on with quotes like these from Lecuyer’s book. Every advance is shepherded into existence by a small group of skilled engineers, perhaps with a single individual named as the motive force or originator of an idea. But the success of all these inventions - transisitors, integrated circuits - is the continual series of improvements to production techniques and performance that were made by the unnamed engineers of the Valley.&lt;/p&gt;

&lt;p&gt;Which is why my mind went to Mokyr’s work. In &lt;a href=&quot;https://amzn.to/33YHWiq&quot;&gt;The Englightened Economy&lt;/a&gt; this is one of his themes. Chapter 3 of that book is about “Useful Knowledge and Technology”, and discusses the relative importance of captial-S science versus incremental improvement.&lt;/p&gt;

&lt;p&gt;A few items from Mokyr to compare to the quotes regarding Silicon Valley:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;But the spirit of mechanical improvement through better access to knowledge is symbolized by many other figures whose mechanical aptitude and ability to tease out every drop of economic value out of what they knew never ceases to astonish us. (p. 55)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tacit artisinal &lt;em&gt;savoir-faire&lt;/em&gt;, experience-driven insights, trial and error, and serendipity drove many of the eighteenth-century inventions, especially in mechanical engineering and iron and coal, far more than any solid scientific base. (p. 60)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It’s not that during either revolution (Industrial or Silicon) the people at work were blind to scientific principles, but knowing them doesn’t necessarily get the efficiency of your steam engine any or yield from your silicon wafers any higher. For that you need to do the thing, and by “you” I mean a small cadre of skilled “mechanics” for lack of a better term. Mokyr uses the example of John Smeaton, known for no specific invention in particular, but who developed much more efficient water mills, among his many very-important-but-not-notable accomplishments.&lt;/p&gt;

&lt;p&gt;But do not take the Silicon or Industrial revolution to mean that it is the mass of workers who are responsible for these improvements.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;… the Industrial Enlightenment was not the realm of a few heroic inventors and engineers, but neither was it a mass phenomenon that included the working class. It was a minority affair, confined to a fairly thin sliver of a technological elite of well-trained and often literate men. (p. 57)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is something that Lecuyer doesn’t speak to head on, but it’s lurking in the background of his entire book. Silicon Valley was built by a small group of engineers and technicians that revolved around this geographic area and its corporations. The origin of that thin sliver of the well-trained was the vacuum tube industry.&lt;/p&gt;

&lt;p&gt;As Mokyr notes, it is probably impossible to separate the causation between science and practical know-ho, or to separate the causation between flashes of individual insight and the boring accumulation of process improvements. Lecuyer’s book doesn’t provide proof one way or the other. I was just more struck by symmetric the two situations were in this respect.&lt;/p&gt;

&lt;p&gt;I think the tendency is to lean on the stories of individual insights and singular inventions. They are better stories, after all. There is a reason that James Burke’s &lt;a href=&quot;https://amzn.to/2POzyJU&quot;&gt;The Day the Universe Changed&lt;/a&gt; is such compelling TV. And I’ve always read Mokyr, despite his acknowledgement that there is a role for such individual moments, as pulling hard in the other direction to try and correct our overall outlook on what drove innovation, and ultimately economic growth, in the long run.&lt;/p&gt;

&lt;h2 id=&quot;nocal-baby&quot;&gt;NoCal, baby&lt;/h2&gt;
&lt;p&gt;So Joel Mokyr is really smart, and the history of Silicon Valley is consistent with his views on how industrial revolutions work. But the other element of Lecuyer’s book that stands out is the pure contingency involved in Silicon Valley evolving where it did. Remember that in the 1930s-50s when the vacuum tube industry and then the nascent semiconductor industry were developing, there was &lt;em&gt;no question&lt;/em&gt; that the beating technological heart of the U.S. was located in the Northeast. In 1948 you would have placed a more money on Rochester, N.Y. than San Francisco being the home of an innovative electronics industry.&lt;/p&gt;

&lt;p&gt;What put this network of capable engineers in northern California rather than upstate New York. Have you been to either place in February? Lecuyer cites numerous examples of how it was simply a case of people preferring to live around Santa Clara rather than out east that helped Silicon Valley develop. The geographic advantages of Northern California didn’t &lt;em&gt;cause&lt;/em&gt; smart engineers to emerge there, but they did ensure that the smart engineers that did emerge &lt;em&gt;didn’t leave&lt;/em&gt;. If you were a sharp engineer in Indianapolis in 1950 and RCA came calling, you probably packed up and moved to New York. But when RCA (and Westinghouse and GE and ….) tried to poach these engineers from Silicon Valley - and they did repeatedly - these guys stayed put because Northern California is delightful. And at that point, &lt;em&gt;not&lt;/em&gt; a housing nightmare.&lt;/p&gt;

&lt;p&gt;This goes all the way back to the vacuum tube origins of Silicon Valley. Many of the engineers at Eitel-McCullough, Varian, and Litton ended up working in the East during World War II, either as employees of eastern firms, or as representatives for their California-based firms. But:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;They longed for more congenial and familiar surroundings. The sentiment was not specific the Varians and their friends. It was shared by many western engineers who had moved to the East Coast in the late 1930s and during World War II. Most of these men desired to go back to the West and were afflicted by what was often called at the time “Californiaitis” - the intense desire to relocate to California.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Motivated in part by a similar attachment to California, and also to help care for his ailing mother, Bill Shockley decided to open up his semiconductor firm in Mountain View. This might have been just another example of NoCal keeping the local boys home, but a second example of contingency in the development of Silicon Valley came from his choice. Turns out Shockley was kind of an asshole to work for. He apparently tried to use lie detectors more than once on his employees, among other stories.&lt;/p&gt;

&lt;p&gt;This led to a group of his top engineers - including Hoerni, Moore, and Noyce - to leave the company and set up on their own. They were funded by Fairchild Camera, and hence Fairchild Semiconductor was born. One of their great disagreements with Shockley was over the technical direction to take semiconductors, and it is arguable that had they not left, the arrival of integrated circuits would have been delayed or lost. You’ll have to leave that contention to someone who knows more about the actual engineering than me. But the combination of Shockley’s poor management style combined with the insistence of the Fairchild group that they stay in Northern California meant that the pool of engineers and knowledge stayed local to the area.&lt;/p&gt;

&lt;p&gt;I think it is hard to understate how important it was that as new firms hived off and split from existing ones - including from Fairchild, which spawned numerous children - they &lt;em&gt;stayed&lt;/em&gt; in Northern California. And while some of that was for obvious economic reasons like the availability of engineers, a lot of it was also based purely on geographic preference.&lt;/p&gt;

&lt;p&gt;The origin of the agglomeration economies that we think lie behind the relative productivity of particular cities may well be random. Beyond that origin, Lecuyer’s book provides some ideas for &lt;em&gt;how&lt;/em&gt; agglomeration economies work, and it is very much about the informal social networks formed that pass around tacit knowledge.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Beneath this atmosphere of intense and often ruthless competition was an undercurrent of information sharing. Engineers involved in MOS [metal oxide semiconductors] startups exchanged process and design data with engineers in other firms in an informal way. Most MOS engineers face the same difficult task of developing and stabilizing complex manufacturing techniques. Any information that would help them solve the numerous process issues that they were encountering was welcome. … A web of previous associations also facilitated information sharing. Most of the MOS engineers had worked for other corporations before …. At these firms they built friendships … These previous associations made it easy to contact engineers at other firms and ask their advice. (p. 275)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bars also fostered the exchange of information among engineering groups. In the first half of the 1960s engineers and managers at Fairchild and other silicon corporations on the Peninsula had developed the habit of meeting after work at a local bar. (p. 275)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;… the MOS community on the Peninsula developed a repertoire of process “tricks” that were known only in the area. … In contrast, MOS firms located outside Northern California were not plugged into these networks and did not benefit from their shared knowledge. (p. 275)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To draw this back to the Mokyr work and the Industrial Revolution, we’re back to the idea that the “Tacit artisinal &lt;em&gt;savoir-faire&lt;/em&gt;, experience-driven insights, trial and error, and serendipity” were as important as any scientific insights in driving innovation. But again, this was a thin sliver of highly skilled engineers circulating in a small geographic area from firm to firm, not a body of knowledge spread out across the entire workforce.&lt;/p&gt;

&lt;p&gt;None of this changes the underlying idea in growth economics that it is innovations and invention that drive growth in the long run. But the similarity of the Silicon Valley experience to how Mokyr describes the Industrial Revolution experience does suggest that this innovation and invention is less a function of economy-wide aggregate features (e.g. demographics, trade) and more on niche groups of innovators embedded in specific places and cultures. Put it this way, my Bayesian posterior on the origins or economic growth took a step in Mokyr’s direction after reading Lecuyer.&lt;/p&gt;

&lt;p&gt;You could also file this as an example of the idea that it is better to concentrate your investment and R&amp;amp;D (and education?) rather than making it broad-based. For a couple of other posts I did thinking along those lines, see &lt;a href=&quot;https://growthecon.com/blog/should-developing-countries-try-to-create-a-business-elite/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://growthecon.com/blog/focused-or-broad-based-growth/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I’m also wondering if this should make me revise opinion on how robust growth is in the long run? If growth depends on some contingent factors leading to niches of innovation, then wouldn’t we expect that to fail every now and then? Or is this where the non-rivalry of the the production processes - once they are developed - kick in a la Romer and save us?&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Aug 2020 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Economic impacts of the coronavirus - part 3/n(?)</title>
        <link>https://growthecon.com/blog/Labor-IO/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Labor-IO/</guid>
        <description>&lt;p&gt;If you’re wondering what I’m attempting to do in these posts, then join the club. I’m just sort of grasping around for a way of thinking about the aggregate impacts of the shutdowns that takes into account the fact that it will hit particular industries directly (e.g. restaurants) but that this will have ripple effects on other sectors. The prior posts (&lt;a href=&quot;https://growthecon.com/blog/IO-Tables/&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://growthecon.com/blog/Base-IO/&quot;&gt;here&lt;/a&gt;) were building up some understanding of a baseline model to do this.&lt;/p&gt;

&lt;p&gt;The big problem with the baseline model is the fact that it assumes a lot of flexibility in the economy, especially in terms of labor moving around between industries in response to productivity or demand shocks. We’re not seeing the kind of perfect flexibility the baseline model assumes. We are seeing &lt;em&gt;some&lt;/em&gt; flexibility, as Amazon, Costco, and other firms are hiring even as many industries are laying people off. But there is nowhere close to enough of this new hiring to offset the massive job losses that have occurred. We’re at 10 million UI claims in the last two weeks as of today.&lt;/p&gt;

&lt;p&gt;Like a lot of macro models, the baseline version I started with is useful for thinking about relatively long-run changes when the frictions (search and match, for example) have had time to work themselves out. But I think I can still leverage this baseline model to get some idea of the short-run impacts by ignoring some of it and then making some simplifying assumptions of my own.&lt;/p&gt;

&lt;h3 id=&quot;the-industries&quot;&gt;The industries&lt;/h3&gt;
&lt;p&gt;To explain, let me start with the input/output structure. I’m going to play around with fifteen industries (okay, 17, but the last two are tiny and mainly there so that things add up). I could do this for 71 or (God forbid) 405 industries using I/O tables provided by the BEA, but this is sufficient to get the idea and calculate some effects.&lt;/p&gt;

&lt;p&gt;You can see the 15 main industries and some summary information in the following figure. Yes, that’s just a clip from a spreadsheet, which you can find &lt;a href=&quot;https://www.dropbox.com/s/sk1o0xd8omjrbll/IO_sim.xlsx?dl=0&quot;&gt;here&lt;/a&gt; if you want to play with it. This data is all from 2018 - I know, I know - but that is the latest version of the full I/O tables you can get. For my purpose of seeing how things spread around the economy, I’m okay with that. I’m not trying to give you a precise estimate of GDP in the 2nd quarter of 2020.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/IOsetup.png&quot; alt=&quot;Industry information&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first column shows the share of “final use”, which is another way of referring to GDP. Final use of an industry’s output is that output which is not used as an intermediate good by some other industry. The sum of final use across industries adds up to GDP. Agriculture constitutes 0.3% of GDP, and manufacturing is 9.6%, for example.&lt;/p&gt;

&lt;p&gt;The second and third columns show the Domar weight for each industry, which I explained in the prior post. It’s calculated twice as a check on myself. Once calculated the normal way, by dividing gross output of an industry (Q) by GDP. The second time is calculated by using the I/O matrix itself, and this was just to make sure I wasn’t making some mistake with that matrix. If you take a look at the Domar weights, you can see which industries have a lot of connections as suppliers to other industries. Manufacturing, for example, has a Domar weight of 29.2% even though it is only 9.6% of GDP. That is because manufacturing produces a lot of output that is used as intermediates by &lt;em&gt;other&lt;/em&gt; industries, so its influence on the economy outweighs its final use. Retail, on the other hand, has a Domar weight of 8.3% compared to a share of GDP of 7.5%, not much different. That is because retail isn’t used much as an input by &lt;em&gt;other&lt;/em&gt; industries.&lt;/p&gt;

&lt;p&gt;Following that you can see the total final use and gross output of each industry. And next to those in the final columns are the payroll of each industry (labor compensation as reported in the I/O accounts) and the number of employees (in thousands, which I pulled from a different BEA account).&lt;/p&gt;

&lt;h3 id=&quot;the-shock&quot;&gt;The shock&lt;/h3&gt;
&lt;p&gt;I said I was going to ignore some of the baseline model in order to make sense of the current shock. I’m going to shove through an exogenous drop in final use spending on a few industries (e.g. art, entertainment, and food service) and then &lt;em&gt;ignore&lt;/em&gt; that in the baseline model this spending would end up being done on other industries. In the baseline model there is no place for consumers money to go other than spending on final use goods or services from the industries. So if you spend less on food service, you would spend that money in the retail industry, for example.&lt;/p&gt;

&lt;p&gt;What I’m doing is assuming that you can just not spend that money. I’m allowing people to have a bank account, or a mattress, or a shoebox, or whatever, and to just stop spending as much. If people spend less on goods and services, GDP will shrink. This is all pretty old school Keynsian cross stuff. And for the purposes of evaluating the effect of a massive spending shock over the horizon of a couple of weeks, I’m good with that. We’re well within the window of time when it makes sense that things like relative prices, wages, and labor allocations across industries aren’t able to adjust. If you aren’t comfortable with that, I could also introduce a “household production” industry into the mix which people spend resources on, but which doesn’t get added up as part of GDP. The drop in spending on food service and other industries would be matched by an increase in “spending” on home production.&lt;/p&gt;

&lt;p&gt;Either way, measured GDP will fall. What is more interesting to me here is the impact of these immediate spending shocks on the gross output of &lt;em&gt;other&lt;/em&gt; industries. When we all spend less at restaurants and hotels, that impacts the industries they use like wholesalers, professional services, and finance. And that in turn impacts their suppliers, which in the restaurant example you might imagine includes the agricultural sector.&lt;/p&gt;

&lt;p&gt;The gross output of each industry is going to be affected negatively by this spending shock, and the size of the negative effect is going to depend on how tied together they are by the I/O matrix. Without my Keynsian-like assumption, there would be some countervailing force propping up other industries as spending shifted from restaurants towards other areas. That could well be part of a response. We already see that some retail institutions (Amazon, some grocery stores) are seeing increased activity. You could play with that in the spreadsheet if you want.&lt;/p&gt;

&lt;h3 id=&quot;the-effect&quot;&gt;The effect&lt;/h3&gt;
&lt;p&gt;I pushed some numbers through this, and the figure below shows what I’m getting. I assumed that spending on retail fell by 50%, on arts/entertainment/food service by 75%, and on other services by 75%. This is nothing other than gut feel. This is a back of the (very large) envelope stuff. The column showing these percent changes in outlined in red in the figure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/IOeffect.png&quot; alt=&quot;Effects of shock&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What follows are the implications. First comes the absolute change in final use spending in each industry. That’s 766 billion less in retail spending, 944 billion less on arts/ent/food, and 488 billion less on other services. Next comes the impact on &lt;em&gt;all&lt;/em&gt; the industries due to this shock to final use spending. The “Chg Gross Output” column takes the spending shock and pushes it through the I/O matrix to figure out the impact on each industry due to the logic I explained above.&lt;/p&gt;

&lt;p&gt;Gross output in agriculture falls by 24 billion, and in mining by 26 billion, for example. You get big effects in manufacturing, with a drop in 287 billion, in finance with a 388 billion hit, and in professional services with 415 billion. Also notice that in retail, arts/ent/food, and other services, the drop in gross output is &lt;em&gt;bigger&lt;/em&gt; than just that from the drop in spending. The ripple effects from other industries come back to haunt them further.&lt;/p&gt;

&lt;p&gt;Next to the absolute change in gross output is the percent change in each industry, giving you a better idea of the shock to each. No one really escapes here, except perhaps education/health, with only a drop of 0.2%. This small effect is due to the fact that education/health isn’t a big &lt;em&gt;supplier&lt;/em&gt; of intermediate goods to other industries, and so lower demand for things like retail don’t really impact this industry much.&lt;/p&gt;

&lt;p&gt;We can now get to the additional simplifying assumptions I am making to parse through the effects. First, I’m assuming that the share of industry gross output used on payrolls stays constant, as if the industry had a Cobb Douglas production function. This means that payrolls scale up and down with gross output, or that the percent change in total payroll in an industry is the same as the percent change in gross output. This is the last column in the above figure.&lt;/p&gt;

&lt;p&gt;The second assumption is that within an industry the wage is sticky. If the wage is sticky, then any drop in payroll has to be accomplished by firing people. So the percent change in employment in an industry is &lt;em&gt;also&lt;/em&gt; the same as the percent change in gross output. This is in the second to last column of the figure.&lt;/p&gt;

&lt;p&gt;For retail, this implies a drop in employees of 7,336,000, and in arts/ent/food a drop of 1,454,000. Other services lose 4,145,000 workers. But note that professional services sees a substantial drop of 1,802,000, all because of the ripple effects of the initial spending shocks. There are hundreds of thousands of jobs lost in other industries like manufacturing and finance. None of these should be taken too seriously, as again I’m just doing back of the envelope stuff here.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/IOaggregate.png&quot; alt=&quot;Aggregate&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I can aggregate all this as well. The last figure here shows those aggregations. GDP falls by 11%, which is entirely due to the assumed collapse in final use spending in those three industries. There is nothing magic about getting that number, but I did choose the shocks to get something like this, as it jives with some reports about the size of the drop in GDP we might expect over the next few months. Gross output drops by 10%, in line with GDP, and payrolls by 11%, neither of which are surprising given the assumed drop in GDP.&lt;/p&gt;

&lt;p&gt;Total employment in this scenario falls by 16,886,000, which is 12% of employment in 2018. That’s not something I was trying to hit, but it is line with reports that the unemployment rate could jump by something in that neighborhood. We’re already at 10 million UI claims, so the question may be whether the negative shocks I threw in the spreadsheet are large enough.&lt;/p&gt;

&lt;p&gt;What you can play with in the spreadsheet are also stimulus scenarios. Be careful here. The stimulus involves very little spending &lt;em&gt;on&lt;/em&gt; government services directly, but instead is mainly transfers by the government to others to spend on any industry they like. So don’t add a big percent increase in the “Government” final use line. Instead add a positive percent to industries you think people will spend UI benefits or the $1200 checks on.&lt;/p&gt;

&lt;h3 id=&quot;doing-it-right&quot;&gt;Doing it right&lt;/h3&gt;
&lt;p&gt;I can’t emphasize enough that this is not some kind of calibrated forecast of what is going to happen in Q2 or Q3 of this year. It is solely an exercise in seeing how &lt;em&gt;some&lt;/em&gt; kind of shocks will permeate throughout the entire economy, even if they are centered on only a handful of industries.&lt;/p&gt;

&lt;p&gt;If you &lt;em&gt;did&lt;/em&gt; want to do something more accurate, what else would you have to do? I can think of several important ones.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Expectations. It’s not like the pandemic is a secret, so people are presumably adjusting their spending on other industries in &lt;em&gt;anticipation&lt;/em&gt; of the possible effects this year. For example, businesses may be lowering capex because they don’t think demand will materialize until end of this year. That would act like another spending shock to manufacturing or construction. Workers who are worried about getting laid off in the future will pull back on spending as well.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Payrolls and spending. I’m not enforcing any relationship between the drop in payrolls and the drop in spending. If my little exercise is the “through mid-April” forecast, then you have to think through how the drop in payrolls will influence spending across industries in the “mid-April to mid-May” period, and so on.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Relative price changes. I didn’t say it explicitly, but this little exercise assumes that the relative prices of industries don’t change. If retail locations slash prices to salvage &lt;em&gt;something&lt;/em&gt; out of the next few weeks, then this may get people to substitute spending towards them. Although perhaps lockdowns prevent this from doing anything about it?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Industry substitutions. Similar to above, if relative prices change then industries may decide to spend more on cheaper intermediates and less of more expensive ones. That changes the I/O matrix. I’m assuming the matrix stays constant, or that the “recipe” each industry follows for production stays constant. That may not be a bad assumption for small shocks, but is probably wrong for large shocks like these.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A lot of things missing, as you can tell. The farther forward you want to forecast, the more things my simplistic model is going to get wrong. But I find the simplistic model useful just for thinking about the rough scale of the shocks occurring and how they influence the whole economy. We’re starting to see papers coming online that are doing more sophisticated macro modeling of the impact of the virus, which from my very brief scan of intros are taking at least some of these effects into account. Those will be helpful for thinking about how long the dip will last and how significant the rebound will be, which my little spreadsheet has zero information about.&lt;/p&gt;

&lt;p&gt;Stay safe. Stay home. Wash your hands. And you should probably wear a mask.&lt;/p&gt;
</description>
        <pubDate>Thu, 02 Apr 2020 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Economic impacts of the coronavirus - part 2/n(?)</title>
        <link>https://growthecon.com/blog/Base-IO/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Base-IO/</guid>
        <description>&lt;p&gt;There isn’t a real question about there being severe negative impacts of the virus on employment, household finances, or the overall growth rate. What I’m after here is trying to understand how shocks (and what kind of shocks?) to some industries ripple through the economy to influence others. For example, when you shut down hospitality businesses like restaurants, bars, and hotels, how does that affect suppliers like the food processing or farming industries?&lt;/p&gt;

&lt;p&gt;I’ve got no chance at coming up with something coherent in a small enough time frame to speak to the current round of proposed stimulus. At this point the scale of the problems are so large, and so apparent, that the kinds of things I’m thinking about here are second order. Treasury rates are historically and ridiculously low. Borrow like crazy and push a bunch of that money out to households (without a stupid phase-in) and businesses so that the former can keep paying bills and the latter can keep making payroll. Keep the circulation going. If you want to claw back some of that by making the household payments taxable later on, or make the business payments 30-year 0% loans, okay. That is less relevant than the speed of action now.&lt;/p&gt;

&lt;p&gt;Okay, throat clearing aside, let me step back into my second-order considerations of how industry shocks propagate through the economy. If you’re looking for a reason to keep reading, by the way, then I’d consider this useful information for thinking about how to build a more resilient economic stabilization system after the coronavirus has died down.&lt;/p&gt;

&lt;p&gt;In the last &lt;a href=&quot;https://growthecon.com/blog/IO-Tables/&quot;&gt;post&lt;/a&gt; I started outlining what an I/O table. That shows us how much of the output of one industry is used as an input by other industries - intermediate goods and services. Once you allow for industries to supply one another, then the concepts of gross output and GDP become distinct. Gross output is, to put it simply, GDP plus intermediates. What I noted in that post was that just knowing what the I/O table looks like doesn’t tell you how much economic activity there is. And the I/O table is necessary, but not sufficient, for figuring out how shocks to one industry influence others.&lt;/p&gt;

&lt;p&gt;This post is going to verbally lay out the implications of a baseline model. If you’re digging this, then you should look closely at &lt;a href=&quot;http://vasco-m-carvalho.github.io/pdfs/ProductionNetworks.pdf&quot;&gt;Carvalho and Tahbaz-Salehi&lt;/a&gt; and &lt;a href=&quot;http://vasco-m-carvalho.github.io/pdfs/Carvalho_JEP_2014.pdf&quot;&gt;Carvalho&lt;/a&gt;, who go into the math. I may post up a more formal version of this verbal model in the near future.&lt;/p&gt;

&lt;p&gt;Before we get going, be aware that this baseline model is only kinda-sorta going to be useful for thinking about shocks like the coronavirus, because it is going to assume a lot of flexibility in prices and employment across industries, neither of which are going to be good assumptions for short-run impacts of something like the virus shutdowns. But I don’t know how to think about a better model for the shutdowns without having this baseline to work from. So here we go.&lt;/p&gt;

&lt;h3 id=&quot;the-supply-side-in-words&quot;&gt;The supply side in words&lt;/h3&gt;
&lt;p&gt;Imagine that some industry A experienced a 10% decline in its total factor productivity. For the same amount of capital, labor, and intermediates its real production today is only 90% of what it was yesterday. What is the effect on total GDP?&lt;/p&gt;

&lt;p&gt;That depends on how important the industry was to begin with, of course. You might be tempted to say that the importance could be measured by the share of GDP (value added) accounted for by industry A. If industry A’s value added was 15% of GDP yesterday, then you might predict that GDP would be lower by .1 times .15 = .015, or lower by 1.5% today. And the rough intuition is right that the “bigger” the industry, the more consequential a drop (or increase) in productivity in that industry is for GDP.&lt;/p&gt;

&lt;p&gt;The problem is that the share of GDP is not the right way to measure the impact of industry A, because industry A might be a supplier to other industries. If their productivity goes down, then there are fewer products from A flowing to industries B, C, D, … and Z. And thus those industries cannot produce as much today as they did yesterday. And therefore the output of &lt;em&gt;all&lt;/em&gt; of those industries will fall, and the actual impact on GDP will be more severe than the 1.5% we just calculated.&lt;/p&gt;

&lt;p&gt;The I/O table I mentioned in the last post allows us to figure out the final effect of the productivity shock to industry A by working through the ripple effects on B, C, D, … and Z. The I/O table tells us how much spending on intermediates by B, say, comes from industry A. The larger this share, the bigger the effect on B’s production, and vice versa. And it doesn’t stop there. Because if B is a big supplier to C, then when A’s productivity falls, B’s production falls, and hence C’s production falls as well. Even worse, if C is a big supplier to A, then A’s production is going to fall even further, meaning B’s falls again, and so on.&lt;/p&gt;

&lt;p&gt;We aren’t doomed. Using the I/O table we constructed the &lt;em&gt;Leontief inverse&lt;/em&gt; in the last post, which is essentially the solution to following all of these paths throughout the economy. It tells us the final effect of the productivity shock to industry A (or to any industry) on all other industries. We can combine that with how much final consumers like to buy the products of industry A to come up with the right way to measure the impact of industry A on the whole economy.&lt;/p&gt;

&lt;p&gt;Those impacts are referred to as “&lt;a href=&quot;https://www.jstor.org/stable/2228246?seq=1#metadata_info_tab_contents&quot;&gt;Domar weights&lt;/a&gt;” after Evsey Domar, the same guy from the Harrod/Domar model of economic growth and the papers on serfdom and slavery. What’s cool about Domar weights is that even though they are built from an underlying I/O table and all that, in the end they can be calculated very simply. The Domar weight for industry A, for example, is just the &lt;em&gt;gross output&lt;/em&gt; of industry A divided by GDP.&lt;/p&gt;

&lt;p&gt;Our naive calculation above (15%) was the &lt;em&gt;value added&lt;/em&gt; of industry A divided by GDP, but that understated the role of A in the economy. The Domar weight might be something like 20%, with the extra five percentage points coming from the ripple effects of A on other industries. For an industry that has very little final demand but is used as an intermediate by lots of other industries (e.g. warehousing, ocean shipping, semiconductor manufacturing, crude oil production) the actual value-added weight could be very small but the Domar weight could be huge. For an industry that is mainly final demand but isn’t a big supplier of other industries (e.g. restaurants) the Domar weight is probably very close to the share of value-added.&lt;/p&gt;

&lt;p&gt;Regardless, if we use the Domar weight of 20% for industry A, then the actual impact of the 10% drop in industry A’s productivity will lower GDP today by .1 times 0.2 = .02, or 2%.&lt;/p&gt;

&lt;p&gt;This has some interesting implications for overall GDP and the impact of productivity shocks. We’ll take those Domar weights seriously, but for the moment be naive about other aspects of the economy. In particular, we’re going to assume that the labor force and capital stock stay constant in response to any productivity shocks (hey, I told you it was a baseline model). Then you can do some math and show that the percentage change in GDP is equal to the Domar-weighted percentage change in &lt;em&gt;all&lt;/em&gt; industry productivity levels. That makes some sense, I would think. The change in GDP (since we are holding labor and capital constant) has to depend on the change in productivity of all the industries that make up the economy.&lt;/p&gt;

&lt;p&gt;Here’s the weird/cool/scary part of this. Because of the interactions between industries in the I/O table, the Domar weights need not add up to one. And this means that the effect on GDP of productivity shocks can be &lt;em&gt;bigger&lt;/em&gt; than any of the individual industry shocks. The interrelated nature of the industries is going to amplify productivity shocks beyond their initial size.&lt;/p&gt;

&lt;p&gt;Let’s take an example. If we had 3 industries A, B, and C that are all interrelated, we could easily have Domar weights for the three of them that are 20%, 60%, and 50%. And if the coronavirus or anything else were to lower productivity in &lt;em&gt;each&lt;/em&gt; industry by exactly 10% then the interrelated nature of the economy tells us that the drop in GDP is equal to .2 times .1 + .6 times .1 + .5 times .1 = .13, or 13%. No industry experiences more than a 10% drop in productivity, but GDP falls by 13%. Why? Industry B gets hit by its own 10% drop in productivity but it &lt;em&gt;also&lt;/em&gt; loses inputs from A and C, meaning its production goes down by more than 10%. And that in turn means A and C have fewer inputs, which lowers their production by more than 10%.&lt;/p&gt;

&lt;p&gt;If you think of the virus as some sort of common productivity shock across industries (or firms, or whatever) then it is their relationships with one another as suppliers and customers that create a massive economic shock in the aggregate. The more related industries are, the larger the sum of the Domar weights, and the larger the aggregate effect of the initial productivity shock.&lt;/p&gt;

&lt;p&gt;One thing you might have picked up on here is that I’ve described the effects of the productivity shocks in any industry in terms of their effect on its “downstream” customers. That is, I described how if A has a negative productivity shock, this influences B because B needs inputs from A. I didn’t speak directly about the “upstream” effects of the productivity shock in A, meaning I didn’t describe the fact that A may buy fewer inputs itself in response to its productivity shock, hurting its suppliers.&lt;/p&gt;

&lt;p&gt;The concept that changes in GDP are a Domar-weighted combination of changes in productivity by industries is usually known as “&lt;a href=&quot;https://academic.oup.com/restud/article-abstract/45/3/511/1573872?redirectedFrom=fulltext&quot;&gt;Hulten’s Theorem&lt;/a&gt;”, and holds in many more generic cases than what I’ve described. My focus on the “downstream” effects only was partly for exposition, and partly based on assumptions in the baseline model I’m working off of. There has been a bunch of work on this recently, so see things like &lt;a href=&quot;http://pages.stern.nyu.edu/~xgabaix/papers/granular.pdf&quot;&gt;Gabaix&lt;/a&gt;, &lt;a href=&quot;https://uc5832d6123d2287a8e4ddd2f84e.dl.dropboxusercontent.com/cd/0/inline2/A0R7Sfb3T_4Mil-lGIBDBo69kic-FKYnqi4nJLYV6mjPmLM3s3JtarEQPboDBV9ovo-DXg53pLw5ECtih1mfOvqf_5STzfYfIKyxJgnkeRvqxRduBJg80bubFMAEXV8UAqbQ1kujnYdVkDTuuQBWSolfTp7UhxnaLJOD7excArGIe4-w3-gZNKSD4XztnmL8ZertaCqteFrTBJmsj1ZP4u4gqVPuIiXyIuby1TbUhUYJoX48mKijbz-cm3jRbb8p2VU5tTQ8mONZP_P7xAvEfHOJf_JzzvmBACyuyRKbr8KktQMFpCsOy34k0wAvsICpNcfmPkGJ9VCDU13e9PYXbIbZ/file&quot;&gt;Baqaee and Farhi&lt;/a&gt;, or the papers I linked above to dig into the generality or non-generality of that Theorem.&lt;/p&gt;

&lt;h3 id=&quot;the-demand-side-in-words&quot;&gt;The demand side in words&lt;/h3&gt;
&lt;p&gt;Thinking through the supply side was just half the problem. And to be honest, I’m not sure that for the specifics of the corona-virus we should be thinking in terms of productivity shocks. Restaurants did not suddenly forgot how to cook when people got sick. This was more about significant changes in demand, whether those were chosen by individuals or ordered by governments.&lt;/p&gt;

&lt;p&gt;With this baseline model, think about a change in the share of their spending that people choose to do on the products of different industries. So everyone decides to decrease the fraction of their spending they want to do on industry B (e.g. restaurant meals) and increase the spending they want to do on industry A (insert toilet paper joke here). What affect does this change in the composition of demand have on an economy where A and B &lt;em&gt;and C&lt;/em&gt; are linked through the I/O table?&lt;/p&gt;

&lt;p&gt;In short, what is going to matter is how this change in demand changes the Domar weights. Those weights, recall, are based not only on the I/O relationships which capture intermediate use but also depend on final demand for products. Our change in what final consumers want to spend their money on is going to change the Domar weights.&lt;/p&gt;

&lt;p&gt;This could be good or it could be bad for aggregate output, in theory. If industry A is not a big user of intermediate goods for whatever reason, but industry B is a big user of intermediate goods, then this shift in spending could be very &lt;em&gt;bad&lt;/em&gt; for aggregate output. Why? If we decide to spend all of our money on products from industry A this creates very little “upstream” demand for intermediates from other industries, which limits their economic activity. When we spend more on industry A we’re going to push up it’s Domar weight, but not by very much.&lt;/p&gt;

&lt;p&gt;The drop in spending on industry B reduces its Domar weight directly. But because this industry uses a lot of intermediates that reduces even further the upstream demand by industry B from other industries, reducing B’s Domar weight further. And don’t forget industry C, who is standing there trying to act like nothing is happening. It’s Domar weight will be pulled down to some extent because of the change in demand for its products by both A and B (and that will feed back to the Domar weights of A and B).&lt;/p&gt;

&lt;p&gt;If industry A does not have a lot of upstream demand then the increase in its Domar weight is going to be &lt;em&gt;more&lt;/em&gt; than offset by the drop in the Domar weights of B and C. Remember from above how the Domar weights could sum to a number more than one? Here, the shift of spending from B to A is going to lower that &lt;em&gt;sum&lt;/em&gt;. And &lt;em&gt;maybe&lt;/em&gt; that will lower aggregate economic activity.&lt;/p&gt;

&lt;p&gt;Why maybe? With the demand shift we have to consider the &lt;em&gt;level&lt;/em&gt; of productivity across industries and how that interacts with the change in Domar weights. Yes, shifting spending to industry A from industry B may lower the sum of the Domar weights. But if the level of productivity in industry A is very high and productivity in B and C is very low then deciding to spend more money on A would be good for aggregate output.&lt;/p&gt;

&lt;p&gt;The ultimate effect of a demand shock from the virus will depend on (1) which industries our spending shifts into and (2) whether those industries have relatively high or low productivity.&lt;/p&gt;

&lt;p&gt;Notice that the effect of demand shocks in this baseline model are all about the “upstream” connections of an industry to its suppliers. The productivity shocks were all about the “downstream” connections of an industry to its customers. It’s not true that the distinction is that clean. Demand shocks can have upstream and downstream effects, as can productivity shocks. But in this baseline version things separate out cleanly. That said, &lt;a href=&quot;https://ideas.repec.org/p/nbr/nberwo/21344.html&quot;&gt;Acemoglu, Akcigit, and Kerr&lt;/a&gt; find evidence that shocks do tend to propagate this way. So the baseline model is not a terrible first pass.&lt;/p&gt;

&lt;h3 id=&quot;were-not-done-yet&quot;&gt;We’re not done yet&lt;/h3&gt;
&lt;p&gt;The big missing link here is that the baseline model is built on the assumption that the labor and capital supplies are held constant. And that is obviously not what we’re seeing in the short-run response to the coronavirus, where layoffs and firings are proceeding at a staggering pace. What comes next in figuring this out is shutting down the ability of labor to shift freely between industries, so that the productivity and/or demand shocks that hit the economy lead to labor being unemployed. Then the I/O network is going to tell us how the demand shock that is killing restaurants, for example, not only leads to unemployment in that industry, but propagates to unemployment in other industries that supply it. But I still need to figure that out, so stay tuned.&lt;/p&gt;
</description>
        <pubDate>Sat, 21 Mar 2020 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Economic impacts of the coronavirus - part 1/n(?)</title>
        <link>https://growthecon.com/blog/IO-Tables/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/IO-Tables/</guid>
        <description>&lt;p&gt;I’m washing my hands, avoiding crowds (even more than normal), and thinking about the economic effects of the coronavirus. There is no question there has already been a significant effect, and there will be more effects to come. I’m thinking about what those effects are, how they are distributed across industries (e.g. airlines versus trucking), and how the affected industries influence &lt;em&gt;other&lt;/em&gt; industries and consumers.&lt;/p&gt;

&lt;p&gt;I think this is going to take a few posts, as I don’t have a solid feel for how to do this. And this is going to start theoretically before I (hopefully) get to putting some numbers on things. If you’re interested in some kind of real-time estimate of the effect on GDP and the stock market, this is very much &lt;em&gt;not&lt;/em&gt; the blog for you.&lt;/p&gt;

&lt;p&gt;Let’s get some definitions out of the way. We talk a lot about GDP (&lt;img src=&quot;http://latex.codecogs.com/png.latex?Y\inline&quot;/&gt;), which is the value of all &lt;em&gt;final&lt;/em&gt; goods and services produced in a year (or quarter, or whatever time frame). But many, many transactions are for &lt;em&gt;intermediate&lt;/em&gt; goods and services. Those intermediates are purchased by one firm from another in order to produce something else. The classic example here would be a bakery buying wheat (the intermediate good) from a farmer in order to sell bread (the final good). GDP only measures the value of the bread produced. &lt;em&gt;Gross output&lt;/em&gt; (&lt;img src=&quot;http://latex.codecogs.com/png.latex?Q\inline&quot;/&gt;) would measure the value of the bread &lt;em&gt;and&lt;/em&gt; the value of the wheat.&lt;/p&gt;

&lt;p&gt;The distinction between gross output and GDP, by itself, doesn’t tell us anything about the effects of the coronavirus. But it does remind us that final goods depend on the production of intermediate goods, and so anything that disrupts the production of those intermediates will affect GDP even if nothing directly impacts our demand for those final goods and services. To trace the impact of the shocks from the coronavirus we need to understand the input/output (I/O) relationships linking producers of final goods and services to producers of intermediates.&lt;/p&gt;

&lt;p&gt;Let’s think through some ways the virus would influence the economy in our toy farmer/baker example. If everyone stays home and cooks their own food, then demand for bread falls. The baker will sell less, demand less wheat, and in turn the farmer will suffer a loss of sales. We can use the I/O relationships to tell us how a shock to final demand influences intermediate producers.&lt;/p&gt;

&lt;p&gt;On the other hand, we could have a situation where the farmer gets the virus, say, and cannot work. Then this lowers the amount of wheat produced and hence the baker cannot make as much bread. Here the I/O relationships tell us how a shock to an intermediate producer influences the production of final goods and services.&lt;/p&gt;

&lt;p&gt;Of course both of these shocks are possible, and in reality both kinds of shocks are occurring. To get my head around how big of an impact those shocks could have, I want to build up the math behind the structure of these I/O relationships. This is going to be math-heavy relative to most posts, ultimately reaching matrix algebra. I’m sorry, I don’t know any other way to talk about this stuff. I’m adapting this from notes I’ve used in the past for a grad course. I have tried to keep in some simplified examples of what I’m doing, but it can get a little hairy.&lt;/p&gt;

&lt;h3 id=&quot;the-leontief-inverse&quot;&gt;The Leontief inverse&lt;/h3&gt;
&lt;p&gt;The connection of GDP (&lt;img src=&quot;http://latex.codecogs.com/png.latex?Y\inline&quot;/&gt;) to gross output (&lt;img src=&quot;http://latex.codecogs.com/png.latex?Q\inline&quot;/&gt;) depends on the input/output relationships of all the different units of production. Input/output refers to the fact that some of the output of one unit of production (&lt;img src=&quot;http://latex.codecogs.com/png.latex?i\inline&quot;/&gt;) is used as an input by another unit of production (&lt;img src=&quot;http://latex.codecogs.com/png.latex?j\inline&quot;/&gt;). As noted, those intermediate transactions are not part of GDP. But they do determine how much gross output is necessary to produce a given amount of GDP.&lt;/p&gt;

&lt;p&gt;Let’s set up a simple example. Consider an oil drilling company that produces barrels of oil. The barrels are used by a refining company that uses them to produce gasoline. But it is also the case that the oil drilling company needs to buy gasoline in order to run their equipment. In addition, there are consumers who have final demand for gasoline, but there is no final demand for oil (i.e. no one consumes oil directly). This is more complex than the wheat/bread example, as the two industries serve as intermediate good providers for each other. But that is something we want to allow for, as most industries are going to operate both as a user and provider of intermediate goods.&lt;/p&gt;

&lt;p&gt;Let’s say that 100 barrels of oil can produce 1,000 gallons of gasoline. And let’s say that consumers demand 1,000 gallons of gasoline. But it is &lt;em&gt;also&lt;/em&gt; the case that it takes 50 gallons of gasoline to produce 100 barrels of oil. So how much oil production is there? To get 1,000 final gallons of gasoline, we need 100 barrels of oil produced. But that requires an additional 50 gallons of gas, which requires an additional 5 barrels of oil. But that 5 additional barrels of oil requires 2.5 gallons of gas, which requires and additional 0.25 barrels of oil. And so on and so on.&lt;/p&gt;

&lt;p&gt;We can construct this interaction in a little system of equations.&lt;/p&gt;

\[\begin{aligned}
	y_B &amp;amp;= 0.1\times y_G + 0 \\
	y_G &amp;amp;= 0.5\times y_B + 1,000
\end{aligned}\]

&lt;p&gt;where &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_B\inline&quot;/&gt; are barrels produced, which are equal to one-tenth of the total gallons of gas produced, as that is the demand from the refinery. The zero in the first line represents the fact that there is zero final demand for oil (no one uses oil directly, it is only an intermediate good here). The second line shows that the total gallons of gas produced are equal to one-half the number of barrels produced (that is the demand from oil producers) plus the 1,000 gallons demanded by final consumers. This is just a two-equation, two-unknown situation. It can be solved to find &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_B = 105.26\inline&quot;/&gt; is the gross output of the oil drilling company, and &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_G = 1,052.63\inline&quot;/&gt; is the gross output of the refinery. That 1,000 gallons of final demand for gas leads to an extra 52-ish gallons produced, along with 105-ish barrels of oil as intermediate good.&lt;/p&gt;

&lt;p&gt;This same logic can be extended to the case of &lt;img src=&quot;http://latex.codecogs.com/png.latex?J\inline&quot;/&gt; arbitrary units of production. Ultimately we’d have a &lt;img src=&quot;http://latex.codecogs.com/png.latex?J\inline&quot;/&gt; equation system, with &lt;img src=&quot;http://latex.codecogs.com/png.latex?J\inline&quot;/&gt; unknown gross outputs of &lt;img src=&quot;http://latex.codecogs.com/png.latex?p_j y_j\inline&quot;/&gt;, taking the final demands &lt;img src=&quot;http://latex.codecogs.com/png.latex?p_j c_j\inline&quot;/&gt; of each unit as given. This is tedious, but it is a straightforward linear algebra problem, and can be set up in matrix form. The only difference with the little example of oil and gas is that here we’re going to use values (i.e. with relative prices included) rather than raw quantities.&lt;/p&gt;

\[\begin{aligned}
	p_1 y_1 &amp;amp;= p_1 y_{11} + p_1 y_{21} + ... + p_1 y_{J1} + p_1 c_1 \\
	p_2 y_2 &amp;amp;= p_2 y_{12} + p_2 y_{22} + ... + p_2 y_{J2} + p_2 c_2 \\
	 &amp;amp;...&amp;amp; \\
	p_J y_J &amp;amp;= p_J y_{1J} + p_J y_{2J} + ... + p_J y_{JJ} + p_J c_J \\ 
\end{aligned}\]

&lt;p&gt;where recall that &lt;img src=&quot;http://latex.codecogs.com/png.latex?p_i y_{ji}\inline&quot;/&gt; is the intermediate demand by unit &lt;img src=&quot;http://latex.codecogs.com/png.latex?j\inline&quot;/&gt; for output from unit &lt;img src=&quot;http://latex.codecogs.com/png.latex?i\inline&quot;/&gt;. Depending on the level of analysis you are working with - establishment, firm, sector - you might be able to assert that &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_{ii} = 0\inline&quot;/&gt;. But we don’t have to assume this. It is okay if we think of units of production purchasing their own output to use as an intermediate good. Think of a refinery buying its own gas to run its own trucks and equipment. Now we can simplify this by building it into matrix form.&lt;/p&gt;

&lt;p&gt;Define the matrices as follows&lt;/p&gt;

\[\mathbf{q} = 
	\begin{bmatrix}
	p_1 y_1 \\
	p_2 y_2 \\
	... \\
	p_J y_J
	\end{bmatrix}
\mathbf{c} = 
	\begin{bmatrix}
	p_1 c_1 \\
	p_2 c_2 \\
	... \\
	p_J c_J
	\end{bmatrix}
\mathbf{A} = 
	\begin{bmatrix}
	\frac{p_1 y_{11}}{p_1 y_1} &amp;amp; ... &amp;amp; \frac{p_1 y_{J1}}{p_J y_J} \\
	\frac{p_2 y_{12}}{p_1 y_1} &amp;amp; ... &amp;amp; \frac{p_2 y_{J2}}{p_J y_J} \\
	... &amp;amp; \ddots &amp;amp; ... \\
	\frac{p_J y_{1J}}{p_1 y_1} &amp;amp; ... &amp;amp; \frac{p_J y_{JJ}}{p_J y_J} \\
	\end{bmatrix}\]

&lt;p&gt;The vector &lt;img src=&quot;http://latex.codecogs.com/png.latex?q\inline&quot;/&gt; captures the gross output of each unit, the vector &lt;img src=&quot;http://latex.codecogs.com/png.latex?c\inline&quot;/&gt; the final demand for each units output. The matrix &lt;img src=&quot;http://latex.codecogs.com/png.latex?A\inline&quot;/&gt; is called a “technical coefficients” matrix. The raw data for these matrices come from something called a “use table”, which are part of input/output accounts produced by statistical agencies. I’ll probably go through one of those in a future post.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://latex.codecogs.com/png.latex?A\inline&quot;/&gt; tells us how much of each intermediate good is necessary to produce one (real) dollar of additional output from a given unit of production. It takes &lt;img src=&quot;http://latex.codecogs.com/png.latex?p_2 y_{12}/p_1 y_1\inline&quot;/&gt; in purchases of intermediate good 2 to produce one real dollar of output of good 1, for example. &lt;img src=&quot;http://latex.codecogs.com/png.latex?A\inline&quot;/&gt; thus tells us the “recipe” for producing gross output.&lt;/p&gt;

&lt;p&gt;With these matrices, we can simplify our system of equations down to&lt;/p&gt;

\[\mathbf{q} = \mathbf{A}\mathbf{q} + \mathbf{c},\]

&lt;p&gt;and solve this using normal matrix operations,&lt;/p&gt;

\[(\mathbf{I} - \mathbf{A})\mathbf{q}  = \mathbf{c}\]

&lt;p&gt;where &lt;img src=&quot;http://latex.codecogs.com/png.latex?\mathbf{I}\inline&quot;/&gt; is an identity matrix, and so&lt;/p&gt;

\[\mathbf{q} = (\mathbf{I} - \mathbf{A})^{-1}\mathbf{c}.\]

&lt;p&gt;This is the matrix equivalent of our earlier example with the barrels and gas. The &lt;img src=&quot;http://latex.codecogs.com/png.latex?(\mathbf{I} - \mathbf{A})^{-1}\inline&quot;/&gt; matrix is a Leontief inverse”. It isn’t obvious here, but this Leontief inverse summarizes all of the direct and indirect effects of final demand for &lt;img src=&quot;http://latex.codecogs.com/png.latex?c\inline&quot;/&gt; on gross output &lt;img src=&quot;http://latex.codecogs.com/png.latex?q\inline&quot;/&gt;.&lt;/p&gt;

&lt;p&gt;To see what is going on, go back to the simple example involving barrels and gasoline. Write the matrix form of this as&lt;/p&gt;

\[\begin{bmatrix}
	y_B \\
	y_G
	\end{bmatrix}
=
	\begin{bmatrix}
	0 &amp;amp; 0.1 \\
	0.5 &amp;amp; 0 \\
	\end{bmatrix}
	\begin{bmatrix}
	y_B \\
	y_G
	\end{bmatrix}
+
	\begin{bmatrix}
	c_B \\
	c_G
	\end{bmatrix}\]

&lt;p&gt;where I’ve allowed both oil, &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_B\inline&quot;/&gt;, and gas, &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_G\inline&quot;/&gt;, to have some final demand. Our general setting says that we should form the Leontief inverse first, which in this case is&lt;/p&gt;

\[(\mathbf{I} - \mathbf{A})^{-1} =
	\begin{bmatrix}
	1.052 &amp;amp; 0.105 \\
	0.526 &amp;amp; 1.052 \\
	\end{bmatrix}.\]

&lt;p&gt;The entries in this table tell us the total effect of final demand, whatever that may be. For example, the upper right entry (0.105) tells us that every additional gallon of gas demanded induces 0.105 barrels of oil to be produced. We know that technically, only 0.1 barrels are necessary, but an extra 0.005 are produced because oil production requires some gasoline itself. The bottom left entry says that every additional barrel of oil demanded (if anyone wanted oil as a final good) would lead to 0.526 gallons of gas being produced, 0.5 because it takes that much gas to produce a barrel, and an additional 0.026 because that gas requires some oil itself.&lt;/p&gt;

&lt;p&gt;Given that Leontief inverse, we know that&lt;/p&gt;

\[\begin{bmatrix}
	y_B \\
	y_G
	\end{bmatrix}
=
\begin{bmatrix}
	1.052 &amp;amp; 0.105 \\
	0.526 &amp;amp; 1.052 \\
	\end{bmatrix}
\begin{bmatrix}
	c_B \\
	c_G
	\end{bmatrix}.\]

&lt;h3 id=&quot;accounting-for-shocks&quot;&gt;Accounting for shocks&lt;/h3&gt;
&lt;p&gt;Note that just knowing the matrix &lt;img src=&quot;http://latex.codecogs.com/png.latex?\mathbf{A}\inline&quot;/&gt;, and thus the Leontief inverse, doesn’t tell us how big GDP or gross output will be. It only allows us to solve for the relationship of gross output and GDP. Determining actual GDP or gross output would still depend on things like the supply of factors of production (e.g. labor, capital), the productivity of individual units of production, and the preferences of people involved. Nevertheless, this structure is still useful because it gives us the basis for understanding how to account for the interactions of different units of production.&lt;/p&gt;

&lt;p&gt;Ignoring all those other relevant factors (preferences, productivity, factor supply), let’s see a little of what we can do with the Leontief matrix.&lt;/p&gt;

&lt;p&gt;Let’s say that prior to the virus that final use of oil was &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_B = 100\inline&quot;/&gt; and final use of gasoline was &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_G = 1000\inline&quot;/&gt;, and treating these as measured in real values, that means GDP was 1,100. Gross output (again in real values) of oil was &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_B = 210.2\inline&quot;/&gt; and of gasoline was &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_G = 1104.6\inline&quot;/&gt;, for total gross output of 1314.8.&lt;/p&gt;

&lt;p&gt;If the virus meant a shock to demand for gasoline because we all stayed home to watch Netflix, we can work out the impacts. Let’s say that now &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_G = 500\inline&quot;/&gt;, but that demand for oil stays the same at &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_B = 100\inline&quot;/&gt;. This drops GDP to 600. But it also drops gross output to &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_B = 157.7\inline&quot;/&gt; and &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_G = 578.6\inline&quot;/&gt;, for a total drop to gross output of 736.3. Because of the drop in gasoline demand, oil production overall falls from 210.2 to 157.7. A full analysis would account for whether there was any impact on final demand for oil due to the virus, whether the drop in gross output in the oil industry or gasoline industry led people to get fired and hence to even lower final demand, and so on and so on.&lt;/p&gt;

&lt;p&gt;We can make this harder. What if the virus means a drop in the production of oil, say because the virus gets loose on a drilling rig in the Gulf? Let’s say that total production of oil is forced to drop from 210.2 to &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_B = 100\inline&quot;/&gt;. What happens? We have to solve this for the level of final demand such that the gross output of oil is only 100. We’re going to have to scale down everything in order to accommodate that drop in oil production. But how? There are a lot of solutions to this system such that &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_B = 100\inline&quot;/&gt;, and nothing in the Leontief inverse itself pins down exactly which solution we’d end up at. One &lt;em&gt;possible&lt;/em&gt; answer is that we have &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_B = 0\inline&quot;/&gt; and &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_G = 950\inline&quot;/&gt;, so that the 100 barrels of oil are used solely to provide final consumption of gasoline, but there is no oil left over for final use. Or, we could have &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_B = 20\inline&quot;/&gt; and &lt;img src=&quot;http://latex.codecogs.com/png.latex?c_G = 750\inline&quot;/&gt; if people really, really want to consume some oil directly.&lt;/p&gt;

&lt;p&gt;The point is that we’re going to have to account for people’s spending preferences as well in order to parse out the shocks. Which is why this is probably going to take me a long time and a few posts to figure out how to think about this right. For now, let’s pretend that I’ll be all over that project, and you’ll see more information over the next few days.&lt;/p&gt;

&lt;p&gt;Until then, wash your hands and stay the f&amp;amp;#@ home.&lt;/p&gt;

</description>
        <pubDate>Mon, 16 Mar 2020 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Knowledge diffusion and business dynamism</title>
        <link>https://growthecon.com/blog/Dynamic-Markups/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Dynamic-Markups/</guid>
        <description>&lt;p&gt;As I wait to hear if and when UH will close campus because of the coronavirus I figured it would be a more productive use of my time to type than to update websites reporting case numbers. This post has absolutely nothing to do with the virus, so if you’re looking for something to either take your mind of of it, or at least put you to sleep, then here you go. At some point I’d like to do something about the economic impact of the virus, specifically using it to think about I/O networks and such, but I haven’t figured out a good way to work through that yet.&lt;/p&gt;

&lt;p&gt;What was on my mind instead was markups, market power, and productivity, which has been on ongoing topic here. I did a few posts &lt;a href=&quot;https://growthecon.com/blog/Paradox/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://growthecon.com/blog/Paradox-2/&quot;&gt;here&lt;/a&gt; on &lt;em&gt;accounting&lt;/em&gt; for the effect of markups on productivity and GDP. One of the points of those was that given an increase in average markups, there may be a counter-intuitive &lt;em&gt;increase&lt;/em&gt; in measured productivity and GDP at the same time. If inputs are shifted from low-markup to high-markup products, this implicitly is raising the value of what we produce from the consumers perspective.&lt;/p&gt;

&lt;p&gt;Those posts took the increase in average markups as a given, however, and didn’t consider why that increase took place. Nor did it consider the dynamic consequences of that increase in markups, which might involve firms changing their decisions about how much to invest in innovation based on those markups.&lt;/p&gt;

&lt;p&gt;In my grad growth course recently we went through two papers by Ufuk Akcigit and Sina Ates (AA), which focus on the reason for why markups may have gone up, but also allow one to model the dynamic consequences of those markup changes. The &lt;a href=&quot;https://ideas.repec.org/p/nbr/nberwo/25755.html&quot;&gt;first&lt;/a&gt; paper provides a simpler model to get your head around, and the &lt;a href=&quot;https://ideas.repec.org/p/red/sed019/150.html&quot;&gt;second&lt;/a&gt; gives you all the bells and whistles.&lt;/p&gt;

&lt;p&gt;The basic story from AA is that many of the facts regarding the decline in business dynamism observed over the last 20-30 years, including the rise in markups, can be understood as a consequence of a decline in the rate of knowledge diffusion across firms. With less diffusion of knowledge, the gap in productivity between industry leaders and followers grew, which allowed for higher markups to be charged by the leaders, which in turn explains why profits rose and wages fell as a share of GDP. They also attribute the fall in firm entry rates to the decline in knowledge diffusion, as it became harder for outsiders to jump into industries. Ultimately they tie this decline in knowledge diffusion to an increase in intellectual property rights protections. Their model tells them knowledge diffusion was more important (in quantitative terms) than things like lower corporate taxes, R&amp;amp;D subsidies, or entry costs.&lt;/p&gt;

&lt;p&gt;Even if you find reasons to be skeptical of their explanation, the paper provides a way of thinking about how market power and markups interact with investments in R&amp;amp;D to jointly determine the aggregate growth rate. It’s an application of the kind of Schumpeterian growth models that Akcigit is known for, building on the body of work associated mainly with &lt;a href=&quot;http://individual.utoronto.ca/zheli/A3.pdf&quot;&gt;Aghion and Howitt&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;facts-on-markups-and-dynamism&quot;&gt;Facts on markups and dynamism&lt;/h3&gt;
&lt;p&gt;Before we get to the model and the explanation based on knowledge diffusion, let’s recap some of the facts that AA are building their model to explain. I’m going to focus on 7 here, while AA present 10 different facts, mainly just to save space and time. I did not cut and paste in all of their figures documenting these facts, and just included a few notes on each. If you’re reading this blog, my guess is that you are familiar with most of these already, and can see AA’s first paper for the specific cites and data.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Market concentration rose. The share of sales accounted for by the top 4 firms across industries rose from about 38% in 1980 to 44% in 2010.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Average markups rose. Various sources document average markups rising from around 1980 to 2010, but be aware that there are questions about whether this rise in markups is due to measurement error.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The profit share of GDP rose. This is consistent with higher markups on average, and you get an increase from around 2% of GDP in 1980 to around 14% in 2010.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The labor share of GDP went down. Consistent with the rise in profit share, from about 68% in 1980 to 60% in 2010.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The productivity gap rose. This one may not be as familiar. Roughly, the most productive firms have seen their productivity rise by about 30% from 2002 to 2011, while other firms saw their productivity rise by only about 10% in the same period.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The firm entry rate fell. Familiar to those of you interested in business dynamism. The entry rate was about 12% in 1980, and only about 8% in 2010.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The share of young firms fell. Young (less than 5 year old) firms employed about 18% of workers in 1980, but only about 8% in 2010.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;where-do-markups-come-from&quot;&gt;Where do markups come from?&lt;/h3&gt;
&lt;p&gt;What AA want to do is provide a unified explanation for all seven of these facts (actually, all ten facts in their paper) without taking any of them as a given. Everything flows from the basics of how firms compete and set markups. Start by thinking about a single product (e.g. USB chargers, or dishwashers, or payroll processing services). For that product, imagine there are two firms who can produce it. Those two firms are in Bertrand competition with one another. They each choose the price they will charge, and then let the customers sort out how much to buy from each firm. The firms are aware they are in competition with the other, and so set prices strategically to maximize profits, knowing how the other firm will respond.&lt;/p&gt;

&lt;p&gt;In other settings this can lead to all sorts of interesting behavior, but for AA things work out in a pretty straightforward manner because firms can have different marginal costs. If firm A has a marginal cost of 2, and firm B has a marginal cost of 3, then if firm A charges anything less than 3, firm B cannot match the price because it will incur a loss. So firm A will charge anything less than 3 and get &lt;em&gt;all&lt;/em&gt; the customers. Firm A wants to maximize profits, so it will charge 2.999999, take all the business, and hence charge a &lt;em&gt;markup&lt;/em&gt; of approximately 3/2 = 1.5. More generally, the markup charged by a firm selling any given product is equal to the ratio of the marginal cost of the &lt;em&gt;trailing&lt;/em&gt; firm (e.g. 3) to the marginal cost of the &lt;em&gt;leading&lt;/em&gt; firm (e.g. 2).&lt;/p&gt;

&lt;p&gt;Firm A thus earns profits. As with any model involving markups, those profits depend on the total expenditures on the product they sell (so market size matters) and the markup itself. For the example in the prior paragraph, Firm A will take 33% of the total expenditures on their product as profits, and the other 67% will be used to cover costs. They charge 3 per unit, and each unit costs 2 to produce, so the remaining 1 is taken as profit.&lt;/p&gt;

&lt;p&gt;By the way, if the two firms had identical marginal costs then AA assume they split the sales to customers, with each charging a price equal to marginal cost, and earning zero profits.&lt;/p&gt;

&lt;p&gt;Next question. Why is one firm leading (i.e. has lower marginal costs), and why is one following (i.e. has higher marginal costs)? This comes about because of an endogenous decision of each firm to invest in R&amp;amp;D that lowers their marginal cost. This is where AA take us from a simple accounting exercise and move into the actual economics behind the dynamics of markups.&lt;/p&gt;

&lt;p&gt;When a firm invests in R&amp;amp;D, they increase the probability that they will discover a way to lower their marginal cost. To make things more coherent AA assume these declines are almost always the same proportion (e.g. each discovery lowers marginal cost by 25%). But, and this will be important for their ultimate story, there is also a chance that you get &lt;em&gt;very&lt;/em&gt; lucky and your marginal cost drops all the way to the marginal cost of the leading firm. This isn’t an analogy they use, but I think of their R&amp;amp;D process as one of hiring engineers. You hire engineers from the labor force at random, and any engineer has a chance of figuring out a piecemeal way of lowering your costs. But sometimes you happen to hire an engineer who used to work at the leading firm, and she is able to spill the beans on some major cost savings. This lucky break is what AA mean by “knowledge diffusion”.&lt;/p&gt;

&lt;p&gt;This probabilistic nature of R&amp;amp;D explains why even the following firm - which recall makes zero sales in the model - is willing to take losses and hang in there to invest in R&amp;amp;D. They &lt;em&gt;might&lt;/em&gt; be able to make enough piecemeal improvements, or get lucky enough in hiring the right engineer, to match or beat the leading firm in terms of marginal cost. If they do they become the leading firm and earn all the profits.&lt;/p&gt;

&lt;p&gt;You can use a similar logic to think about why a outsider &lt;em&gt;third&lt;/em&gt; firm (C) might be started by an entrepreneur who pushes the follower aside and starts competing with the leading firm. You could imagine that this is an engineer from firm B who is fed up with management and figures they can do a better job at lowering costs if they run their own firm. Again, this is what AA refer to as knowledge diffusion.&lt;/p&gt;

&lt;p&gt;As an aside, I’m reading a book right now on the early history of Silicon Valley, and I can’t help but frame it in terms of this model. The Fairchild Semiconductor guys are the fed-up engineers who separate from Shockley Semiconductors because they thought they had better ideas about how to lower production costs on silicon transistors (and because it sounds as if William Shockley was kind of a jackass to work for). And while the Fairchild guys weren’t necessarily pursuing a dominant leader in silicon transistors, they were pursuing the leaders in the existing vacuum tube industry. End of aside.&lt;/p&gt;

&lt;h3 id=&quot;what-drives-rd-investment&quot;&gt;What drives R&amp;amp;D investment?&lt;/h3&gt;
&lt;p&gt;Markups evolve in the AA model endogenously based on how much each firm - leader, follower, outsider - invests in R&amp;amp;D. And the amount they invest depends on the gap in marginal cost between leader and follower, meaning the R&amp;amp;D investment depends on the size of the markup. Everything is jointly determined, and leads to the conclusion that the wider the gaps (the higher the markups) the lower the R&amp;amp;D effort by &lt;em&gt;both&lt;/em&gt; leaders and followers (and outsiders). This isn’t a new result from AA, it is a pretty standard one from the Schumpeterian literature on growth.&lt;/p&gt;

&lt;p&gt;Remember that those following firms are not selling any products, just spending on R&amp;amp;D. If they get very far behind &lt;em&gt;and&lt;/em&gt; the chance of getting lucky with hiring the right engineer (knowledge diffusion) is low enough, then they are looking at years of burning through funds before they &lt;em&gt;might&lt;/em&gt; be able to pass the current leader. Thus they spend very little on R&amp;amp;D. Why bother?&lt;/p&gt;

&lt;p&gt;A similar logic holds for leading firms. If they are very far ahead then they are just burning R&amp;amp;D money for no significant gain in profits. Imagine each time they innovate, their marginal cost falls by half. At first, they are earning 33% of expenditures as profits (3 minus 2 divided by 3). If they innovate, that’s 66% (3 minus 1 divided by 3). If they keep on innovating its 83%, then 92%, then 96%, then 98%, and so on until they are taking almost 100% of expenditures as profits. At that point, why bother to innovate again?&lt;/p&gt;

&lt;p&gt;So when the gap in marginal cost is already very big (and thus the markup is very big) both firms have little incentive to innovate. Note that for the follower, this depends on a big gap &lt;em&gt;and&lt;/em&gt; a low chance of making the lucky hire/discovery and catching up instantly. If the gap is big but there is still a good chance of making the lucky hire/discovery (knowledge diffusion), then the follower might still invest a lot in R&amp;amp;D.&lt;/p&gt;

&lt;p&gt;What about firms that are “neck-and-neck” in the parlance of these models, meaning the gap in marginal cost is zero or very small? In that case &lt;em&gt;both&lt;/em&gt; the leader and follower have a lot of incentives to invest in R&amp;amp;D. The leader because it wants to retain its lead (and profits), the follower because just one or two innovations and they can become the leader (and take those profits). In this case we’ve got a small markup and a lot of innovation.&lt;/p&gt;

&lt;p&gt;Note that the outsider firms follow a similar logic to the followers, except they don’t care much about the gap. For them, all that matters is the chance of making the one big hire/innovation that catches them up to the leader. The higher is that chance, the more they invest in R&amp;amp;D.&lt;/p&gt;

&lt;h3 id=&quot;back-to-the-facts&quot;&gt;Back to the facts&lt;/h3&gt;
&lt;p&gt;With all that set up, AA use this model to try and elicit the underlying source of the decline in business dynamism they documented about three sections ago. They consider lower corporate taxes (no), higher R&amp;amp;D subsidies (no), higher entry costs (no), and a lower chance of knowledge diffusion through that lucky hire/discovery (ding! ding! ding!). Before considering how that maps to the real world, let’s see that a drop in the rate of knowledge diffusion can explain the original facts.&lt;/p&gt;

&lt;p&gt;With a lower chance of getting lucky, there will be fewer products in which the follower (or an outsider) has caught up to the leader, and more products with a clear leader and hence a gap in marginal costs. This will drive everything.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Market concentration rose. If more products have a clear leader, then more products have all sales going to one firm, which will show up as more concentration of sales.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Average markups rose. If more products have a clear leader, then more products have a gap in marginal cost and hence have a high markup. So the average markup across products is higher.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The profit share of GDP rose. If more products have a clear leader, more products have markups that translate to profits. So the share of profits is higher.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The labor share of GDP went down. If the profit share went up, the share of expenditures being paid as costs (i.e. wages) went down.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The productivity gap rose. Productivity is just the inverse of marginal cost here. With less of a chance of knowledge diffusion the incentives to do R&amp;amp;D go down and the gaps in marginal cost (and productivity) between leaders and followers get wider.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The firm entry rate fell. With a lower rate of knowledge diffusion, there is less incentive by outsiders to try and enter a product line.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The share of young firms fell. Same as number 6. With fewer outsiders entering, there are fewer new firms as a share of all firms.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The point of the paper is not that they can match these facts. Of course they can. They wouldn’t have put this paper out if for some reason the model was unable to match the stylized facts. The point is that they tied these facts to a feature of the firm decision process - the chance of getting lucky in R&amp;amp;D - that would not be obvious from just knowing the facts themselves.&lt;/p&gt;

&lt;p&gt;If it seems like knowledge diffusion (a lower chance of getting lucky in R&amp;amp;D) is a bit of a kludge, it is. But their more extensive paper provides a better case for linking this to tighter IP protections, and offers some evidence in support of that. Think of my example of getting lucky enough to hire away an engineer from the leading firm. In the absence of tight IP rules, that engineer can basically recreate the production process of the leader at the follower’s firm. But now imagine that IP rules get tightened up.&lt;/p&gt;

&lt;p&gt;That new engineer may know the production processes of the leader, but the follower cannot implement them because of infringement on a patent, and has to license the process. Of you can’t even hire the new engineer because they have a non-compete agreement in that product line. Either way, the incentives to invest in finding that engineer disappear.&lt;/p&gt;

&lt;p&gt;Another aside about Silicon Valley. The Fairchild story is something that is hard to fathom in the current IP environment. When the Fairchild guys wanted to leave Shockley, they left and started a direct competitor using a technique they had developed at Shockley. What are the chances you could get away with that now? Don’t get me wrong, there were plenty of IP issues in that era, and lots of stories about having to engineer new technology to get around patents by RCA or Western Electric. But the patent defenses seem less well developed, at least to this not-a-patent-attorney. End of this aside.&lt;/p&gt;

&lt;p&gt;Back to AA’s evidence. They cannot document the actual rate of knowledge diffusion, but they can look at some other indicators of the flow of knowledge using patent data. Their first figure shows on the left the share of patents going to the top 1% of patenting firms, and you can see that this rose from about 37% to about 50% in the same time frame that markups rose. In the right panel you see the share of patents going to new entrants, and the decline in obvious. AA argue that this shows a concentration of knowledge in leading firms. I think what they want to argue is that the concentrating of patents at leading firms shows that they are more actively protecting IP than in the past to prevent knowledge diffusion. The increase in patent share by top firms (and the decline by entrants) is not evidence of more innovation by top firms, but rather more active IP protection of existing innovation.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/aa2019_fig9.png&quot; alt=&quot;Patent concentration&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Their second set of data is on patent reassignments, which occur when one firm buys a patent from another. This is a method for a leader of creating a “patent thicket” that prevents followers or outsiders from matching their techniques and marginal costs. You can see in their figure on the left that the share of patents being purchased by firms that are already in the top 1% of patent holders increased over time, while the share of patents purchased by small firms declined. Again, AA would argue this shows that leaders are more actively trying to prevent catch-up by followers or outsiders.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/aa2019_fig10.png&quot; alt=&quot;Patent reassignments&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To the extent that you believe that these figures imply a decline in knowledge diffusion, then the qualitative story AA are telling has some backup. What their model did for them was allow them to quantitatively assess the role of knowledge diffusion, and find that it could be the dominant explanation for all of those facts they documented.&lt;/p&gt;

&lt;h3 id=&quot;what-is-this-missing&quot;&gt;What is this missing?&lt;/h3&gt;
&lt;p&gt;The AA model and explanation is very nice, and hangs together. It is important to note that AA have chosen &lt;em&gt;one&lt;/em&gt; way to model and think about the origin of markups. There are alternatives, and those alternatives could give you different ideas about why average markups rose. The choice AA made allows them to speak directly to the incentives for innovation. You could use a different model allowing for competition of some kind (e.g. Cournot or something more exotic) and perhaps get a different source of those seven facts. That isn’t a particular jab at AA. That is just the nature of attempting to model something.&lt;/p&gt;

&lt;p&gt;A more tangible issue has to do with shifts in expenditure shares &lt;em&gt;across&lt;/em&gt; products. One fact that AA don’t bring up, but which appears to be pretty robust, is that the average markup rose over time in part (large part?) because expenditures shifted away from low-markup products and towards high-markup products. That was part of the story I was telling in my prior posts about how higher average markups could be associated with higher productivity.&lt;/p&gt;

&lt;p&gt;AA’s model can match the evidence on higher average markups, but that is coming entirely from higher markups &lt;em&gt;within&lt;/em&gt; product lines. In their model the expenditure on each product is fixed as a fraction of total GDP, so there are no shifts across products at all. In that sense their explanation is incomplete, and without accounting for that I’d say that we should treat the knowledge diffusion explanation with some skepticism.&lt;/p&gt;

&lt;p&gt;Speculating, you might still be able to use knowledge diffusion as an explanation if you assumed that knowledge diffused more slowly in &lt;em&gt;some&lt;/em&gt; industries but not others. In the products where diffusion became harder you’d get widening gaps in marginal costs and higher markups, as explained above. Those products would look relatively expensive compared to everything else. If preferences were such that all products were complements to some extent, then the higher price for those products with less knowledge diffusion would result in an increase in our expenditures on those products. You could thus account for the shift in expenditure towards higher markup products, explained by the decline in knowledge diffusion &lt;em&gt;in those select products&lt;/em&gt;. You’d still have to show that markups were higher in those same products over time.&lt;/p&gt;

&lt;p&gt;As this post has already reached a ridiculous length, I’m going to stop here. Regardless of my complaint about the expenditure shifts and markups, the AA papers are still a useful structure in which to think about these issues. They are also give you a fairly streamlined structure to think about these leader/follower models that have been used in a wide variety of applications within the field of economic growth, and are worth reading just to see what the state of the art looks like.&lt;/p&gt;
</description>
        <pubDate>Wed, 11 Mar 2020 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>Demographics and the decline in business dynamism</title>
        <link>https://growthecon.com/blog/Aging-Growth/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Aging-Growth/</guid>
        <description>&lt;p&gt;A second post in less than two weeks. It’s a Christmas miracle!&lt;/p&gt;

&lt;p&gt;If you’ve read this blog for a while, you probably know that I’ve got a book coming out soon. &lt;a href=&quot;https://amzn.to/2OTj5EY&quot;&gt;Fully Grown&lt;/a&gt; should be released on January 14th, just in time to get a jump on your Christmas shopping for 2020. The subtitle of the book is “Why a stagnant economy is a sign of success”. Without rehashing the whole thing (you should pre-order it now!) one of the core arguments in the book is that improvements in material living standards, women’s rights, and contraception led to a decline in fertility rates that has now put a drag on the growth rate due to population aging.&lt;/p&gt;

&lt;p&gt;I also spend a lot of time in the book talking about things that are &lt;em&gt;not&lt;/em&gt; responsible for the recent growth slowdown. In particular, I work through the evidence on the decline in “business dynamism”, which refers to a set of stylized facts about the speed at which jobs and establishments enter and exit the economy. See &lt;a href=&quot;https://www.brookings.edu/wp-content/uploads/2016/08/haltiwanger_conference_draft.pdf&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;https://www.aeaweb.org/articles?id=10.1257/aer.p20161050&quot;&gt;here&lt;/a&gt;, and &lt;a href=&quot;https://www.nber.org/papers/w25755&quot;&gt;here&lt;/a&gt; for the evidence. A core fact is that the entry and exit rate of establishments has declined over time, meaning that average establishment age has increased. A second core fact is that job creation and destruction rates also declined, meaning there is less reallocation of labor between establishments.&lt;/p&gt;

&lt;p&gt;There is no disputing those facts, but I argue in the book that this doesn’t account for much of the growth slowdown. Or at least, not much compared to demographic changes. If anything, I may be underselling the importance of demographics because the aging of the workforce could also be driving the decline in business dynamism.&lt;/p&gt;

&lt;p&gt;That connection from demographics to business dynamism is made in a relatively new paper from &lt;a href=&quot;https://ideas.repec.org/p/nbr/nberwo/25382.html&quot;&gt;Hopenhayn, Neira, and Singhania&lt;/a&gt;. It is new enough that I was only able to squeeze in a quick reference to it during the last stages of preparing the book. This post fleshes out the connection, explaining my understanding of their logic about how demographics link to business dynamics.&lt;/p&gt;

&lt;h3 id=&quot;establishing-the-facts&quot;&gt;Establishing the facts&lt;/h3&gt;
&lt;p&gt;To start, we need to build up some additional facts regarding business dynamics. Yes, we know that establishment entry rates and exit rates have fallen over time. But for HNS, to understand this it is important to see how exit rates and establishment size change with the age of an establishment. Once we know these new facts, HNS are going to merge this information on establishment demographics with information on worker demographics and show how they are linked.&lt;/p&gt;

&lt;p&gt;The data I’m using here come from the &lt;a href=&quot;https://www.census.gov/programs-surveys/bds.html&quot;&gt;Business Dynamics Statistics&lt;/a&gt; at the U.S. Census, the same source that HNS use. And before we keep going, let’s be clear that I’m talking about &lt;em&gt;establishment&lt;/em&gt; dynamics (e.g. individual Starbucks locations) as opposed to &lt;em&gt;firm&lt;/em&gt; dynamics (e.g. Starbucks as a whole). I don’t need &lt;a href=&quot;https://twitter.com/updatedpriors&quot;&gt;Decker&lt;/a&gt; flaming me all over Twitter for mixing the two concepts up.&lt;/p&gt;

&lt;p&gt;The first fact is that the exit rate of establishments falls as they get older. The figure below shows this by plotting the exit rate in a given year for different ages of establishments. The multiple points (plotted using + signs) in each age category are observations from different years.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/bds_age_estexit.png&quot; alt=&quot;Estab age exit&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Establishments of age zero are brand new, and by definition cannot have exited yet, so their exit rate is zero for all years. But one-year old establishments have an exit rate of 20-25 percent depending on the year. Many establishments fail right away. As you move to the right you’ll see how the exit rate declines with age, to under 10 percent for establishments that make it to 20 years or older. The “Censored” category captures establishments that were already in existence in 1977, which is as far back as the statistics go, so they could be any age.&lt;/p&gt;

&lt;p&gt;The decline in the exit rate with age is consistent with a story that “only the strong survive”. Each year, presumably the poorest performing establishments in a given cohort are the ones that exit. That means the remaining establishments are relatively profitable, which one could easily imagine is a persistent quality of those establishments.&lt;/p&gt;

&lt;p&gt;We might also expect that more profitable establishments expand, and thus that they have more employees. And this is what we see. The next figure shows that establishments tend to be larger as they get older. I’m always a little surprised that the slope of this relationship isn’t higher. Establishments that are one year old have roughly 10 workers, on average. But establishments that are 26 years old or more have only about 22 workers, on average. Some of this is due to looking at establishments rather than firms. Starbucks got much bigger as a firm as it aged by adding establishments, but each individual Starbucks didn’t necessarily get bigger.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/bds_age_estsize.png&quot; alt=&quot;Estab age size&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Regardless, there is an increase in average size as establishments get older, consistent with the “strong survive” story of establishment growth. This relationship of age to size, and age to exit rates, are going to be crucial to the HNS story about demographics and business dynamics.&lt;/p&gt;

&lt;p&gt;The last fact that HNS talk about is related to the size of establishments, but in focuses on the concentration of employment. This last figure shows the share of all employment in a given age category that is in establishments with more than 250 employees. This goes from well under 10% when establishments are age 1, to around 10%-ish when establishments are aged 21+ years. This isn’t a huge difference, but it again is consistent with the story that only the strongest establishments survive.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/bds_age_sharesize.png&quot; alt=&quot;Estab age concentration&quot; /&gt;&lt;/p&gt;

&lt;p&gt;On top of the these three facts from HNS, I’m going to include one more that is related to the average age of establishments. We know that the aggregate exit rate fell over time and the average establishment size rose; those are two of the stylized facts related to the slowdown of business dynamism. You can perhaps guess at this point that this is all consistent with an increase in the average age of establishments, as shown in the following figure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/bds_age_year.png&quot; alt=&quot;Average estab age&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You should ignore the little dip in age in the early 1980s, as this is driven in part by my assumption about how to treat the “Censored” establishments that already existed in 1977 when the statistics begin. But from about the mid-1990s to now you can take more seriously the information in the figure. The average age of establishments increased at the same time that exit rates fell, entry rates fell, and average establishment size increased.&lt;/p&gt;

&lt;h3 id=&quot;a-simple-example&quot;&gt;A simple example&lt;/h3&gt;
&lt;p&gt;We’ve got these facts about establishments in place. Why should we think that the demographics of workers had anything to do with the downward trend in exit rates and entry rates? To see how this all works, let me start with a really naive example that ignores the age structure of establishments from the prior section entirely, and then fold that back in once we’ve got some logic built up.&lt;/p&gt;

&lt;p&gt;Start with 1,000 workers in an initial year. And in each subsequent year, the economy adds another 1,000 workers. This can be a net addition if you want (some existing workers retire, and extra workers get added), but that isn’t crucial.&lt;/p&gt;

&lt;p&gt;While the absolute number of workers is rising over time (1000, 2000, 3000, 4000, etc.) the &lt;em&gt;net growth rate&lt;/em&gt; of the workforce is dropping. In the first year, it is 100% (1000 to 2000), then 50% (2000 to 3000), then 33% (3000 to 4000), and so on. The net growth rate of the workforce doesn’t ever become negative, but it does decline towards zero as time goes on. Assume as well that the initial 1,000 workers are all 20 years old, and each year the age of the new cohort that enters is 20 as well. the average age of the workforce is climbing over time. It starts at 20, then goes to 20.5, then 21, then 21.5, and so on.&lt;/p&gt;

&lt;p&gt;These demographics are really dumbed down, but they capture the crude features of the demographics of the late 20th and early 21st century we’re worried about. The workforce is increasing in absolute size, but the net growth rate is declining and the average age of workeres is rising.&lt;/p&gt;

&lt;p&gt;Let’s now add in establishments. We’re going to assume that each establishment employs exactly 250 workers. For whatever reason, that is the only scale that works to make a establishment profitable. This “quantum” for establishment size is going to automatically reduce establishment dynamism over time, given the worker demographics.&lt;/p&gt;

&lt;p&gt;In the first year there are 4 establishments (1000/250). In year two, there are eight establishments. Then 12, 16, 20, etc. As with the workforce, you can imagine that there is exit of some establishments each year so that the number of new establishments is higher than 4, but the net addition of establishments each year is only 4.&lt;/p&gt;

&lt;p&gt;What about the &lt;em&gt;net growth rate&lt;/em&gt; of establishments? That’s declining over time, just like the net growth rate of the workforce. 100%, then 50%, then 33%, then 25%, and so on and so on. We can also figure out the average age of an establishments. It starts at 1 year, then is 1.5 years, then 2 years, then 2.5 years, etc. These patterns, while not numerically accurate, capture the basic patterns seen in the literature on business dynamism; a falling net growth rate of establishments and an increase in average establishment age.&lt;/p&gt;

&lt;p&gt;And that’s it. With average establishment size held constant, a falling net rate of growth in the workforce will generate a fall in the net growth rate of establishments and an increase in average establishment age. This just follows mechanically. The demographics can account - in my simple example - for &lt;em&gt;all&lt;/em&gt; of the change in business dynamics.&lt;/p&gt;

&lt;p&gt;The world is more complicated that this, and we’ll get to that. But HNS calculate that this simple logic can account for one-third of the decline in the entry rate of new establishments. Holding establishment size constant, a falling growth rate of workers will mechanically create a falling net entry rate of establishments. So we are already part of the way to explaining the decline in business dynamism using only worker demographics.&lt;/p&gt;

&lt;h3 id=&quot;adding-establishment-demographics&quot;&gt;Adding establishment demographics&lt;/h3&gt;
&lt;p&gt;The prior section depended on the assumption that average establishment size didn’t change. But allowing for a realistic change in average establishment size would actually make the connection between worker demographics and establishment dynamics &lt;em&gt;stronger&lt;/em&gt;. We know from the data that older establishments tend to be larger, and that average establishment size and average establishment age have been growing as business dynamism declined.&lt;/p&gt;

&lt;p&gt;Let’s accommodate this in my little example. Say that every year a establishment stays open, it can absorb 50 more workers. Over the life cycle of a establishment, then, it employs 250, 300, 350, 400, and so on. In the first year, we again have 4 (brand new) establishments absorbing the 1000 workers. In year two, those four establishments can absorb 1200 workers (300x4), and the remaining 800 workers need only 3.2 firms (I wasn’t as clever with the numbers, so we’re getting fractional establishments here), for a total of 7.2 establishments, rather than 8 in the naive example. Average establishment size is now 2000/7.2 = 277, rather than 250. Most important, the net entry rate of establishments is now only 80% (3.2/4), rather than 100%. The increase in capacity of older establishments lowered the net entry rate, while also accelerating the increase in average establishment size and average establishment age. If you spin this forward you’ll see that acceleration continues over time.&lt;/p&gt;

&lt;p&gt;But even this simple two-period example reveals a number of new issues. Note that I assumed all 4 of the original establishments survived into period 2. What if one of them failed? Then the three remaining would only absorb 900 workers, and there would be 4.4 new establishments employing 250 workers each. We’d have 7.4 establishments with an average size of 270.3 and an average age of 1.41. The gross entry rate would be 4.4/4 = 110%, and the gross exit rate would 1/4 = 25%, for a net entry rate of 86%.&lt;/p&gt;

&lt;p&gt;Once we allow establishments to differ by age, the exact exit rate of establishments &lt;em&gt;by age&lt;/em&gt; and their size &lt;em&gt;by age&lt;/em&gt; matters to the evolution of average establishment size, average establishment age, and the net entry rate. The entire history of establishment entry and exit will matter in any given year, and the calculations quickly get very tedious. Nevertheless, the overall point holds. If as establishments age they tend to get larger and exit at a lower rate, then a decline in the growth rate of the labor force will push down the net entry rate of establishments even further than in my naive example, and push up the average age and average size of establishments even more. In short, the demographics of &lt;em&gt;establishments&lt;/em&gt; cannot be divorced from the demographics of &lt;em&gt;workers&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The addition of age-specific establishment characteristics can potentially allow worker demographics to explain even more than the one-third of the decline in establishment entry rates that the naive model could.&lt;/p&gt;

&lt;h3 id=&quot;all-the-bells-and-whistles&quot;&gt;All the bells and whistles&lt;/h3&gt;
&lt;p&gt;HNS work through this all in much greater detail, and use numbers that actually match the observed data on establishment exit rates and size by establishment age. As I mentioned above, they find that one-third of the decline in the establishment entry rate can be accounted for simply by the decline in the growth rate of workers. But, in addition, the remaining two-thirds of the decline in establishment entry rates can also be attributed to the decline in the growth rate of workers given that worker demographics influence establishment demographics (and hence establishment size and exit rates). In short, the entry rate of establishments declined over the last twenty years because fewer establishments were needed to absorb the actual increase in the workforce that occurred.&lt;/p&gt;

&lt;p&gt;What’s very important to note here is that the entire history of the workforce demographics matters. It is not just the decline in the growth rate of the workforce over the last twenty years that led to lower entry rates. It is equally the fault of the very &lt;em&gt;high&lt;/em&gt; growth rate of the workforce in the middle of the 20th century. During that period it took many new establishments to absorb the Baby Boomers as they entered the workforce. Hence the entry rate was high during the 20th century. But as those establishments aged, the ones that survived grew larger and less likely to go out of business. By the time we made it to the year 2000, there was a built-up stock of large, old, unlikely-to-exit establishments that was capable of absorbing most of the workers entering the workforce each year. There was little space for new establishments to enter.&lt;/p&gt;

&lt;p&gt;HNS go on to tie this together with several other stylized facts that have gained a lot of attention recently. Establishments with high markups would probably be more likely to survive, and a counterpart of higher markups is a lower share of output being paid to labor. Older establishments, then, would have higher average markups and a lower average share of output being paid to labor. Thus when the aging of the workforce pushes up the average age of establishments, the average markup in the economy would rise and the average labor share would fall. To some extent, all of the facts about business dynamism, concentration, and market power could be related back to changes in the demographics of workers.&lt;/p&gt;

&lt;p&gt;If you’re looking for the catch, here it is. The explanation that demographics of workers can explain all of the changes in business dynamics relies on the age-specific exit rates and sizes (and possibly markups and labor shares) of establishments. The data telling us how establishment age is related to exit and size (and markups and labor shares) are drawn from the time period in which the growth rate of workers was declining. There is nothing that says these age-specific establishment rates and sizes are a law of nature. Those rates and sizes might be unique to the last few decades given changes in anti-trust policies, regulations, trade, inequality, and so on and so on. Yes, the demographics of workers and establishments are going to be linked to some extent no matter what, but perhaps the real interesting action is in what determines the age-specific exit rates and sizes for establishments.&lt;/p&gt;

&lt;p&gt;Leaving that objection aside, the HNS paper reinforces the argument in my book regarding the role of demographics in the growth slowdown. But perhaps more interesting than that, it provides an indirect argument for increased immigration. If you believe that the changes in business dynamics - lower entry rates, perhaps higher markups and lower labor shares - are bad for the economy, then you would want to change the demographics of this country to encourage more rapid entry of workers. To do that “natively” would require substantial changes in policy and social norms, and even if you were cool with reversing access to contraception and talking people into having more kids, you’d still need to wait about 20 years for all those new babies to hit the job market.&lt;/p&gt;

&lt;p&gt;Or, you could effect an immediate increase in the growth rate of workers by expanding immigration rates. Allowing in more immigrants would allow more establishments to open, increasing the entry and exit rates, pulling down the average age of establishments, lowering their average size, and presumably lowering the average markup and increasing the average labor share. If you were worried about whether those immigrants would take jobs from existing workers, just remember that the economy managed to absorb all of the Baby Boomers into the workforce - while also expanding the labor force participation rate of women - during the middle of the 20th century without having a substantial effect on the employment rate of their parents.&lt;/p&gt;

&lt;p&gt;Have a great holiday! Buy the &lt;a href=&quot;https://amzn.to/2OTj5EY&quot;&gt;book&lt;/a&gt;!&lt;/p&gt;
</description>
        <pubDate>Mon, 16 Dec 2019 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>Revisiting the Kaldor Facts</title>
        <link>https://growthecon.com/blog/Kaldor-Update/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Kaldor-Update/</guid>
        <description>&lt;p&gt;It has been a looooong time since I posted anything, and I can assign blame to all sorts of things for this. Rather than get into those, I thought I’d come back to blogging by returning to the Kaldor facts. These are all observations about the stability of various macroeconomic aggregates that Kaldor used to motivate his own work on growth, and which were subsequently adopted by essentially everyone else who studied growth as well.&lt;/p&gt;

&lt;p&gt;The original Kaldor facts are so embedded into macro and growth that they don’t actually get talked about much anymore. &lt;a href=&quot;https://ideas.repec.org/a/aea/aejmac/v2y2010i1p224-45.html&quot;&gt;Chad Jones and Paul Romer&lt;/a&gt; provided an update to the facts. But that update was really to argue that facts about ideas, institutions, population, and human capital were all more interesting than the original Kaldor facts about physical capital. Not because Kaldor was wrong, but because they had been accepted so completely into the canon of economics.&lt;/p&gt;

&lt;p&gt;I guess I’m not ready to leave aside the original Kaldor facts alone. That is partly because Kaldor’s facts were originally some vague impressions based on very limited data from the US and UK; see footnotes 1,2, and 4 in &lt;a href=&quot;https://academic.oup.com/ej/article-abstract/67/268/591/5248725?redirectedFrom=fulltext&quot;&gt;this paper&lt;/a&gt;. This led me in a prior &lt;a href=&quot;https://growthecon.com/blog/BGP-Empirics/&quot;&gt;post&lt;/a&gt; to ask whether the Kaldor facts were really as robust as we thought. I went back to these facts again this fall as part of my grad macro course, which involved updating the data I used in the prior post and looking across a wider set of countries. This led me to revise my view to be much friendlier towards the facts than before. This post is thus an exercise in arguing for taking the Kaldor facts seriously.&lt;/p&gt;

&lt;p&gt;That doesn’t mean Kaldor’s original facts (Jones and Romer cite six) can’t be tinkered with. Some of them are redundant and others are useful only under some particular assumptions. What I present here is a set of revised Kaldor facts: (1) Stable growth in output per capita, (2) stable capital/output ratios, (3) stable rates of gross capital formation, and (4) a stable cost share for labor.&lt;/p&gt;

&lt;h3 id=&quot;stable-growth-in-output-per-capita&quot;&gt;Stable growth in output per capita&lt;/h3&gt;
&lt;p&gt;Let’s start with what I see as the most basic Kaldor fact, and one that still seems remarkable when you think about it. The growth rate of output per capita (or labor productivity if you care to call it that) is very stable over long periods of time for most &lt;em&gt;developed&lt;/em&gt; countries. I’m going to throw some data in on developing countries to see how they compare, but this whole post is really concentrating on developed country facts.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/notes-lny-bgp.png&quot; alt=&quot;BGP growth&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first figure plots the log output per capita over time for a handful of countries. This handful was chosen very deliberately, as they all show remarkable stability in the growth rate of log output per capita over time. I’m going to tag this the “balanced” group of countries, given the stability of the growth rates. Yes, Mexico shows a break around 1980, but on both sides of that break the growth rate is stable. A last comment on this group is that not is the growth rate stable within each country, but the growth rates are similar across countries. There appears to be a common growth rate for output per capita over time for developed countries.&lt;/p&gt;

&lt;p&gt;A quick mathematical aside. You can see that stability from the fact that the lines stay roughly straight. On a log scale, the slope of a line is the growth rate, so the fact that the slope stays the same for all these countries over time means that their growth rate is stable over time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/notes-lny-catchup.png&quot; alt=&quot;Catchup growth&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The second figure plots the log output per capita over time for a second set of countries, which I’ll call the “catchup” group (with the US as a reference). Here the pattern does not look like stable growth. You can see some experiences with rapid growth (e.g. high slopes) for Germany and Japan between 1950 and 1980, and for South Korea and China after 1970 or 1980, respectively. The growth rate for Nigeria is close to zero for most of the time period, with some acceleration towards the end of the figure.&lt;/p&gt;

&lt;p&gt;This catchup group doesn’t seem to have stable growth rates. But if you look at Japan and Germany, you’ll see that they start to display that stability as they approach the US level of output per capita. South Korea appears to be headed that way as well. Whether China follows a similar trajectory to South Korea, with growth rates falling as it approaches developed levels of output per capita, remains to be seen. Whether Nigeria ever has the same takeoff as South Korea (or Japan earlier) also remains to be seen.&lt;/p&gt;

&lt;p&gt;The point is that the Kaldor fact about stable growth rates appears to hold in the limit, but not necessarily at any given point in time. Past experience - Japan, Germany, South Korea - suggests that the growth rate tends to become stable over time if it isn’t stable to begin with. That past experience is why you’d get most economists to predict that China’s growth rate will eventually stabilize at a rate similar to the one seen in other developed countries.&lt;/p&gt;

&lt;h3 id=&quot;stable-capitaloutput-ratios&quot;&gt;Stable capital/output ratios&lt;/h3&gt;
&lt;p&gt;The second Kaldor fact is that capital/output ratios are stable. This one is going to be more tenuous than the stability of growth rates. Here’s the capital/output ratios for the “balanced” group of countries.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/notes-ky-bgp.png&quot; alt=&quot;KY balanced&quot; /&gt;&lt;/p&gt;

&lt;p&gt;That is stable…ish. Most of these appear to have been drifting upwards over time, from around 2 in 1950 to around 2.5-3 by 2015. One reason to not get too wired up is that the drift could be a data artefact. All the capital/output ratios are calculated from the Penn World Tables, and this may have to do with how output and capital are valued cross-country. If you look only at the US, and use just US national accounts data, you can see more stability in the capital/output ratio.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/notes-ky-us.png&quot; alt=&quot;KY US&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The top line here is the capital/output ratio in aggregate, and while the scaling makes it look more dynamic, note that it stays within a narrower range between 2 and 2.4, with a less obvious trend upward. Moreover, the lines below that measure the capital/output ratio for separate components of the capital stock. Residential and non-residential structures (the dominant part of the capital stock) have fluctuations but very little obvious trend. Equipment also has no distinct trend. The only component that does is intellectual property, and that trend may be due to a lack of accurate accounting in the past.&lt;/p&gt;

&lt;p&gt;Now let’s hop back to the “catchup” group of countries. Here you could talk yourself into stability for Germany and China, perhaps. But there is clearly an upward trend for Japan and South Korea. But note that for both Japan and South Korea, the capital/output ratio does appear to stabilize in the 15-20 years. This would be consistent with the stabilization of their growth rates in the same period after they caught up to places like the US and UK in output per capita.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/notes-ky-catchup.png&quot; alt=&quot;KY catchup&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If it seems like I’m straining to make the case that the capital/output ratios are stable, I am. This is the least convincing of the Kaldor facts. The idea that capital/output ratios are stable, or are heading towards stability in places like Japan and South Korea, is informed in large part by the theory (Solow, neo-classical growth) that was built on to explain that stability. Thus there is some circular reasoning going on, and here’s where the biggest dose of skepticism about the Kaldor facts should be located. We can’t help but look at the Kaldor facts and see the Solow model at work, and infer that the capital/output ratios &lt;em&gt;must&lt;/em&gt; stabilize eventually. But if you hang in there a few sections, I’ll throw in some other data on rates of return that corroborate the stable capital/output ratio story.&lt;/p&gt;

&lt;p&gt;There is also a deep dark rabbit hole to stumble into here, involving the Cambridge controversy and Lant Pritchett’s &lt;a href=&quot;http://piketty.pse.ens.fr/files/Pritchett00.pdf&quot;&gt;critique&lt;/a&gt; of using the perpetual inventory method to calculate capital stocks. As this post is already going to be long enough, I am going to skip past that hole for now. Let’s just say that the stability of the capital/output ratio is a very rough approximation of what we see in the data.&lt;/p&gt;

&lt;h3 id=&quot;stable-gross-capital-formation-share&quot;&gt;Stable gross capital formation share&lt;/h3&gt;
&lt;p&gt;This one is never brought up by Kaldor explicitly, although Domar’s &lt;a href=&quot;https://laprimaradice.myblog.it/media/00/00/2491562877.pdf&quot;&gt;1946 paper&lt;/a&gt; does mention it as a stylized fact. The stability of the gross capital formation share of GDP is crucial in making sense of a stable capital/output ratio. It seems worth establishing whether the data support this.&lt;/p&gt;

&lt;p&gt;Yes, I said “gross capital formation” share as opposed to “savings” or “investment” share. I’m getting more and more convinced that using either of the latter two terms adds too much confusion. It is nearly impossible to shed the colloquial meanings of “savings” and “investment”, even for economists. The gross capital formation share of GDP is the fraction of all real output that consists of new capital goods (e.g. new buildings, computers, or bulldozers). It’s “gross” in the sense that it includes capital goods purchased to replace old depreciated capital goods.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/notes-sinv-bgp.png&quot; alt=&quot;GCF share&quot; /&gt;&lt;/p&gt;

&lt;p&gt;First is the share for our balanced group, and you can see the stability of that around a value of 0.2 to 0.24 for most of them. Dips and spikes occur for sure, but similar to before there is no distinct rise or fall in this share. The second figure here is for the catchup group, and we’ve again got a lot more excitement. Germany has a pretty stable rate. But Japan and South Korea have rates that are quite high for a time (0.3 or more) before they appear to revert back to a slightly lower rate. Nigeria had a distinct drop in the GCF share in the early 1980’s, but appears stable since then.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/notes-sinv-catchup.png&quot; alt=&quot;GCF share&quot; /&gt;&lt;/p&gt;

&lt;p&gt;China is the obvious odd duck here, with a share for gross capital formation that does appear to trend up over time. This trend has to end at some point, as the GCF share of GDP cannot go above one. But there is nothing here that says when it will stop trending up. This catchup group shows, as before, more movement than would be expected just looking at the balanced group. But compared to the capital/output ratio, the stability of the gross capital formation share seems more solid.&lt;/p&gt;

&lt;h3 id=&quot;stable-cost-shares&quot;&gt;Stable cost shares&lt;/h3&gt;
&lt;p&gt;Kaldor cited the stability of the &lt;em&gt;output&lt;/em&gt; share of labor and capital in his work. I’m going to alter his fact to refer to the stability of the &lt;em&gt;cost&lt;/em&gt; share of labor. That is, I’m interested in the payments to labor (i.e. total wages) as a fraction of total costs (i.e. total wages plus total capital costs), as opposed to the fraction of total output (i.e. total wages plus total capital costs plus economic profits). Starting with an initial &lt;a href=&quot;https://web.stanford.edu/~rehall/Invariance_Properties_of_Solow.pdf&quot;&gt;critique&lt;/a&gt; by Robert Hall, the cost share is more relevant to building a theory of production and growth (but perhaps not of distribution) than the output share. We can use the cost share, under mild assumptions, to infer the elasticity of output with respect to labor. We could use the output share, as Solow did, but that requires much stronger assumptions than I think we should be making.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/notes-klems-labsh-cost.png&quot; alt=&quot;Labor cost share&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The figure plots the share of costs going to labor, using data from &lt;a href=&quot;http://www.worldklems.net/data.htm&quot;&gt;KLEMS&lt;/a&gt;. These shares are available for fewer countries and years than the Penn World Table data that is used in the prior facts. What we can see here is something that looks stable…ish. The French data, in particular, show a decided decline in the cost share from 1980 to 1990. But for the rest, the shares don’t have distinct trends. That should indicate to us that the elasticity of output with respect to labor in any production function we use is stable over time. Stable elasticities are what the Cobb-Douglas production function provides, and hence these stable cost shares give us some reassurance that this production function is a decent approximation.&lt;/p&gt;

&lt;p&gt;Of course, I should probably mention that these cost shares are &lt;em&gt;wrong&lt;/em&gt;. If you read through KLEMS documentation, which I made the mistake of doing over Thanksgiving break, you’ll see that this labor share probably isn’t quite right for our purposes. Worse, if you read through the last &lt;a href=&quot;https://sites.google.com/site/davidbaqaee/&quot;&gt;four or five papers&lt;/a&gt; that David Baqaee and Emmanual Farhi have written, you’ll see that the correct way to compute the elasticity involves combining information on cost shares at lower levels of aggregation and weighting them with an I/O matrix. I am working on a paper on calculating the elasticities correctly. Okay, fine. I downloaded some data and have two scribbled note pages. But I have every &lt;em&gt;intention&lt;/em&gt; of working more on a paper calculating the elasticities correctly.&lt;/p&gt;

&lt;p&gt;For the moment we’re going to stick with the crude cost shares in the above figure, because that’s what I’ve got. But check back with me &lt;del&gt;in a few months&lt;/del&gt; a few years from now, and I’ll get you a better answer on cost shares.&lt;/p&gt;

&lt;h3 id=&quot;what-about-rates-of-return&quot;&gt;What about rates of return?&lt;/h3&gt;
&lt;p&gt;An omission from my primary list of revised Kaldor facts is the stability of the rate of return on capital. And if you look at recent &lt;a href=&quot;http://www.macrohistory.net/data/&quot;&gt;data&lt;/a&gt; associated with a paper by &lt;a href=&quot;http://www.macrohistory.net/?sermons=the-rate-of-return-on-everything-1870-2015&quot;&gt;Jorda, Knoll, Kuvshinov, and Taylor&lt;/a&gt;, you’ll find a lot of stability in the rate of return. Here’s a figure from the U.S., plotting five-year averages of the rates of return for three asset classes from 1890-2015. You get something similar for the other major developed countries in their dataset.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/notes-return-usa.png&quot; alt=&quot;Returns&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I don’t think this needs to be one of the core Kaldor facts. It is almost redundant with the capital/output ratio. Or perhaps a better way to say this is that the stability of the rate of return provides some assurance that there is stability in the capital/output ratio. It would not be hard to convince me, however, that you could use the stability of the rate of return as the main Kaldor fact, and then see the capital/output ratio as redundant. But I like the capital/output ratio a little more because it speaks directly to how a growth model is built (i.e. the properties of the production function).&lt;/p&gt;

&lt;h3 id=&quot;you-should-be-more-impressed&quot;&gt;You should be more impressed&lt;/h3&gt;
&lt;p&gt;Regardless of whether you want to include the rate of return or not, the apparent stability of these different values is remarkable. Think of the technological, political, and social changes that have taken place over the last eighty years, if not the last 150 years. The structural economic changes alone - from agriculture to manufacturing to services - have been staggering. Yet despite all of that, the growth rate of output per capita continues to chug along at almost 2% per year in most developed countries. The capital/output ratio in those same countries tends to be somewhere between 2.5 and 3, the share of GDP that gets allocated to capital formation is around 0.2, and the cost share of labor is something like 0.60-0.65. Rates of return on capital didn’t fundamentally shift up or down. These economies have a remarkable stability to them at the macro level despite all sorts of instability and changes at the micro level.&lt;/p&gt;

&lt;p&gt;The Kaldor citation I gave you above is from 1957. Solow published his model of economic growth in 1956. These were economists talking about the inherent &lt;em&gt;stability&lt;/em&gt; of economies that had just whipsawed through the Great Depression and World War II. The Harrod/Domar model of growth that Solow was reacting to featured inherent &lt;em&gt;instability&lt;/em&gt;, which was seen as a feature not a bug because it accorded more readily with recent experience. Talking about stability in economic growth was, for the time, a rather radical idea. The Kaldor facts are interesting precisely because they are about stability, not in spite of that.&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Dec 2019 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>The deep roots of development - Part 5</title>
        <link>https://growthecon.com/blog/Deep-Roots-5/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Deep-Roots-5/</guid>
        <description>&lt;p&gt;In my quest to fall behind on everything in my life, I left writing up the next installment of the deep roots reviews until well after I actually gave the lecture. Here I want to go over some thinking about how geographic, environmental, and/or agricultural characteristics led to variation in development across the globe.&lt;/p&gt;

&lt;h3 id=&quot;where-economic-activity-happens&quot;&gt;Where economic activity happens&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/map_lights.jpg&quot; alt=&quot;Night lights&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The world is not uniformly populated, and neither is economic activity distributed uniformly across the globe. The map shown above is of night lights around the globe, and they are concentrated in several areas - the eastern US, eastern Mediterranean, eastern coast of South America, Europe, India, eastern China, Japan, and a few others. If you could zoom in, you’d see that even within those areas, the lights are not uniform, but concentrated in urban areas with big stretches of relative dark in between.&lt;/p&gt;

&lt;p&gt;One possibility is that this lack of uniformity is random, perhaps driven by contingent historical events or intitutions and culture. &lt;a href=&quot;https://ideas.repec.org/p/cpr/ceprdp/9760.html&quot;&gt;Michaels and Rauch&lt;/a&gt;, for example, find that urban areas in France are more likely to be based around old Roman towns or forts, meaning the modern location of most economic activity in France was determined in part by Julius Caesar. What Michaels and Rauch also find, though, is urban locations in Britain do &lt;em&gt;not&lt;/em&gt; share this feature. There, because urbanization completely collapsed after the Romans left, cities and economic activity are more likely to be organized around places suitable for river transportation.&lt;/p&gt;

&lt;p&gt;You could try to extend this kind of analysis to the entire world, and this is, in princple, what &lt;a href=&quot;https://academic.oup.com/qje/article-abstract/133/1/357/4110418&quot;&gt;Henderson, Squires, Storeygard, and Weil&lt;/a&gt; did in a recent paper. They use night lights, as in the map above, to proxy for economic activity in each pixel of the map (there are 240,000 pixels). They then use a regression to explore how much explanatory power the geographic characteristics of a pixel have for those night lights. This is a stretch, but they are asking whether the world looks more like France, or more like Britain.&lt;/p&gt;

&lt;p&gt;The geographic characteristics they use include some they relate to agricultural productivity: climate type (e.g. tropical dry forest, etc.), temperature, precipitation, number of growing days, elevation, latitude, and a measure of land suitability. Others they include relate to trade: being close to the coast, being on a river, having a natural harbor, and so on. You can quibble with the set of variables, perhaps arguing they are missing separate controls for soil types. Or you could quibble with the division into agriculture and trade, as being on a river or near a coast likely influences both. Nevertheless, their division isn’t particularly important, as all they are interested in is raw explanatory power.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/hssvtab2.png&quot; alt=&quot;Explanatory values&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Their Table 2, shown above, gives you the summary of their results. Combined, line (1) shows you that their variables can explain 46% of the variation in night lights. In other words, raw geographic characteristics can predict almost half of the dispersion in economic activity, meaning it is a bit like Britain. But the remainder is attributable to either other geographic factors HSSW don’t measure, or to “France-like” historical factors.&lt;/p&gt;

&lt;p&gt;If you look down the table, lines (8) and (9) show you that of their variables, the ones they associate with agriculture are responsible for almost all of the explanatory power, while trade variables explain far less. And perhaps this isn’t surprising, as we might expect that people (and hence economic activity) would tend to cluster around areas where food was relatively easy to grow.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/hssvfig3.png&quot; alt=&quot;Predicted values&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Regardless, the main story here is about these R-squareds, as opposed to causality, per se. If all you knew about the Earth was the geographic conditions, you’d be able to predict about 46% of the variation in the location of economic activity. This isn’t perfect, as the France/Britain story would suggest, and as HSSW’s own maps show. Take a look at their Figure 3, above, which plots their predicted level of economic activity by pixel from their regressions. It overstates the amount of activity in places like Cuba, the lower Mississippi and the east coast of Australia. And it misses the concentration of economic activity along the Ganges, Indonesia, or the large urban areas of Africa. It also understates to some extent the activity along the east coast of the United States.&lt;/p&gt;

&lt;p&gt;Well, &lt;em&gt;of course&lt;/em&gt; they can get some predictive power from geographic variables, you may be thinking. Most economic activity is clustered in a few areas (Europe, eastern US, east Asia) and since geographic characteristics tend to cluster as well (i.e. if one pixel is a jungle, the next pixel is likely to be a jungle as well), there has to be &lt;em&gt;some&lt;/em&gt; predictive power to geography. Does this tell us something useful?&lt;/p&gt;

&lt;p&gt;HSSW say yes, in part because of a second set of regressions they run. Because they have multiple pixels per country, they can include country fixed effects. In that case, the estimated effect of geographic variables is made only by looking at how geography correlates with economic activity &lt;em&gt;within&lt;/em&gt; individual countries, and they are effectively throwing out cross-country variation in both geography and economic activity. In this case, they find similar patterns in the effects of geographic variables. For example, across countries places with tropical rain forests show less econoimc activity, but tropical rain forests also display less economic activity than other areas &lt;em&gt;in the same country&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Hence HSSW argue that there is something important about geography, in general, in determining where economic activity takes places. It wouldn’t make sense for the same patterns to hold within and across countries unless there was something meaningful about those geographic features.&lt;/p&gt;

&lt;h3 id=&quot;population-density&quot;&gt;Population density&lt;/h3&gt;
&lt;p&gt;HSSW show these correlations, but do not open up the “black box” of why certain characteristics might be associated with economic activity. Other papers, however, do attempt to provide some mechanisms. One example is &lt;a href=&quot;https://ideas.repec.org/a/aea/aecrev/v101y2011i5p2003-41.html&quot;&gt;Ashraf and Galor&lt;/a&gt;, who looked specifically at the relationship of agricultural productivity to population density and living standards in the pre-industrial period. The “black box” here is a simple Malthusian model where population growth is positively related to living standards, and living standards are negatively related to the size of the population (see &lt;a href=&quot;https://growthecon.com/blog/Malthus/&quot;&gt;here&lt;/a&gt; for a more thorough summary).&lt;/p&gt;

&lt;p&gt;This model says that higher agricultural productivity should be associated with higher population density, but unrelated to living standards themselves. And the empirical work Ashraf and Galor do in this paper confirms these basic predictions. To measure agricultural productivity they use two things, the time elapsed since the onset of settled agriculture associated in a given area, and a combo term that mixes together some of the measures HSSW use, but can be summarized as “inherent land productivity”.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/agfig3a.png&quot; alt=&quot;Revolution&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The first figure shows the partial relationship (after netting out other controls) for the years since the Neolithic Revolution and population density. As you can see, the longer this gap, the higher the density. The notional story here is either (a) that there is some learning by doing going on in agriculture, and hence the longer you have been at it, the better you are or (b) people settled the most productive places first, and this is picking up some effect of that not captured by their other variables. The second figure shows a similar plot for inherent land productivity and density. Again, the more productive, the more dense.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/agfig3b.png&quot; alt=&quot;Productivity&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is all consistent with the Malthusian black box they outline in the paper. It tells us that some of the reason for the strong geographic patterns HSSW find is that population density is higher in places with certain agricultural characteristics, and this almost mechanically is going to generate more economic activity. There is nothing Earth-shattering and counter-intuitive to these findings.&lt;/p&gt;

&lt;p&gt;Where things get a little more interesting is in thinking about what else might be going on in that black box. If there are scale effects, or agglomeration effects, or if more people means more minds thinking about how to generate non-rival ideas, then high population density generates more economic activity over and above the simple fact that there are more people. And Ashraf and Galor have a little evidence of this as well.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/agtab1.png&quot; alt=&quot;Neolithic&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This shows the results from their Table 1, where they regress measures of technological usage (from &lt;a href=&quot;https://ideas.repec.org/a/aea/aejmac/v2y2010i3p65-97.html&quot;&gt;Comin, Easterly, Wong&lt;/a&gt;) on the time since the Neolithic Revolution, which remember tells us that populations are more dense. In the case of all three classes of technology, the longer a country/area had been practicing agriculture, the more advanced was its technology.&lt;/p&gt;

&lt;p&gt;There is no strict causal experiment going on here, but it is indicative that places with an early start to agriculture, which probably was due in part to high agricultural productivity, ended up with technological advantages. Comin, Easterly, and Wong already traced the persistence of these technological advantages to living standards today. I did a &lt;a href=&quot;https://growthecon.com/blog/Persistence-Technology/&quot;&gt;post&lt;/a&gt; on that a while ago. Thus it is plausible to argue that initial agricultural conditions are responsible for some fraction - perhaps in the neighborhood of the 46% that HSSW found - of the variation in living standards seen today.&lt;/p&gt;

&lt;h3 id=&quot;agricultural-types-and-deep-determinants&quot;&gt;Agricultural types and deep determinants&lt;/h3&gt;
&lt;p&gt;There are other attempts to dig into the black box connecting environmental - and in particular, agricultural - conditions and modern outcomes. These often work through the effect of particular types of agriculture on cultural norms or institutional structures. And those effects may even work to offset some of the positive advantages that high agricultural productivity may have brought through time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/litinafig9.png&quot; alt=&quot;Litina&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One example is from Anastasia Litina, with a &lt;a href=&quot;https://ideas.repec.org/a/kap/jecgro/v21y2016i4d10.1007_s10887-016-9134-7.html&quot;&gt;paper&lt;/a&gt; on agricultural productivity and cooperation. What she finds is that within continents, controlling for several other geographic factors, that places with higher inherent agricultural productivity are actually poorer than places with lower productivity. The figure above shows the residual relationship she estimates.&lt;/p&gt;

&lt;p&gt;What Litina proposes is that while agricultural suitability was a positive for population density (and probably technology) prior to the industrial revolution, once the IR hit it became a detriment. In other words, agricultural productivity may have gotten you to the industrial revolution faster, but once there it slowed you down. The reason she proposes for this is not that high agricultural productivity may led you to specialize in certain goods with low productivity growth, which you might call the &lt;a href=&quot;http://web.iitd.ac.in/~debasis/Lectures_HUL737/papers/paper2_JET%201992.pdf&quot;&gt;Matsuyama hypothesis&lt;/a&gt;, but rather a cultural effect.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/litinatab6.png&quot; alt=&quot;Litina&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The idea is that places with &lt;em&gt;low&lt;/em&gt; agricultural productivity are forced to cooperate more to ensure survival, and that everyone meets subsistence. This generates more within-group trust, which is then useful once you hit the industrial revolution. Places with high productivity do not have to generate that same cooperate or trust, and that hinders their industrial development. Cross-country, Litina shows that in fact measures of trust do negatively relate to land suitability.&lt;/p&gt;

&lt;p&gt;A slightly related idea is that the specific crops you grow may require different levels of cooperation or trust. The necessity of managing large irrigation works would seem to be something that requires, and selects for, trust or cooperation. &lt;a href=&quot;https://science.sciencemag.org/content/344/6184/603&quot;&gt;Talhelm et al&lt;/a&gt; looked at whether there were measurable psychological differences within China associated with whether people were from the rice-growing south, or wheat-growing north. The hypothesis was that the rice-growing region would have people that thought more holistically, and put greater weight on group outcomes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/talhelmfig2.png&quot; alt=&quot;Rice&quot; /&gt;&lt;/p&gt;

&lt;p&gt;They found significant differences between the rice and wheat growing regions. The figure here shows one example of their findings, on holistic thinking. A few key pieces of information here are that they administered these tests to non-farmers within these regions. This is not research showing that &lt;em&gt;farmers&lt;/em&gt; have different attitudes, but that even people who are &lt;em&gt;non-farmers&lt;/em&gt; share these attitudes based on the farming that traditionally took place within their geographic area. Implicitly they are arguing for a strong form of persistence in how agricultural type influenced cultural norms over time. A second note is that the did these tests for areas on the rice/wheat border, finding similar results, and that this is not driven just be gross differences in development or institutions between north and south China. It isn’t experimental evidence, but it is suggestive.&lt;/p&gt;

&lt;p&gt;A last example of how the particulars of agriculture might translate to cultural differences is from &lt;a href=&quot;https://ideas.repec.org/a/oup/qjecon/v128y2013i2p469-530.html&quot;&gt;Alesina, Giuliano, and Nunn&lt;/a&gt;, who looked at how agricultural areas where the plow was used have very different attitudes towards gender roles than areas where plows were not used.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/agntab1.png&quot; alt=&quot;AGN&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These first results show a negative relationship of traditional plow usage and the participation of women in agricultural tasks. This is no country-level, but rather ethnic-group level. The difference in columns (1) and (2) is that the first uses the Ethnographic Atlas (limited data but more groups), while column (2) and the remaining columns use the Standard Cross-Cultural Sample (more data, fewer groups). Regardless, more plow use is associated with less participation of women in these agricultural tasks. The speculation is that as animal-drawn plow use involves brute force, it favors male labor in agriculture, and this leads men to take on more of all agricultural tasks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/agntab3.png&quot; alt=&quot;AGN&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The more interesting fact they document is that this persists to differces in labor force participation in 2000. Their Table 3 (which I cut off a bunch of ancillary crap from) finds the negative relationships you see. Fewer women work in a country when the ethnicities making up that country were traditional plow-users. The effect size is substantial, with a 15 point drop in participation comparing full plow-use to non-plow-use, on a mean of 51%. You also see an effect on firms with female ownership, although nothing for political positions. Similar to the rice/wheat differences, this suggests persistent cultural effects associated with the type of agriculture done.&lt;/p&gt;

&lt;h3 id=&quot;geography-history-and-long-run-outcomes&quot;&gt;Geography, history, and long-run outcomes&lt;/h3&gt;
&lt;p&gt;The lesson from all these examples is that while the gross level of agricultural productivity may be central to where economic activity takes place, the kind of agriculture done has important follow-on effects that affect how this translates to living standards. The different types of agriculture - plow vs. non-plow, rice vs. wheat, etc. - created variation in cultural and institutional outcomes that influenced economic activity as well. Therefore we have places of high agricultural productivity with very different long-run outcomes, and places of low agricultural productivity with very different long-run outcomes. There is no straight line from agricultural productivity to high GDP per capita.&lt;/p&gt;

&lt;p&gt;On top of that, historical circumstances generated different responses to the agricultural conditions in place. To give you a stark example of what I mean, consider the distribution of “caloric suitability” across the world prior to colonization. This caloric suitability comes from &lt;a href=&quot;https://ideas.repec.org/p/bro/econwp/2015-5.html&quot;&gt;Galor and Ozak&lt;/a&gt;, and it is an attempt to measure the raw calories that an area of land could produce. In short, they look at the raw yield (in tonnes) that each crop in a given area could produce, multiply that by the calories per tonne, and then look for the maximum of total calories across all crops. Given the adjustment for calories, this tends to make places that can grow rice or potatoes look good (both very calorie dense) relative to other staples.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/csipre1500.png&quot; alt=&quot;CSI&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The darker the green in this figure, which plots their data, the more calorie suitable a pixel is. The striking thing about this map is the massive calorie potential in the eastern US, and in the River Plate basin. But remember that this is for the per-1500 period before colonization. Those two areas were not, at that point, anywhere close to the most densely populated places on the planet, nor would either have been a clear leader in living standards. Pure agricultural productivity was not enough, apparently.&lt;/p&gt;

&lt;p&gt;Why not? One theory is that their populations had simply not had enough time to “fill up” these areas and go through the learning-by-doing in agriculture that would have made them as dense and technologically sophisticated as China or Europe at this time. The Neolithic Revolution and settled agriculture only took place around 3-6,000 years ago in the Western Hempisphere, while it happened around 9-12,000 years ago in the Eastern Hempisphere. If the eastern part of North America and the River Plate basin had not been colonized, we might have predicted that the indigenous populations would achieve density levels and technological sophistication equal to, or surpassing, the Old World civilizations. That didn’t happen, of course, because of colonization. Geography matters here, but so does history. It isn’t plausible to explain long-run development ignoring one or the other.&lt;/p&gt;
</description>
        <pubDate>Thu, 18 Apr 2019 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>The deep roots of development - Part 4</title>
        <link>https://growthecon.com/blog/Deep-Roots-4/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Deep-Roots-4/</guid>
        <description>&lt;p&gt;Congratulations to all of you who guessed that I would fall behind in writing up these deep roots posts. I was able to get my notes together enough to cover material on culture during my class, but only now finally got around to writing this up as a post. This line of research is relatively new to me, so I’m going to apologize ahead of time for what is probably a less coherent take on the state of things than I’d like.&lt;/p&gt;

&lt;p&gt;Guiso, Sapienza, and Zingales have a very nice &lt;a href=&quot;https://ideas.repec.org/a/aea/jecper/v20y2006i2p23-48.html&quot;&gt;paper&lt;/a&gt; on the relationship of culture and economic outcomes, although it is now over a decade old and thus missing out on some of the latest work in this area. Nevertheless, it gives a good idea of what we’re talking about here.&lt;/p&gt;

&lt;p&gt;The aspect of culture most used by GSZ is trust, meaning generally a willingness to trust strangers (non-kin). I’m going to leave aside any question of causality of trust on economic outcomes for the moment, but for now let’s just note that the evidence shows this aspect of culture varies a lot across populations. Using data on immigrants to the US (thus holding constant the institutional and economic setting to some extent) they show that people self-report being willing to trust others.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/Guiso_etal_2006_fig2.png&quot; alt=&quot;Trust&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What you can see are big differences, with those of Japanese and Scandanavian descent reporting much more trust, and those from South Asia, the Carribean, or Africa reporting much less. The fact that this varies so much is alone quite interesting, as it indicates substantial variation in something you might have guessed only varied across individuals, but not systematically across populations.&lt;/p&gt;

&lt;p&gt;Moreover, eye-balling this figure you get a quick sense of why people latched onto culture as an explanation for economic outcomes. The level of reported trust almost looks like it was rank-ordered by the average GDP per capita of the origin countries of different ethnic groups. China is probably an outlier, but in general we see relatively rich places with high levels of trust.&lt;/p&gt;

&lt;p&gt;In a nutshell, that is the kind of fact motivating this literature on culture and development. The idea is that there are certain cultural attitudes, or preferences, or norms, or what have you, that foster economic exchange, or innovation, or accumulation. Therefore development could be driven, in part, by having a specific culture that promotes those three things.&lt;/p&gt;

&lt;p&gt;This sounds a lot like the argument about institutions, that some foster exchange, innovation, or accumulation more than others. And just like institutions, there is a definitional problem. What exactly counts as “culture”? For my own purposes, and for the purposes of this post, I tend to think of it in the following way. Economic development involves a series of constrained optimization problems, which implies a set of preferences and a set of constraints. Things like geography (for sure) and institutions (kind of) set the constraints. Culture (kind of) is related to the preferences.&lt;/p&gt;

&lt;h3 id=&quot;preference-measures&quot;&gt;Preference measures&lt;/h3&gt;
&lt;p&gt;We can look more carefully at people’s preferences along a variety of dimensions. One prime example of this is a recent paper on global preferences by &lt;a href=&quot;https://academic.oup.com/qje/article/133/4/1645/5025666&quot;&gt;Falk, Becker, Dohman, Enke, Huffman, and Sunde&lt;/a&gt;, which includes a fantastic &lt;a href=&quot;https://www.briq-institute.org/global-preferences/about&quot;&gt;site&lt;/a&gt; where you can download and use their data. FBDEHS worked with Gallup to run survey questions on preferences around the world, on a comparable basis, recovering about 80,000 individual responses in 76 countries.&lt;/p&gt;

&lt;p&gt;They group the preferences into six types: patience, risk-taking, positive reciprocity, negative reciprocity, altruism, and trust. They use several questions to measure each of the six, and then combine the answers to those questions to get a single index of each one. A person’s risk-taking score, for example, depends on both a self-assessment as well as a value elicited from a standard set of questions asking that ask people to choose between a certain amount of money (e.g. &lt;img src=&quot;http://latex.codecogs.com/png.latex?10) or a lottery (e.g. a coin flip for\inline&quot;/&gt;25 or zero). The materials on their site have full information on how each of these was measured and validated.&lt;/p&gt;

&lt;p&gt;Given the individual responses, they can do some simple country-level averages, and then look at how the different preferences correlate across countries. Their Table 3, shown here, shows those relationships. While there are a number of strong correlations here, it is not the case that these are perfectly related, meaning the six measures contain some distinct information. Patience and altruism, for example, are unrelated, implying one could think about them as different concepts. And given that kind of variation, it is at least plausible that one could identify different effects of patience and altruism on economic outcomes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/falketal3.png&quot; alt=&quot;Correlations&quot; /&gt;&lt;/p&gt;

&lt;p&gt;At the same time, there are some patterns that show up, or preferences that tend to move together. Trust, altruism, and positive reciprocity are all significantly and positively related, and one might term that package of preferences “prosociality”. Another set of characteristics that tend to move together are patience, risk-taking, and negative reciprocity. There is no obvious name for that correlation, although I’m tempted to call it “the revenant” because it calls to mind people willing to undertake a dangerous quest for revenge long after they are already dead. That is probably reading a little too much into the data, though.&lt;/p&gt;

&lt;p&gt;More seriously, be very careful that this second set of correlations is &lt;em&gt;not&lt;/em&gt; “antisocial”, because it is &lt;em&gt;not&lt;/em&gt; the opposite of the prosocial characteristics. It is a different dimension along which people appear to vary. A country low in trust, altruism, and positive reciprocity would be “antisocial”, regardless of their patience, risk-taking, and negative reciprocity. One could also have a prosocial country that also rated high on the “revenant” characteristics.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/falketal10.png&quot; alt=&quot;Individuals&quot; /&gt;&lt;/p&gt;

&lt;p&gt;FBDEHS also report similar correlations at individual level in their Table 10, which are interesting to compare to the country-level averages in the last table. Here, everything is signficant because they are using 80,000 individuals, but don’t let that distract you. What I see here is a weaker set of relationships, in terms of the size of the coefficients, but still some evidence of sets of characteristics. Prosociality appears again as a collection of positive reciprocity, altruism, and trust, and you also get the revenant package of patience, risk-taking, and negative reciprocity.&lt;/p&gt;

&lt;p&gt;The numbers in this table are all excluding country fixed effects, meaning that they ignore the fact that in some countries that average level of trust, altruism, and positive reciprocity are high (and in others those are low), for example. These numbers show that taking those averages as given, within a country it also tends to be that people who trust &lt;em&gt;more than average for their country&lt;/em&gt; also are more altruistic &lt;em&gt;than the average for their country&lt;/em&gt;, and so on.&lt;/p&gt;

&lt;p&gt;This leaves the comparison of the two tables. Table 10 tells us that the prosocial characteristics tend to move together across individuals within &lt;em&gt;all&lt;/em&gt; countries. More altruistic people tend to be more trusting everywhere, for example. Similarly, in every country people who are more patient tend to favor more negative reciprocity. There is nothing about this, however, that necessarily implies that the cross-country average relationships in Table 3 have to arise. It is quite possible to have these individual correlations within every country, but for the average level of trust or patience to be similar across countries. That is, Table 10 could be true, but Table 3 could easily have been full of zeroes, or even negative relationships.&lt;/p&gt;

&lt;p&gt;However, the numbers in Table 3 indicate that on top of those individual correlations, there is a similar pattern of variation in the &lt;em&gt;average&lt;/em&gt; level of trust or patience (or any of the other characteristics) across countries as we see with individuals. That means that the raw correlations across all individuals in the FBDEHS sample that underlay the packages of traits (prosocial, revenant) are even stronger than what you see in the individual or country level alone.&lt;/p&gt;

&lt;p&gt;From the perspective of research on the deep roots of comparative development, it is mainly the country-level variation that we’re interested in. And these preferences do appear correlated with country-level outcomes. FBDEHS look at raw correlations of each preference with several measures, which I cut and paste below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/falketal2.png&quot; alt=&quot;Characteristics&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are strong correlations - and let’s be really clear here that these are correlations - of GDP per capita with patience, negative reciprocity, and trust. In fact, patience, negative reciprocity, and trust are the three traits that show up correlated with most of the other measures in the table: democracy, life expectancy, the Gini, and homicides. If we take high GDP per capita, high life expectancy, and few homicides as a rough gauge of development, then developed places tend to have two traits, patience and trust, and probably tend to be risk-averse and put a high weight on negative reciprocity. Keep in mind that there is nothing wrong with being both prosocial (trusting) and patient (a revenant), they are not mutually exclusive.&lt;/p&gt;

&lt;p&gt;So here is the million-dollar question. Does being trusting and patient &lt;em&gt;make&lt;/em&gt; you developed? Or does development &lt;em&gt;make&lt;/em&gt; you trusting and patient? I am unaware of any clear evidence that answers these questions with any confidence. GSZ attempt to solve this causality problem by using religion to instrument for preferences. That … doesn’t make sense. It’s not any different than using say, the mortality of European settlers in different colonies to instrument for institutions, to pick a completely random example out of hat. In both cases, it is implausible that the only effect of the instrument (e.g. religion) on the outcome (e.g. savings rates, income redistribution) is through preferences.&lt;/p&gt;

&lt;p&gt;Most research relies on what I’d call “verbal Granger causality”. The argument is that culture and preferences changes very slowly over time and were determined in the past. Therefore if we see a correlation of preferences with some economic outcome, it must be that the preference caused the economic outcome. But that isn’t quite right either. We know that history matters for economic outcomes, in the sense that past events can have persistent effects. So it is quite possible that there was some event in the “deep” past that made an economy poor, for example, and that also made its population less trusting of strangers, for example. The poverty persists, perhaps for reasons entirely unrelated to culture or preferences, and the lack of trust persists because cultural attitudes tend not to change much without a large shock. So when we look today, we see a poor country that is less trusting. But that doesn’t mean the lack of trust is why they are poor.&lt;/p&gt;

&lt;p&gt;The danger here is that we’re doing ex post reasoning on cultural causes of development. Trust in strangers must be good for development because we see trust high in rich countries. Maybe trusting strangers is bad for development, but a host of other positive forces made trusting countries rich. Negative reciprocity is associated with higher GDP per capita, and you can tell yourself a story about why that could be. Perhaps because punishing cheaters deters others from cheating in the future, and that’s more important that rewarding good behavior (positive reciprocity). But if the coefficient on positive reciprocity had been significant, and that on negative reciprocity insignificant, you probably would have been just as happy with a story about how it is the rewards that matter more than the punishments. The point is that we don’t have any clear theory of which cultural preferences &lt;em&gt;should&lt;/em&gt; be good for development, so we may just be making stuff up based on correlations.&lt;/p&gt;

&lt;h3 id=&quot;family-structure&quot;&gt;Family structure&lt;/h3&gt;
&lt;p&gt;Keeping in mind the danger of ex post reasoning, and the lack of clear causal relationships, there is one aspect of culture that is of particular importance for studying development: family preferences. I’ve written on the blog a number of &lt;a href=&quot;https://growthecon.com/blog/topic-takeoff/&quot;&gt;posts&lt;/a&gt; about how it is the change in the relationship of population growth and GDP per capita growth that generates sustained development, and not a specific technological revolution (e.g. steam engines). Thus cultural preferences regarding family size and structure can be crucial in understanding why some places developed earlier than others.&lt;/p&gt;

&lt;p&gt;There are several papers out there now specifically looking at cultural differences in family preferences and modern outcomes. Benjamin Enke has a &lt;a href=&quot;https://ideas.repec.org/p/nbr/nberwo/23499.html&quot;&gt;paper&lt;/a&gt; that looks at how family structure is related to cooperation and moral systems, while Jon Schulz has a &lt;a href=&quot;https://drive.google.com/file/d/1zP-HTvQ_2W2N6GS3TlMiRJcGgmZoA4ce/view&quot;&gt;paper&lt;/a&gt; that uses variation in exposure to the Catholic Church as an exogenous driver of differences in family structure, and hence of modern attitudes.&lt;/p&gt;

&lt;p&gt;Both papers document in detail what an anthropologist would tell you, which is that the nature of family structure differs a lot across cultures. Nuclear families or clans? Do you trace relationships through the father, the mother, or both? Do new couples co-locate near one branch of the family or another? Are there dowries or bride prices? Is cousin-marriage encouraged or banned?&lt;/p&gt;

&lt;p&gt;The answers to those questions matter to the extent that they affect preferences for familiy size or quality/quantity of kids. &lt;a href=&quot;https://ideas.repec.org/a/kap/jecgro/v15y2010i2p93-125.html&quot;&gt;Alesina and Giuliano&lt;/a&gt; have a paper that looks at how variation in family structure (strong versus weak family ties is how they refer to it) affects fertility and several other outcomes. While those same authors along with Nunn have a &lt;a href=&quot;https://ideas.repec.org/p/hrv/faseco/11986333.html&quot;&gt;paper&lt;/a&gt; on how plow use changed cultural attitudes towards fertility. The upshot of both is that these differences in preferences for family size are quite substantial.&lt;/p&gt;

&lt;p&gt;These papers are probably underappreciated for their importance to the story of the take-off to sustained growth. Differences in fertility preferences would affect the level of living standards in Malthusian settings for sure. Beyond that, differences in fertility preferences, and in particular how sensitive fertility was to living standards, could influence whether a given culture took advantage of a technological or institutional or historical shock to make the move to sustained growth. I think this is a place where it might be useful to step back from the almost purely empirical work being done right now in the deep roots literature, and reconnect explicitly with the growth theory on the origins of take-offs. That theory could provide some guidance to what exactly we should be trying to measure when we talk about culture or preferences for family size.&lt;/p&gt;

&lt;h3 id=&quot;cultural-variation&quot;&gt;Cultural variation&lt;/h3&gt;
&lt;p&gt;As a last point, let’s assume that there is &lt;em&gt;something&lt;/em&gt; causal about culture (related to families or otherwise) for economic development. Why do those country-level preferences vary at all? Aren’t we all sort of the same? I’ve read some with these questions in mind, but not deeply. One place to start is this &lt;a href=&quot;https://pseudoerasmus.com/2015/10/04/ce/&quot;&gt;post&lt;/a&gt; by Pseudoerasmus, who takes a much deeper dive into the subject.&lt;/p&gt;

&lt;p&gt;Two main theories about the deep roots of culture are “evolutionary psychology” and “cultural evolution”. The former thinks about how natural selection operated to create specific “hard-wired” mental structures in humans in response to their environment. The latter adds that culture itself - knowledge, norms, rules - evolve as well. From the perspective of someone reading the economics literature on deep origins of development, the distinction between these fields is not that important.&lt;/p&gt;

&lt;p&gt;Why? Because for the purposes of the empirical work that people do in this area, it is environmental variation that is measurable and (arguably) exogenous. For the papers you’ll find in economics involving deep origins of culture, environmental characteristics are always on the right-hand side, and there is little to no explicit discussion of cultural evolution. Perhaps there is some hand-waving about how culture does evolve, but for the purposes of running some regressions, researchers almost always fall back on environmental features to explain (imperfectly, with R2 less than one) cultural variation.&lt;/p&gt;
</description>
        <pubDate>Sun, 17 Mar 2019 00:00:00 -0500</pubDate>
      </item>
    
      <item>
        <title>The deep roots of development - Part 3</title>
        <link>https://growthecon.com/blog/Deep-Roots-3/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Deep-Roots-3/</guid>
        <description>&lt;p&gt;This is the third entry in the series on deep roots, and it concerns institutions. One of the earlier (and most widely-read) series on this blog was the “Skeptics Guide to Institutions” which had four entries: &lt;a href=&quot;https://growthecon.com/blog/the-skeptics-guide-to-institutions-part-1/&quot;&gt;one&lt;/a&gt;, &lt;a href=&quot;https://growthecon.com/blog/the-skeptics-guide-to-institutions-part-2/&quot;&gt;two&lt;/a&gt;, &lt;a href=&quot;https://growthecon.com/blog/the-skeptics-guide-to-institutions-part-3/&quot;&gt;three&lt;/a&gt;, and &lt;a href=&quot;https://growthecon.com/blog/the-skeptics-guide-to-institutions-part-4/&quot;&gt;four&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Those posts were particularly concerned with a critique of the cross-country empirical work on institutions that started around the mid-1990s as part of the cross-country growth regression literature, and was carried forward by the Acemoglu, Johnson, and Robinson study that used settler mortality as a source of exogenous variation in institutions. I don’t want to reinvent the wheel here, and those original posts are still a decent introduction to that set of papers. The TL;DR version of them is that I don’t find the empirical work convincing in establishing the proposition that institutions are &lt;em&gt;the&lt;/em&gt; fundamental determinant of comparative development. The main criticisms were as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;The scales of institutional quality (e.g. “protection against expropriation” or “constraints on executives”) are used improperly in regressions. Treating these scales, which might run from 1 (worst) to 7 (best), as a continuous variable implies that the differences in institutions which exist can in fact be measured. That is, it implies that Liberia’s institutions (a 2) are better than Cuba’s (a 1) in &lt;em&gt;exactly&lt;/em&gt; the same way that Australia’s (a 7) are better than South Korea’s (a 6). There’s no way that is true. Better to use sets of dummies for each group.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In many cases institutional scales are just functioning as regional dummies. If you code a measure of institutional quality for European countries in 1750, and get that the Netherlands and England have a “3”, while Spain and Portugal have a “1”, and use this in a regression, then you may as well be using an indicator for “gray winters” versus “sunny winters”.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Instrumenting for the quality of institutions in colonies using the mortality rates of European settlers doesn’t satisfy the condition that the instrument (settler mortality) have an effect on living standards &lt;em&gt;only&lt;/em&gt; through its affect on institutions. First, the measures of institutions are picking up far more than the specifics of constraints on the executive and the like, and second, settler mortality is like a summary statistic for biological/geographic conditions, which almost certainly have other routes to influence living standards.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hence I don’t spend a lot of time in class going through the body of literature on these cross-country institutional studies. Nevertheless, I do spend time talking a lot about institutions.&lt;/p&gt;

&lt;p&gt;Fair warning that I didn’t proofread this carefully, so apologies for the typos that probably exist.&lt;/p&gt;

&lt;h3 id=&quot;whats-the-question&quot;&gt;What’s the question?&lt;/h3&gt;
&lt;p&gt;A key point in studying institutions, from my perspective, is being clear on what question we’re actually trying to answer. If the question is “Do institutions matter?”, then I think the answer is “Yes”, but that this answer is trivial. &lt;em&gt;Of course&lt;/em&gt; they matter. I don’t know that you can call yourself a social scientist and not believe that institutions, writ large, matter for economic outcomes. Markets (distorted or not) are institutions, and so even if you have some hardcore belief that you only want to study the &lt;em&gt;economics&lt;/em&gt; of something, you &lt;em&gt;still&lt;/em&gt; implicitly think that institutions matter. So the literature isn’t about convincing us that institutions are worth studying. They are.&lt;/p&gt;

&lt;p&gt;The second kind of question is “Are institutions responsible for sustained growth and/or comparative development?” That’s a much meatier question, and there isn’t an obvious answer here, meaning it is open for study. The original cross-country literature had this as it’s main question, with one important modification. The question was usually a form of “Are institutions &lt;em&gt;solely&lt;/em&gt; responsible for sustained growth and/or comparative development?”, and the implied answer had to be Yes/No. That put too high of stakes on everything, as if there was some kind of Highlander-like cosmic battle going on amongst competing explanations and &lt;em&gt;there could be only one&lt;/em&gt;. One, there is no plausible way to pick one of those answers (although you would bet on “No”) using data, which would always involve uncertainty. Two, if you wanted to make this argument theoretically, then you can make the answer “Yes” just by redefining institutions until you have a nebulous enough concept to make it true by definition.&lt;/p&gt;

&lt;p&gt;The less severe “Are institutions responsible for sustained growth and/or comparative development?” is plausible as a question, but again runs into the issue that we probably won’t be able to find enough data across a wide enough range of economies to really make any definitive conclusions. Which means that this question is something that will probably always be best addressed in a more speculative fashion by someone who is synthesizing lots of existing findings, rather than being pinned down by any specific regression.&lt;/p&gt;

&lt;p&gt;But most of the papers in this literature do have specific regressions in them. What are they asking? I’d say it is something along the lines of “What were the observable effects of institution X?”. This is a much more modest question, of course. Once you answer it, you will not know whether institutions are the root cause of comparative development or not. But you will have a clear idea of the effects of institution X, and that may be an input into the synthesizing that you or someone else does later on.&lt;/p&gt;

&lt;p&gt;This is the current state of the literature on institutions, from my perspective. In retreating a little on the scope of the question, we’ve been able to get a wave of very nice papers on specific institutions and their influence on economic outcomes over time. That’s the literature I focus on in the class.&lt;/p&gt;

&lt;h3 id=&quot;variation-in-institutions&quot;&gt;Variation in institutions&lt;/h3&gt;
&lt;p&gt;One of the features of this latest literature is the care it (usually) takes with identifying causal effects, motivated by the general evolution of economics in the last few decades. In the case of institutions, however, this has meant that nearly &lt;em&gt;all&lt;/em&gt; of the work now ends up studying consequences of a broader historical event, colonization.&lt;/p&gt;

&lt;p&gt;The reason for this involves an implicit assumption about institutions themselves. If you think that institutions are themselves a reaction to existing conditions (geographic, economic, political, etc..), and evolve to solve very specific problems, then there is essentially no way to evaluate the effect of institutions across any two units of observation. You could call this the “Ostrom problem” after &lt;a href=&quot;https://en.wikipedia.org/wiki/Elinor_Ostrom&quot;&gt;Elinor Ostrom&lt;/a&gt;, who noted across a long career that local institutions to manage common pool resources (almost?) always had a clear rationale and were able to prevent environmental overuse.&lt;/p&gt;

&lt;p&gt;Why does this create an empirical problem? Let’s assume that I’m trying to compare several different societies (or countries, or villages, or whatever) with some difference in observable institutions. Even if I control for other observable characteristics (e.g. environmental or whatever) the the Ostrom problem is that the differences in observable institutions are, almost by definition, related to some other unobservable characteristics. In short, the Ostrom problem is that differences in institutions can never be thought of as random.&lt;/p&gt;

&lt;p&gt;Which brings us back to colonization. Most current work on institutions uses an aspect of colonization to find variation in institutions, because it might be plausible to argue that these institutions were imposed from outside, and not related to unobservables. In certain situations, you might even be able to argue that the institutional differences were the result of random chance.&lt;/p&gt;

&lt;p&gt;A good example here is the paper by &lt;a href=&quot;https://ideas.repec.org/a/tpr/restat/v92y2010i4p693-713.html&quot;&gt;Lakshmi Iyer&lt;/a&gt; on the effects of direct versus indirect British rule in India. There, she argues that there was plausibly random variation in direct/indirect rule due to death of local rulers without heirs. For a specific time period, if there was such a lapse, the British took control directly, while in areas where an heir existed they took control and rule remained indirect. With this kind of quasi-random variation in institutions, she can do a well-defined empirical comparison, and finds that directly ruled areas have fewer public goods (e.g. schools, clinics, roads), even today, than indirectly ruled places.&lt;/p&gt;

&lt;p&gt;This only works because there was a colonizer that had a level of control of the institutional structure, and thus the organic local institutions (which may have used adopted heirs or some other means of choosing a successor) were shut down. This same kind of logic is at work in most of the other institutional papers that have come out recently. By leveraging a colonizers power over a given colony, we can see some kind of clear exogenous variation in institutional structure that otherwise would be correlated with unobservables.&lt;/p&gt;

&lt;h3 id=&quot;institutions-and-historical-persistence&quot;&gt;Institutions and historical persistence&lt;/h3&gt;
&lt;p&gt;I talked about this in my original Skeptics Guides, but once we’re looking at the literature on effects of specific (often colonial) institutions, we’re talking much more about historical persistence than institutions &lt;em&gt;per se&lt;/em&gt;. That is, a common goal in these papers is to establish that there are &lt;em&gt;current&lt;/em&gt; differences in living standards associated with some &lt;em&gt;historical&lt;/em&gt; differences in institutions. That’s the purpose of Dell’s paper on the mining &lt;em&gt;mita&lt;/em&gt;, and the purpose of Iyer’s paper on British rule in India.&lt;/p&gt;

&lt;p&gt;The institutions that they study no longer exist, of course. So the finding that the &lt;em&gt;mita&lt;/em&gt; or British direct rule had negative effects on living standards is not a statement about the direct effects of &lt;em&gt;those&lt;/em&gt; institutions on contemporaneous populations. Instead, these papers establish that while once those institutions had &lt;em&gt;some&lt;/em&gt; negative effect on the affected economies - although this is usually some kind of black box - these areas remained behind even after the institution itself was removed. These papers are evidence that there is some path dependence in development, and if you push down a place far enough, it won’t be able to catch up again. Note that this runs counter to our standard stories of growth and development, where negative shocks have temporary effects and forces of accumulation, catch-up, and/or convergence bring the economy back to normal.&lt;/p&gt;

&lt;p&gt;In the sense that institutions like the &lt;em&gt;mita&lt;/em&gt; or British rule can push an area below the threshold beyond which they cannot recover, then institutions matter for development for sure. And the evidence seems to keep accumulating that institutions of various kinds have these kinds of effects. The broader conclusion is thresholds exist, and that in turn means history matters for development in a powerful way. This gives us another reason for looking backwards for the sources of comparative development. Moreover, while the institutions literature was crucial in establishing that thresholds exist, that doesn’t limit us to thinking only of institutional reasons for falling behind. Anything, including geography or culture, could be a reason for falling below a threshold. It’s not institutions OR geography OR culture. It’s institutions AND geography AND culture.&lt;/p&gt;
</description>
        <pubDate>Tue, 05 Feb 2019 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>The deep roots of development - Part 2</title>
        <link>https://growthecon.com/blog/Deep-Roots-2/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Deep-Roots-2/</guid>
        <description>&lt;p&gt;Look at me, two posts in less than two weeks! I’m back with the second part of the series I’m writing on the deep roots of comparative development. Part 1 is here, and gave an overview of this literature. Here I’m gonna tackle some of the basic evidence on crude living standard differences that I think motivates studying those deep roots in the first place.&lt;/p&gt;

&lt;h3 id=&quot;modern-living-standards&quot;&gt;Modern living standards&lt;/h3&gt;
&lt;p&gt;The variance in measures like GDP per capita across countries today is well known. This variance is the source of the question “Why are some places rich and some places poor?”. To get some sense of this variation, here’s a density plot of log real GDP per capita across countries from Angus Maddison’s dataset.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/fig_dens_maddison.png&quot; alt=&quot;Density plots of GDP per capita&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The line from 2010 ranges from about 6 (400-ish real dollars) to 10 (22,000-ish real dollars), or a factor of about 55. That takes into account some extremes, but the 90th/10th ratio is around 22, and even the 75th/25th ratio is still around 4. That is the scope of what we are trying to explain. How is it that some places produce four, or twenty, or fifty times as much as others?&lt;/p&gt;

&lt;p&gt;If you look backward in time, say at 1913 or 1820, then you still see variance, but it is lower. In 1913 the distribution spans almost 3 log points (6 to 9), meaning a ratio of about 20 between top and bottom countries. The 90/10 ratio is about 6 in 1913. Going back to 1820, you still see variation, although the span is only about 1 log point (6 to 7), for a ratio of about 2.7, and a 90/10 ratio of about 3.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/fig_dens_maddison_lim.png&quot; alt=&quot;Density plots of GDP per capita&quot; /&gt;&lt;/p&gt;

&lt;p&gt;One issue with the first figure is that it may be skewed a little by the fact that more and more countries are included as the year becomes more recent. The second figure here shows the same kind of plots using only the same 48 countries that appear in the 1820 data. What that does is lop off the bottom end of the distribution in 2010. The 48 countries that Maddison calculated GDP per capita for in 1820 are all somewhat well off in 2010, although not universally so.&lt;/p&gt;

&lt;p&gt;What can we learn from these figures? First, we can see that the very wide distribution of GDP per capita today (2010) was much narrower about 200 years ago, which was right around the time the Industrial Revolution hit northwest Europe. (NB: Arguing about the timing and scope of the IR is &lt;em&gt;not&lt;/em&gt; what I’m interested in here - 1820 is correct +/- 40 years either way). So with the onset of industrialization a major divergence took place that exaggerated the distribution of GDP per capita.&lt;/p&gt;

&lt;p&gt;What isn’t obvious from the figures is whether it was the &lt;em&gt;same&lt;/em&gt; countries leading, and the same countries lagging, at each point in time. It could well be that the leading countries in 1820 got overtaken by poor countries in 1820, who are now rich. But that doesn’t appear to be the case. Rather than look at the density plots, the next figure shows log GDP per capita in 2010 against log GDP per capita in 1820 for the 48 countries that have data in both years. There is a clear positive relationship, meaning that the countries at the top end of the distribution in 1820 were still around the top of the distribution in 2010.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/fig_comp_maddison.png&quot; alt=&quot;1820 versus 2010&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I did not label these points with country names on purpose, because that way lies niggling arguments about specific cases, and for the time being that is not what I want to get into. Suffice it to say that there is evidence that leaders of 2010 were also likely to be leaders in 1820, although not universally.&lt;/p&gt;

&lt;p&gt;As an aside, a perfectly valid question here is whether we should buy Maddison’s numbers for 1820. It could well be that Maddison decided &lt;em&gt;first&lt;/em&gt; that there &lt;em&gt;must&lt;/em&gt; be a positive relationship, and then backed out his 1820 numbers to make sure the figure ended up right. I don’t think he explicitly did this, but it could well be that his implicit ideas about relative incomes based on his impression of history were leading him one way or another. But I think there is sufficient data from wage series accumulating to support the idea that Maddison’s numbers are &lt;em&gt;roughly&lt;/em&gt; right in how they order countries in 1820.&lt;/p&gt;

&lt;p&gt;A second thing to learn from these figures - or at least the first one - is that the bottom end of the distribution is about the &lt;em&gt;same&lt;/em&gt; in 2010 as it was in 1820. The poorest places in both time periods have real GDP per capita of around $400. It’s not just that the top end saw faster growth from 1820 to 2010 than the bottom end, it’s that the bottom end doesn’t appear to have grown &lt;em&gt;at all&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Perhaps this is trying to be too subtle, but I think this leads to a distinction in the following questions. “Why did poor countries today grow slower than rich countries from 1820 to 2010?” is not the same thing as “Why did poor countries today not grow at all?”. The latter question is more relevant to this deep roots literature. It is about what conditions led some countries to (eventually) make the jump to sustained growth, and what conditions have prevented (so far) others from making that same jump. I think the deep roots literature takes as a given that once you do make the jump, that there are strong convergence forces at work that will carry you to the neighborhood of rich countries, a la South Korea or Japan.&lt;/p&gt;

&lt;p&gt;So perhaps to explain growth &lt;em&gt;today&lt;/em&gt;, we need to reach back to 1820 or earlier and identify what created the variation in the first place.&lt;/p&gt;

&lt;h3 id=&quot;rich-populations-and-poor-populations&quot;&gt;Rich populations and poor populations&lt;/h3&gt;
&lt;p&gt;The data in the prior figures is all based on country borders. And if you think about which ones are rich and which ones are poor, there are some regularities based on the origins of the people in those countries. Europe, and especially western Europe, is relatively rich. But so are places like the U.S., Canada, New Zealand, and Australia that are referred to as “Neo-Europes” because they are populated mainly be former Europeans. Looking down the range of GDP per capita, places like the southern cone of South America (Argentina, Chile, Uruguay) all have large groups of European descent, and they tend to be somewhat richer than places without European-descended populations, as in much of South Asia and Sub-Saharan Africa. Exceptions do exist, of course, as with South Korea or Japan.&lt;/p&gt;

&lt;p&gt;We can look at some data to see that this is a bit more systematic, although don’t confuse this for any kind of causal claim, just an observation. Using data from &lt;a href=&quot;https://ideas.repec.org/a/oup/qjecon/v125y2010i4p1627-1682..html&quot;&gt;Putterman and Weil&lt;/a&gt;, I’ve created two plots. The first shows log GDP per capita in 2000 against the fraction of population in 2000 in a country that was descended from Europeans.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/fig_pw_europe.png&quot; alt=&quot;Density plots of GDP per capita&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There is a positive relationship, dominated by the two groups at the tails with either 0% or close to 100% European population, but there are a fair amount of countries lying in the middle, and you can see that the relationship is consistent across the whole range.&lt;/p&gt;

&lt;p&gt;In contrast, next is the plot of log GDP per capita in 2000 against the fraction of population in a country that was descended for Sub-Saharan Africa. Here the relationship is negative, again dominated by countries in the tails, but with a consistent message through the middle of the figure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/fig_pw_africa.png&quot; alt=&quot;Density plots of GDP per capita&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There is no way that, by chance, places with a high fraction of European descendants all happened to stumble onto the same package of institutions and technologies that stimulate sustained growth. Rather, this suggests that Europeans in general had, or developed, some institutions, technologies, or characteristics that were conducive to sustained growth. These features may have existed in some form or other back in 1500, which is how far back the migration data behind the figures goes, and Europeans just carted them around with them wherever they went. In that case, we’d want to look backwards in time to try and figure out what those characteristics were. On the other hand, it may be that the keys to sustained growth were not known in 1500, but that once some Europeans figured them out, it was easy to diffuse them amongst other Europeans. In that case, we still want to figure out what those charactersitcs were, but we’d also want to think about why diffusion was so easy amongst European populations (and so hard to other populations).&lt;/p&gt;

&lt;p&gt;Let me be very clear that this is not a justification for doing ex-post reasoning about why Europeans are “better” than other populations. The leap to sustained growth by mainly European populations did not happen in a historical vacuum. The remaining populations of the world were not afforded an opportunity to see if they would find their way to sustained growth, and if that would diffuse among them in a similar manner, because the Europeans stepped in and colonized many of those populations first. As will be clear from this deep roots literature, colonization had significant and persistent effects on institutions, technologies, and other characteristics of these populations. It could well be that the only thing Europeans figured out and diffused among themselves was the willingness and ability to colonize other populations, and extract resources from them.&lt;/p&gt;

&lt;h3 id=&quot;reversals-and-persistence&quot;&gt;Reversals and persistence&lt;/h3&gt;
&lt;p&gt;That colonization experience should make us wary of assuming that the characteristics of rich, European-descended populations today are instrumental for development. The variation in living standards that shows up in Maddisons data in 1820 is correlated with whether a country took off to sustained growth or not after 1820, but that variation reflects the experience of colonization that took place prior to 1820 as well.&lt;/p&gt;

&lt;p&gt;If we can go backwards to a period prior to colonization, then this can tell us more about the differences in 1820, and hence today. And it opens up the question of whether the places that did reach sustained growth today really were &lt;em&gt;always&lt;/em&gt; richer or better off (persistence), or whether they in fact were behind, and then overtook other economies (reversal).&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ideas.repec.org/a/oup/qjecon/v117y2002i4p1231-1294..html&quot;&gt;Acemoglu, Johnson, and Robinson&lt;/a&gt; posed this question, and argued for a reversal. In order to do this, they had to use proxies for development, as GDP per capita numbers are not available for a lot of countries back to 1500, and furthermore they are going to be very noisy estimates.&lt;/p&gt;

&lt;p&gt;Let’s take an aside to talk about why those might (or might not) be relevant measures of living standards. What we know from other areas of the growth literature is that the urbanization rate is highly correlated with living standards. The causation here is not clear - do cities drive growth, or does growth drive cities? - but the relationship shows up consistently over time. What Remi Jedwab and I did in a &lt;a href=&quot;/assets/EEH_2015.pdf&quot;&gt;paper&lt;/a&gt; was to look back at this correlation in history.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/fig_jv_urbrates.png&quot; alt=&quot;Urbanization and development&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The figure plots urbanization and log GDP per capita for three different years: 1500, 1950, and 2000. Yes, you should be wary of the 1500 relationship because of data issues, but a similar line is going to show up for 1700 or 1820 or 1850. The point is that the correlation is positive over a long span of history. In our paper we talk more about why the slope changed over time, and the baseline &lt;em&gt;level&lt;/em&gt; of urbanization rose across all countries, but for the purposes here we just want to see that urbanization and development are crudely correlated.&lt;/p&gt;

&lt;p&gt;That takes care of urbanization. The other proxy is population density. That one is a little tougher to argue is a good measure of &lt;em&gt;living standards&lt;/em&gt;, even though it might be a very good proxy for the overall level of productivity or technology. For the period of time that AJR are thinking about, 1500, we think that the world was operating in a Malthusian state, as most production relied directly on fixed natural resources and population growth was positively associated with living standards. We could do the theory on this, as in &lt;a href=&quot;https://ideas.repec.org/a/aea/aecrev/v101y2011i5p2003-41.html&quot;&gt;Ashraf and Galor&lt;/a&gt;, to show that those living standards, in equilibrium, are &lt;em&gt;not&lt;/em&gt; related to productivity or technology, but rather to the parameters governing fertility and mortality behavior. On the other hand, population density &lt;em&gt;would&lt;/em&gt; be related to productivity or technology. Rather than looking at their theory, you could also read &lt;a href=&quot;https://growthecon.com/blog/Malthus/&quot;&gt;this post&lt;/a&gt; on Malthusian mechanics I did a while ago. The point is that population density isn’t a very good metric for living standards, although it does give us some indication of economic possibilities, perhaps, of a country/nation.&lt;/p&gt;

&lt;p&gt;Going back to AJR, they showed that &lt;em&gt;among colonies&lt;/em&gt;, places with high urbanization rates or high population density in 1500 (e.g. North Africa, Mexico) were relatively &lt;em&gt;poor&lt;/em&gt; in GDP per capita by 1995. At the same time, places with low urbanization and population density in 1500 (e.g. Australia, Canada) were relatively &lt;em&gt;rich&lt;/em&gt; by 1995.&lt;/p&gt;

&lt;p&gt;However, a more recent paper by &lt;a href=&quot;https://ideas.repec.org/a/aea/aejmac/v6y2014i3p1-28.html&quot;&gt;Chanda, Cook, and Putterman&lt;/a&gt; has revisited this result in light of &lt;em&gt;populations&lt;/em&gt;, as opposed to countries. These authors took the migration data from Putterman and Weil, and came up with the ancestry-adjusted measure of urbanization and density in each country in 1500. For example, in the original AJR data, the urbanization rate in Argentina in 1500 was essentially zero, and the population density was very low. But that reflects the populations that lived in Argentina in 1500. In the time from 1500 to today, Argentina was colonized and settled by the Spanish, and then received a major migration of Europeans like Italians. So the population in Argentina &lt;em&gt;today&lt;/em&gt; is descended from populations that had very &lt;em&gt;high&lt;/em&gt; urbanization and density in 1500.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/fig_ccp_urb.png&quot; alt=&quot;Adjusted relationship for urbanization&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What CCP do is thus adjust each country’s urbanization and density in 1500 to account for this, and compare to the original AJR result. The figure here with the label “Panel A” is from their paper. On the left it shows the original AJR relationship of log GDP per capita in 1995 with the urbanization rate in 1500, and the negative slope - the reversal - is clear. But on the right, you have the CCP ancestry-adjusted measure of urbanization along the x-axis. This has a clear &lt;em&gt;positive&lt;/em&gt; slope. In other words, countries that contain a large number of people descended from places with high urbanization rates are still rich today. In that sense there was persistence in development over time.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/fig_ccp_dens.png&quot; alt=&quot;Adjusted relationship for density&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can do the same adjustment with the density data, as in the figure with label “Panel B” from the CCP paper. Again, the AJR result is on the left, and the CCP result is on the right. And again, there is a clear flip from a negative relationship and reversal to a positive relationship and persistence. Countries today that have populations descended from dense places are relatively rich today.&lt;/p&gt;

&lt;p&gt;This gives us some evidence that population-based differences in living standards are persistent over very long periods of time. And the fact that these comparisons are only over former colonies removes some concern that we’re comparing apples (colonizers) to oranges (colonized). But there clearly remain some open issues here. The nature of colonization was not identical across these countries. The ancestry-adjusted population of Argentina is heavily European because colonization led, through disease or warfare, to an almost total annihilation of the original population. On the other hand, Nigeria’s population has very little European descent because the disease environment favored Nigerians and (perhaps because of this) Europeans never wanted to, or never could, undertake migrations like those into Argentina.&lt;/p&gt;

&lt;p&gt;Nevertheless, the CCP results confirm that there is &lt;em&gt;something&lt;/em&gt; persistent in development levels of populations. So if we want to understand why some of those populations were able to achieve the take-off to sustained growth, and some not, we want to keep digging backwards in time to see how they differed.&lt;/p&gt;

&lt;h3 id=&quot;what-do-we-do-with-this-evidence&quot;&gt;What do we do with this evidence?&lt;/h3&gt;
&lt;p&gt;Before going forward, it may be worth thinking about what we’re up against in trying to explain current development patterns as a function of past development patterns. I think of it in two steps.&lt;/p&gt;

&lt;p&gt;First, we have to identify characteristics of &lt;em&gt;populations&lt;/em&gt; today that differ by the level of development. We cannot just identify them, we need some causal evidence that these characteristics have a real effect on development. In addition, we’ll need some theoretical understanding, which need not involve any kind of fancy math, of what creates that causal link. To give you an example of what I mean here, think of trust in strangers. There is evidence that the amount of trust people have in strangers differs significantly between populations, with many rich populations displaying higher levels of trust than poor populations. There is some plausible evidence that trust in fact causes more economic activity, and the theory is that trust with strangers allows one access to a much wider possible set of transactions than limiting oneself to transactions with kin-group members.&lt;/p&gt;

&lt;p&gt;The second step, which is where the deep roots literature specializes, is in trying to identify the &lt;em&gt;source&lt;/em&gt; of the variation in that characteristic. Why would some populations be prone to trust strangers more than other populations? The data presented here are indirect evidence that this variation extends way back in time, and hence the source may extend way back in time as well. It could be specific historical events, such as evidence that trust within Africa was affected by the degree to which populations were exposed to the slave trade. Or perhaps there are environmental features that lead to variation, as perhaps different types of farming require different amounts of cooperation or work with possible strangers? Maybe it involves some combination of institutional and cultural shifts, perhaps related to marriage patterns? Regardless, we’re after &lt;em&gt;why&lt;/em&gt; these characteristics, like trust, vary by populations, not just in identifying that they vary in the first place.&lt;/p&gt;

&lt;p&gt;We need both steps. The first step, by itself, can be interesting, but without the second step can deteriorate into “just-so” stories about why certain populations are “of course” better suited to development. The second step, by itself, can be interesting, but without the first can deteriorate into what amounts to overly complicated magazine articles without any relevance for current development. Which isn’t to say that every single paper has to tackle both steps, although some do. Our overall understanding has to involve both.&lt;/p&gt;
</description>
        <pubDate>Fri, 11 Jan 2019 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>The deep roots of development - Part 1</title>
        <link>https://growthecon.com/blog/Deep-Roots-1/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Deep-Roots-1/</guid>
        <description>&lt;p&gt;This coming semester I’m teaching a new version of my graduate course in growth and development. I’ve always taught a course that looks at long-run growth, but in the past that has involved at times a lot of theory (e.g. unified growth models) along with a close look at the literature on institutions as the origin of the take-off embedded in that theory. Some of the most popular posts I’ve every done on this blog were the &lt;a href=&quot;https://growthecon.com/blog/the-skeptics-guide-to-institutions-part-1/&quot;&gt;“Skeptics Guide to Institutions”&lt;/a&gt;, which were in part lecture notes for that course. I also folded in material on the transition out of agriculture, something that I find an important part of this transition.&lt;/p&gt;

&lt;p&gt;But that version of the course was always a little muddled in focus, and so for this semester my aim is to step back and start over. The plan is to take a more coherent look at the literature on “deep roots” or “comparative development”, which I’ll define in more detail below. As part of that, my plan is to offer a few lectures during the semester that give an overview of areas within that literature, and a bit of their intellectual history, to frame the specific papers that I’m going to have students dig into and the data work I’m going to have them do.&lt;/p&gt;

&lt;p&gt;This post is meant to be a rough draft of the first of those overview lectures, introducing the field and the major ideas and themes we’ll be covering. The title of the post includes “Part 1”, which is intended as a commitment device. Part 2 should (no, will!) be about the evidence of persistence in economic outcomes over history, and the spatial pattern of development. Part 3 will be about institutions and colonization, Part 4 on culture and family structure, Part 5 on agricultural conditions, and Part 6 on cultural and genetic diversity.&lt;/p&gt;

&lt;p&gt;Timing-wise, those posts are likely to dribble out over the next few months, ideally well ahead of the scheduled date in class, but more realistically in some panicked burst of activity the day before. Once I get the final syllabus worked up, I’ll post that as well, in case people are interested in the bibliography.&lt;/p&gt;

&lt;h3 id=&quot;what-is-the-deep-roots-or-comparative-development-literature&quot;&gt;What is the deep roots or comparative development literature?&lt;/h3&gt;
&lt;p&gt;As with any literature, there is no crystal clear definition. But I’d say that one characteristic common to any paper in this literature is that the underlying question is “Why are some places rich and some places poor?”. A second characteristic is that the answer involves deep-rooted characteristics of populations, rather than things like trade policy, macroeconomic stability, research subsidies, or social safety nets.&lt;/p&gt;

&lt;p&gt;To be more concrete, I think there are several key stylized facts or concepts that this line of research has either established or takes as given. Most people in working in this area would agree with most of the following:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Differences in development are about differences in &lt;em&gt;populations&lt;/em&gt;, not countries. It is not that France, Germany, and the U.S. are rich, it is that places with people descended from ancient European populations tend to be rich. Conversely, places populated with descendants of ancient African populations tend to be poor. Note that this is not a statement about genetics. It is a statement about where the ancestors of current populations lived in the past.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;These populations differ substantially in not just the proximate sources of development (e.g. capital stocks and productivity levels) but in more fundamental characteristics like culture and institutions. Attitudes towards trust, patience, importance of family, and the like all show significant variation across populations. The assumption is that these characteristics drive the proximate sources of development, and some evidence is available to back this up.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Differences in the cultural and institutional characteristics of population arose early. By early, I mean well before industrialization, conceivably back to the origins of settled agriculture in 10,000 BCE, and perhaps even before that. This does not necessarily mean that these cultural and institutional differences created differences in living standards in the past; the effect on development may have been latent.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;There are differences in the geographic, biological, agricultural, and climatic conditions of the ancestors of current populations. Furthermore, cultural and institutional characteristics are correlated with these conditions (things like variability in rainfall, the presence of frost, the durability of stored food, the disease environment, access to the ocean, and so on). Whether those environmental conditions &lt;em&gt;caused&lt;/em&gt; (some of) the differences in culture and institutions is not as clear, but evidence is accumulating that they did.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Things like culture and institutions are incredibly &lt;em&gt;persistent&lt;/em&gt;. Even once the underlying source of differences in those things disappears (e.g. immigrants with different ancestral environmental histories come to the same country) their cultural and institutional differences remain, at least for several generations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;While characteristics are persistent, specific historical events (e.g. the slave trade) appear capable of changing them demonstrably. Therefore these events can change the development possibilities of populations. Which events rise to this significance is an empirical question, but colonization is a common origin.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The work I’ll cover in this course can usually be framed as speaking to one or more of these points. But taking them together, we can stitch together a rough story of why some places are rich and some are poor. First, we should rephrase that as “Why are European-descended populations so rich relative to the rest of the world?”. Second, we could answer it this way. They are rich because the environment they originated in favored the spread of cultural and institutional characteristics (e.g. trust in strangers, patience) that were conducive to economic growth. Given that advantage, they were able to avoid (and instead impose) significant negative historical shocks on the rest of the world that arrested or rolled back their development, giving rise to the observed difference in living standards today.&lt;/p&gt;

&lt;h3 id=&quot;institutions-versus-geography&quot;&gt;Institutions versus geography?&lt;/h3&gt;
&lt;p&gt;The words “institutions” and “geography” both show up in the points I just laid out. And that recalls a long-running debate on the relative importance of each. That debate, I think, has played itself out. Not because one side won and another lost, but because we appreciated that it was a stupid debate in the first place. There is nothing mutually exclusive about institutions and geography (and culture, for that matter) as determinants of development. Rather, both matter and interact with one another to create persistence differences.&lt;/p&gt;

&lt;p&gt;Let me illustrate what I mean by comparing two excellent papers in this field. The first is Melissa Dell’s &lt;a href=&quot;https://ideas.repec.org/a/ecm/emetrp/v78y2010i6p1863-1903.html&quot;&gt;paper&lt;/a&gt; on the mining &lt;em&gt;mita&lt;/em&gt; in Peru. The &lt;em&gt;mita&lt;/em&gt; was a forced labor institution that required natives within a specific area to provide work in the Potosi silver mine for Spain. Dell established in her paper that areas today that were once inside the &lt;em&gt;mita&lt;/em&gt; have lower development levels (on several measures) than places that were once outside the &lt;em&gt;mita&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;The second paper is Marcella Alsan’s &lt;a href=&quot;https://ideas.repec.org/a/aea/aecrev/v105y2015i1p382-410.html&quot;&gt;paper&lt;/a&gt; on the effect of the TseTse fly on African development. She builds a measure of the natural geographic range of the TseTse fly, based on temperature and rainfall. As the TseTse feed mainly on cattle, areas with the fly are less likely to use cattle in agriculture. Alsan shows that across ethnic groups, places exposed to TseTse flies did use fewer cattle, had less of a role for women in agriculture, and were less dense, among other things.&lt;/p&gt;

&lt;p&gt;On the surface, Dell’s paper shows the importance of an institution, while Alsan’s shows the importance of geography. And it would be ridiculous to think that one somehow invalidates the findings of the other. Both, though, show that aspects of development are persistently affected by deep roots, in a broad sense. In Dell’s case, there is a specific historical event - the &lt;em&gt;mita&lt;/em&gt; - that continues to cast a shadow on development within Peru. Note, however, that her finding is not on the effect of that institution, per se, as the mita ceased to exist centuries ago. Rather, she shows that historical shocks have persistent effects. Further, you can easily read Dell’s paper as proof that geography matters, because the location of the &lt;em&gt;mita&lt;/em&gt; was driven by the location of the Potosi mine. Those places are poor because geographically they happened to be close to a major silver lode.&lt;/p&gt;

&lt;p&gt;In Alsan, the deep root is the range of the TseTse fly, which affected how ethnic groups within Africa subsisted, with effects on the role of women and type of agriculture. Again, underlying conditions had persistent effects. Further, she shows that the TseTse itself has no direct effect on development (measured by night lights) once you control for ethnic group centralization prior to colonization. One possibility is that the TseTse - through changing density and other characteristics - influenced centralization, and hence influenced development indirectly.&lt;/p&gt;

&lt;p&gt;The point is that in neither case is there a bright line between institutions and geography (or culture). Both papers show the deep-rooted elements - in one case a historical institution, in another the geographic range of a pest - have detectable effects on development that can persist up until the present day. Both papers provided evidence that helped build the concepts in points 1-6 above, but neither invalidates the other.&lt;/p&gt;

&lt;h3 id=&quot;empirical-methodology-and-data&quot;&gt;Empirical methodology and data&lt;/h3&gt;
&lt;p&gt;Aside from the concepts I listed, perhaps the other defining characteristic of this deep roots literature is the methodology used. It is an almost entirely empirical literature. Theory, when it is used, is illustrative rather than structural. Yes, it is easy to see the deep roots literature as an outgrowth of unified growth theory (UGT), which was much more theory-based. Oded Galor, the originator of UGT, is a central figure in the deep roots literature. But to my point, the theory embedded in his papers today is far more used to frame some simple hypotheses than to model history. If you want to think about how this deep roots literature fits with UGT, think of it as trying to figure out the specific conditions that determine why some places hit the take-off point, and when, rather than figuring out the specific mechanics of how a take-off works.&lt;/p&gt;

&lt;p&gt;Methodologically, the deep roots literature has ingested much of the logic of the causal revolution in economics, and combined that with two novel sources. The first source is extenseive GIS data, including night lights as well as datasets on inherent agricultural characteristics. This has meant the ability to do sub-country level empirical work at the district or pixel level, massively increasing the power of studies and allowing for better identification by being able to use fixed effects for larger political units and/or doing spatial regression discontinuities.&lt;/p&gt;

&lt;p&gt;The second source(s) are bringing what I’ll call cultural datasets into the literature. One prominent one you’ll see is the Ethnographic Atlas, a compendium of anthropological information that was compiled from ethnic-group level studies, and coded into a common set of indicators for different cultural characteristics. For example, Alsan’s paper uses this to look at which groups within Africa relied mainly on cattle, and which had a significant role for women in agriculture, for example. Another is the World Values Survey (among others) that takes contemporary measures of cultural attitudes on things like trust, family, and the like. In both cases, further work has been done to link these cultural measures to maps, so that one can combine the geographic data with the cultural data, often at a sub-country level.&lt;/p&gt;

&lt;p&gt;Beyond these, researchers in this area have brought data in on genetic diversity of populations, language relationships across groups, historical city populations, and so on, in order to make their case. One of the prominent features of this literature is an explosion in datasets being brought to bear on relevant questions.&lt;/p&gt;

&lt;p&gt;While welcome, there are potential issues with this expansion of data. The origins of the data are not always well understood, as one might expect within the field of economic history, for example. The Ethnographic Atlas, for example, is taken as given. It was coded mainly by a single anthropologist working from studies taken from over about eighty years. One can easily imagine that you could teach an entire class on a single one of the 1200-odd ethinc groups in the dataset, and debate the nuances of the family structure, gender roles, and taboos of that group. The idea of coding that nuance into, say, a five point scale for whether a group is “patriarchal” probably makes most anthropologists break out into hives.&lt;/p&gt;

&lt;p&gt;The geographic datasets utilized also tend to be black boxes. A common source is something called the Global Agro-ecological Zones (GAEZ) project. This provides a pixel-level map of the world with numbers of the potential yield of that pixel for oats, for example. How do they arrive at that potential yield? Well, that depends on estimates of rainfall, sunlight, and soil type in that pixel, combined with plant-level parameters for needed water, length of growing period, and the like. What assumptions about how the plant is cultivated are built into the program the GAEZ uses to make that estimate?&lt;/p&gt;

&lt;p&gt;You should remain skeptical - in the academic sense - of the work built on these kinds of datasets. I don’t think we have a good feel for how sensitive the existing results are to plausible variation in these sources. That is, one could easily come up with an alternative Ethnographic Atlas based on a new set of anthropologists coding the same source material, or come up with a new GAEZ based on a different set of assumptions from agronomists. Do those line up closely with the existing versions? If so, great. That might give us some assurance that the results we review are robust. But if not, things are very murky. The deep roots results could well fall apart with a slightly different version of the Atlas or GAEZ.&lt;/p&gt;

&lt;h3 id=&quot;determinism&quot;&gt;Determinism&lt;/h3&gt;
&lt;p&gt;Leaving aside the questions about data quality, this literature seems to imply some strong versions of determinism. That is, were the places that are poor today doomed to be poor because of some historic event 500 years ago, or because of geographic conditions present 10,000 years ago?&lt;/p&gt;

&lt;p&gt;Here I think it helps to think statistically, rather than in absolutes. And here I do not mean thinking about the uncertainty associated with point estimates of effect sizes, but rather the fact that in no case will any study show you an R-squared of one, meaning perfect prediction. To use a more concrete example, it is plausible that ethnic groups in areas where there were large returns to long-run investment in agricultural production may end up more patient in the long-run as well (as more patient people were selected for). There is a significant relationship of productivity with patience in the data.&lt;/p&gt;

&lt;p&gt;There is a significant relationship, but the R-squared is about 10%. That means that within the existing data, it is quite plausible to find pairs of ethnic groups that have different patience levels today even though they had similar productivity levels, or pairs with the same patience, but with different productivity. That’s all consistent with a statistically significant result and an R-squared of 10%.&lt;/p&gt;

&lt;p&gt;More to the point on determinism, the results don’t mean that ethnic group A with higher productivity &lt;em&gt;had&lt;/em&gt; to have higher patience than group B with lower productivity. Imagine bootstrapping world history 10,000 times, starting over at like 100,000 BCE every time. The significant relationship of productivity and patience means that we’d expect patience to be higher in A than in B in more than half of those runs, but the R-squared of 10% it wouldn’t happen in all of them. It might be only that in 550,000 of the run does A have more patience than B, meaning B is more patient in 450,000 alternative histories. And yes, the positive relationship of productivity and patience could still be true even in those 450,000 histories because the patience of groups C, D, E, etc.. are all changing each time as well.&lt;/p&gt;

&lt;p&gt;The fact that the explanatory variable here, agricultual productivity, is taken to be plausibly exogenous to the patience of the groups is immaterial. Lots of other things affect the patience of an ethnic group over and above the productivity level, and hence lots of things could have changed over the course of history to explain patience.&lt;/p&gt;

&lt;p&gt;Acknowledging that geography (or biology, or agro-climatic characteristics) are significant for some cultural trait, institution, or level of development does &lt;em&gt;not&lt;/em&gt; imply a deterministic relationship exists, and that history is locked in no matter what. R-squares are not 100%!&lt;/p&gt;

&lt;p&gt;The findings in this literature do not mean it is impossible to change the development level of countries or groups today. But the deep-rooted nature of development may mean we have to find &lt;em&gt;other&lt;/em&gt; policy levers to push, as we cannot go back in time and roll back colonization, or change inherent agricultural productivity, and so forth. This isn’t that different than what you’d find in an applied micro course on, say, education. There you might study the effects of a program to raise graduation rates, and see whether it is effective or not. But note that graduation rates in some schools were not low to begin with because of the lack of this program, they were low because of (probably) poor socio-economic backgrounds, a lack of resources, poor teachers, etc. Even in these worlds we spend a lot of time pushing &lt;em&gt;other&lt;/em&gt; policy levers than the ones that created the situation in the first place.&lt;/p&gt;

&lt;h3 id=&quot;going-forward&quot;&gt;Going forward&lt;/h3&gt;
&lt;p&gt;Unlike a lot of courses, this material will at times be breathtaking in the questions it asks and answers it proposes. It will seem presumptuous to explain cross-cultural patience as a function of agricultural productivity around the time of the Neolithic Revolution. And I think that researchers within this field do have a tendency to take big swings at big questions, and at times the prose in the papers will reflect that. Don’t let that put you off. The question still remains whether there is a valid empirical link established, and whether that link can be interpreted causally or just as a correlation. I think you’ll see that there is an accumulation of papers establishing strong links between deep roots and current development, and that this is not just a few odd results.&lt;/p&gt;

&lt;p&gt;As mentioned above, what I’m hoping to do from here forward (on the blog) is post subsequent parts with material on persistence, institutions and colonization, culture and families, agricultural productivity, and diversity. In the class itself, we’ll be covering specific papers within each section, and I’ll be trying to get my students up to speed on using R’s spatial packages to bring in some of the datasets used and replicating some basic results.&lt;/p&gt;

&lt;p&gt;There is a &lt;a href=&quot;https://growthecon.com/blog/topic-deep/&quot;&gt;topic page&lt;/a&gt; up on my site already with all the existing posts I’ve classified as related to “deep roots”, so if you’re into this material feel free to have a poke around that.&lt;/p&gt;
</description>
        <pubDate>Mon, 31 Dec 2018 00:00:00 -0600</pubDate>
      </item>
    
      <item>
        <title>New evidence on convergence</title>
        <link>https://growthecon.com/blog/Convergence/</link>
        <guid isPermaLink="true">https://growthecon.com/blog/Convergence/</guid>
        <description>&lt;p&gt;Dev Patel, Justin Sandefur, and Arvind Subramanian &lt;a href=&quot;https://www.cgdev.org/blog/everything-you-know-about-cross-country-convergence-now-wrong&quot;&gt;posted&lt;/a&gt; the other day some new evidence on cross-country convergence. They showed that there is statisticaly significant evidence for unconditional convergence in GDP per capita across countries. I’ll get to more details below, but in short they find that poor countries grow faster than rich ones, on average.&lt;/p&gt;

&lt;p&gt;They set this up as a counter-point to an &lt;a href=&quot;https://www.aeaweb.org/articles?id=10.1257/jel.20181207&amp;amp;&amp;amp;from=f&quot;&gt;article&lt;/a&gt; coming out in the Journal of Economic Literature by Paul Johnson and Chris Papageorgiou that says cross-country convergence doesn’t occur. The difference in the PSS post and the JP paper is that PSS look at relatively recent windows of data. For example, PSS look at whether countries that were poor in 1990 grew faster than rich countries in 1990 from 1990 to 2014.&lt;/p&gt;

&lt;p&gt;In constrast, JP appear to look at longer time frames. They find that there isn’t much evidence countries that were poor in 1960 grew faster than rich countries in 1960. This isn’t a contradiction with PSS. Both can be true at once. All PSS have done is indicated that around twenty-five years ago poor countries did start growing faster than rich countries.&lt;/p&gt;

&lt;p&gt;The implication of that finding is that poor countries are &lt;em&gt;converging&lt;/em&gt; to rich country GDP per capita. And while that statement is defensible, it does need a host of qualifications, because it doesn’t mean you should expect that developing countries are soon going to look like Western Europe. This post is meant to pick through those qualifications.&lt;/p&gt;

&lt;h3 id=&quot;flavors-of-convergence&quot;&gt;Flavors of convergence&lt;/h3&gt;
&lt;p&gt;Let’s start with a better definition of convergence. There are two kinds. Within economics, they acquired particular names, and I’ll use those to be consistent with the literature. They are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence: this kind of convergence occurs if the growth rate of GDP per capita is negatively related to the initial level of GDP per capita. That is, &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence is defined by poor countries growing faster than rich countries.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence: this kind of convergence occurs if the variance (or any measure of dispersion, really) of GDP per capita &lt;em&gt;across&lt;/em&gt; countries shrinks. &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence means the gap in GDP per capita from rich to poor gets smaller.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Now, it &lt;em&gt;feels&lt;/em&gt; like &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence should imply &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence. And in some cases it does. Rather than GDP per capita, think about the height of the people in my house. If you plotted the growth rate of height from 2005-2018 against height in 2005 for all four of us, you’d get a negative coefficient. My two daughters were really short in 2005, but grew very fast over the next 13 years. My wife and I were both relatively tall in 2005, but neither of us grew at all. That’s &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence. In this case, if you looked at the variance of heights in 2005, that would be much larger than the variance of heights in 2018, and hence there was also &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence in my house.&lt;/p&gt;

&lt;p&gt;For height, &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence implies &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence because there is not any additional noise or variance in height to worry about. I don’t wake up every day and randomly find myself 6 inches taller or shorter than I was the day before. That ensures that as my daughters grow, they really do catch up in height. I don’t get randomly taller, and they don’t get randomly shorter.&lt;/p&gt;

&lt;p&gt;But in the case of economic growth, there are random shocks to GDP per capita. &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence says that poor countries, &lt;em&gt;on average&lt;/em&gt;, grow faster than rich countries. But there will be instances where poor countries have really slow, or negative, growth sometimes. Think of currency crises or political upheavals. There will be some instances where rich countries experience rapid growth. With both of these things going on, it’s entirely possible that poor countries keep falling farther behind in terms of GDP per capita, &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-&lt;em&gt;divergence&lt;/em&gt;, even though the poorer they get the faster they grow on average.&lt;/p&gt;

&lt;p&gt;Here’s an analogy that could help. Imagine somone one juggling bowling pins. Gravity is like&lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence. If the bowling pin is up in the air, then gravity is making it fall. But every time it reaches the juggler, she throws it back up in the air. This means there is always the same amount of dispersion in the location of the pins; some are up and some are down. In other words, there is a constant amount of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence, even though the &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence caused by gravity is always at work. If the juggler throws the pins up with a little less force each time, then the dispersion will decrease. If the juggler throws the pins up with more force each time, the dispersion will &lt;em&gt;increase&lt;/em&gt;. Nevertheless, gravity - &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence - is still working the whole time.&lt;/p&gt;

&lt;p&gt;Economic shocks act a little like the juggler, except that it isn’t just the rich countries (the ones the juggler catches) that experience shocks (the toss in the air). But the principle is similar, which is that with sufficiently large shocks, the dispersion in GDP per capita may not fall, and could even rise, over time. This is true even though &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence, like gravity, operates on countries the whole time.&lt;/p&gt;

&lt;p&gt;In terms of cross-country comparisons, we’re mainly interested in &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence: is the gap between poor and rich countries shrinking over time? Observing &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence in the data does not tell us whether that is true. Now, some sort of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence is &lt;em&gt;necessary&lt;/em&gt; for &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence to occur. At some point, a poor country has to grow faster than a rich country in order to catch up. But &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence isn’t sufficient for &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence. The PSS result doesn’t mean that the dispersion of GDP per capita across countries got smaller, or will get smaller.&lt;/p&gt;

&lt;h3 id=&quot;convergence-speed&quot;&gt;Convergence speed&lt;/h3&gt;
&lt;p&gt;Let’s leave aside whether &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence implies &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence for the moment. Let’s assume that the shocks are small enough that in fact, &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence is implied. The next question is &lt;em&gt;how long&lt;/em&gt; it will take a poor country to close the gap with a rich country, and the actual coefficient that PSS estimate can tell us about this.&lt;/p&gt;

&lt;p&gt;To make sense of this, I need a little math. The convergence relationship that PSS estimate looks like this&lt;/p&gt;

\[\frac{\ln y_{t} - \ln y_0}{t} = \alpha + \beta \ln y_0.\]

&lt;p&gt;On the left is the growth rate of GDP per capita, &lt;img src=&quot;http://latex.codecogs.com/png.latex?y\inline&quot;/&gt;, from some initial year 0 to year &lt;img src=&quot;http://latex.codecogs.com/png.latex?t\inline&quot;/&gt;. This is related to the initial level of GDP per capita, &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_0\inline&quot;/&gt;, on the right-hand side. The strength of that relationship is measured by the coefficient &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;. &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence means that &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta&amp;lt;0\inline&quot;/&gt;, or that the growth rate gets smaller as the initial level of income gets higher. How large (in absolute value) &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt; is determines how strong that effect is. The extra parameter &lt;img src=&quot;http://latex.codecogs.com/png.latex?\alpha\inline&quot;/&gt; is a baseline growth rate.&lt;/p&gt;

&lt;p&gt;A little re-arrangment of this gives us&lt;/p&gt;

\[\ln y_t = \alpha t + (1 + \beta t) \ln y_0\]

&lt;p&gt;which is the level of GDP per capita at time &lt;img src=&quot;http://latex.codecogs.com/png.latex?t\inline&quot;/&gt;, given initial GDP per capita at time 0. That multiplicative term &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta t\inline&quot;/&gt; is the effect of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence over time.&lt;/p&gt;

&lt;p&gt;Using this, here’s a question we could ask. Given a poor country has &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_0^{Poor}\inline&quot;/&gt; that is only 10% of the value in a rich country, &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_0^{Rich}\inline&quot;/&gt;, how long will it take (i.e. how big does &lt;img src=&quot;http://latex.codecogs.com/png.latex?t\inline&quot;/&gt; have to be) before &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_t^{Poor}\inline&quot;/&gt; is 90% of the value in the rich country, &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_t^{Rich}\inline&quot;/&gt;? Given the set-up, this &lt;em&gt;will&lt;/em&gt; happen at some point. I didn’t add any of the shocks mentioned above that could keep spreading these two countries apart. &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence will eventually win out.&lt;/p&gt;

&lt;p&gt;At this hypothetical time &lt;img src=&quot;http://latex.codecogs.com/png.latex?t\inline&quot;/&gt;, we want that &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_t^{Poor}/y_t^{Rich} = .9\inline&quot;/&gt;, which if you take logs and plug in from the above equation, gives us&lt;/p&gt;

\[\ln .9 = \alpha t + (1 + \beta t) \ln y_0^{Poor} - \alpha t - (1 + \beta t) \ln y_0^{Rich}\]

&lt;p&gt;and we can simplify this to&lt;/p&gt;

\[\ln .9 = (1 + \beta t) (\ln y_0^{Poor} - \ln y_0^{Rich}).\]

&lt;p&gt;We also said that &lt;img src=&quot;http://latex.codecogs.com/png.latex?y_0^{Poor}/y_0^{Rich} = .1\inline&quot;/&gt;, so taking logs of that, we can plug in and get&lt;/p&gt;

\[\ln .9 = (1 + \beta t) \ln .1\]

&lt;p&gt;and now re-arrange to solve for time &lt;img src=&quot;http://latex.codecogs.com/png.latex?t\inline&quot;/&gt;&lt;/p&gt;

\[t = \frac{\frac{\ln .9}{\ln .1} - 1}{\beta}.\]

&lt;p&gt;This is how long it will take the poor country to go from 10% of rich country GDP per capita to 90% per capita. And you could plug in other numbers in the obvious spots here to think about the time to go from 20% to 99%, or whatever you wanted.&lt;/p&gt;

&lt;p&gt;The key is that the absolute size of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt; matters. The smaller is &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt; in absolute value, the more time it takes to converge. Now, what PSS show is that in samples that only run through 2000, &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt; was about 0, which means that &lt;img src=&quot;http://latex.codecogs.com/png.latex?t\inline&quot;/&gt; is essentially infinity. With no &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence, there isn’t a way for the poor country to ever catch up, because it doesn’t grow faster than the rich country. But with later samples, &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta&amp;lt;0\inline&quot;/&gt;, so they can.&lt;/p&gt;

&lt;p&gt;Their biggest estimate value is &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta = -.005\inline&quot;/&gt;, not very big. Plugging that into the above equation implies that &lt;img src=&quot;http://latex.codecogs.com/png.latex?t = 190\inline&quot;/&gt;, or it will take about 190 years for a country to go from 10% of rich-country GDP per capita to 90%. That’s a loooong time. So even in the case where we assume that &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence leads to &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence (i.e. the ratio goes from 10% to 90%), and ignore the possibility that shocks keep spreading things out, &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence may not imply much noticeable &lt;img src=&quot;http://latex.codecogs.com/png.latex?\sigma\inline&quot;/&gt;-convergence over the next few decades.&lt;/p&gt;

&lt;h3 id=&quot;absolute-and-conditional-convergence&quot;&gt;Absolute and conditional convergence&lt;/h3&gt;
&lt;p&gt;The PSS result of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta = -.005\inline&quot;/&gt; is small. At the same time, you will see references that the convergence coefficient is more like &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta = -0.02\inline&quot;/&gt; in the literature. Probably the most famous of these papers are from &lt;a href=&quot;https://ideas.repec.org/a/oup/qjecon/v106y1991i2p407-443..html&quot;&gt;Barro&lt;/a&gt; in 1991 and &lt;a href=&quot;https://ideas.repec.org/a/ucp/jpolec/v100y1992i2p223-51.html&quot;&gt;Barro and Sala-i-Martin&lt;/a&gt; in 1992. There are a host of other papers offering more estimates of this parameter, but I think it is fair to say that -0.02 is a good eyeball average of those results.&lt;/p&gt;

&lt;p&gt;Now, we have to be a little careful here in these older results to PSS. PSS estimate &lt;em&gt;unconditional&lt;/em&gt; &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence, meaning they just making raw comparisons of growth in GDP per capita against initial GDP per capita across countries. Their result implies that poorer countries grow (a little bit) faster than rich countries, and that this doesn’t depend (is unconditional) on characteristics of those countries. It says that if you are poor, no matter &lt;em&gt;why&lt;/em&gt; you are poor, you grow a little faster than rich countries, no matter &lt;em&gt;why&lt;/em&gt; they are rich.&lt;/p&gt;

&lt;p&gt;The original convergence literature did the same kind of unconditional analysis, and found nothing. That is the point, in some sense, of the PSS note. But that original literature did find evidence for &lt;em&gt;conditional&lt;/em&gt; &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence. This means that if you look only at groups of countries that have similar characteristics (e.g. savings rate, human capital levels, etc..) then you find &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence in those groups - the poorer ones grow faster than the rich ones.&lt;/p&gt;

&lt;p&gt;But &lt;em&gt;across&lt;/em&gt; groups, there was no tendency for &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence. For example, if you looked only at the OECD countries, you’d see pretty strong evidence of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence, with an estimate of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta = -0.02\inline&quot;/&gt;, roughly. And if you looked only at the set of Sub-Saharan African countries, you’d see similar evidence of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence. But, there was no tendency for SSA countries as a group to grow faster than OECD countries. It was only that &lt;em&gt;within&lt;/em&gt; the group of SSA countries, poorer ones grew faster, and &lt;em&gt;within&lt;/em&gt; the group of OECD countries, poorer ones grew faster. You can find this notion of conditional - or “club” - convergence in blog-favorite William Baumol’s 1986 &lt;a href=&quot;http://piketty.pse.ens.fr/files/Baumol1986.pdf&quot;&gt;paper&lt;/a&gt; that was one of the first to think about this topic.&lt;/p&gt;

&lt;p&gt;A different way of looking at conditional convergence was to use data on states or prefectures within a single country. They would all have roughly similar characteristics relative to countries (e.g. Texas and Florida differ, but that difference pales in comparison to the difference between Texas and Nigeria). And within countries, the evidence seems was clear that &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence happens. Again, these coefficients were usually around &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta = -0.02\inline&quot;/&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta = -0.02\inline&quot;/&gt; number implies much faster convergence. If you think of a poor state that had 10% GDP per capita relative to a rich state, then it would only take about 48 years for it to reach 90% of GDP per capita of the rich state. That’s, not surprisingly, one-fourth the time it takes a poor country to catch up to a rich one. It’s also one way of thinking about why we don’t see U.S. states with only 10% the GDP per capita of rich ones. Any time a gap opens up, it tends to dissipate. Although I need to note that there is some recent research saying that &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence across U.S. states no longer occurs. Let’s leave that aside.&lt;/p&gt;

&lt;p&gt;Which number is right, &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta=-0.005\inline&quot;/&gt; or &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta = -0.02\inline&quot;/&gt;? Neither. They don’t measure the same thing. The former is for unconditional cross-country convergence in the last 25 years, the latter is appropriate for conditional convergence or within-country convergence. Both can be true in their individual setting. Individual provinces within Kenya might converge very quickly, even though Kenya as a whole isn’t converging very quickly to U.S. GDP per capita.&lt;/p&gt;

&lt;h3 id=&quot;what-does-convergence-tell-us&quot;&gt;What does convergence tell us?&lt;/h3&gt;
&lt;p&gt;The use of convergence results depends on what you’re after. The &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt; value that PSS report, similar to every other estimated &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt; value, tells you whether &lt;em&gt;on average&lt;/em&gt; poor countries grow faster than rich ones. But that doesn’t make it very informative about any particular country. It certainly won’t tell you whether to expect some kind of growth miracle or disaster to occur in the future.&lt;/p&gt;

&lt;p&gt;Here’s what I mean. I took the Penn World Tables, one of the datasets used by PSS, and plotted the data used to estimate &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;. You’ve got the average growth rate of GDP per capita from 1990 to 2014 on the y-axis, against the (log) of GDP per capita in 1990 on the x-axis. The downward-sloped dashed line is the best fit to this data, and the slope of that line is about -.005, the PSS estimate of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/fig_convergence.png&quot; alt=&quot;Convergence&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But you can see that this hides a lot of variation. I labelled a few countries for reference. The USA and Japan (JPN), out on the right, can be the stand-in for the “Rich” countries. You can also see China (CHN) and India (IND), both of which had growth rates well above the estimated relationship, and hence they converged much faster towards rich-country GDP per capita. This would set them apart from the Central African Republic (CAF) and Zimbabwe (ZWE), who both started out relatively poor, but &lt;em&gt;shrank&lt;/em&gt; in terms of GDP per capita, and fell even further behind the USA and JPN. I also threw South Korea (KOR) in there, as an example of a country that closed almost the entire gap with JPN from 1990 to 2014, although many other countries with a similar level of GDP per capita in 1990 did not.&lt;/p&gt;

&lt;p&gt;A crude way of seeing how useful the &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence result is comes from looking at the R-squared of the regression that was used to estimate &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;. It’s 0.0462. In other words, 95.38% of the variation in growth rates from 1990 to 2014 is &lt;em&gt;not&lt;/em&gt; explained by how poor a country was in 1990. Yes, there is evidence here for unconditional convergence &lt;em&gt;on average&lt;/em&gt;. But plenty of countries grew slower than necessary to converge to rich country levels of GDP per capita.&lt;/p&gt;

&lt;p&gt;It is probably best not to think of unconditional &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence as representing some kind of structural truth about economic growth. If it were, you’d expect it to show up regardless of the exact time frame looked at, and PSS show that’s not the case. It’s better to think of it as a summary statistic of the general experience of poor countries in a given time frame. The PSS results tell us that &lt;em&gt;something&lt;/em&gt; changed around 1990 such that many poor countries grew faster than rich countries, relative to the period from 1960 to 1990. But it doesn’t tell us what or why it changed, or if it will persist.&lt;/p&gt;

&lt;p&gt;That doesn’t make the PSS estimate spurious. It’s a nice descriptive result that tells us we should think a little more about what might have changed around those years, even if the implication of &lt;img src=&quot;http://latex.codecogs.com/png.latex?\beta\inline&quot;/&gt;-convergence from that period is not that strong.&lt;/p&gt;
</description>
        <pubDate>Fri, 02 Nov 2018 00:00:00 -0500</pubDate>
      </item>
    
  </channel>
</rss>
